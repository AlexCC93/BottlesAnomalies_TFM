{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x00000197C4D26FA0>\n",
      "GeForce RTX 2080 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '../../../../BottleStoodUp_atNight/Positive/'        #For the work laptop\n",
    "data_dir = '../../../Images/BottleStoodUp_atNight/Positive'        #For the home laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_characteristics = transforms.Compose([transforms.Resize(255),\n",
    "#                                 transforms.CenterCrop(224),\n",
    "#                                 transforms.ToTensor()])\n",
    "\n",
    "transform_characteristics = transforms.Compose([transforms.ToTensor(),\n",
    "                                                transforms.Resize(255),\n",
    "                                                transforms.CenterCrop(224)])\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform_characteristics)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only the encoder part of the nertwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_latentSpace(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # N, 1, 28, 28\n",
    "        # 32, 3, 224, 224\n",
    "        input_channels = 3              # number of channels of the input image\n",
    "        output_channels = 110           # ~= 224/2. Shape of the input image \n",
    "        kernel_size = 9\n",
    "        padding_val = 1\n",
    "        stride_val = 5\n",
    "\n",
    "        output_channels_layer2 = output_channels*2+5\n",
    "\n",
    "        output_channels_layer3 = output_channels_layer2*2\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size, stride=stride_val, padding=padding_val),         # input image channels, output channels, kernel size (filter). Dimension rseult: -> N, 110, 44, 44\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels, output_channels_layer2, kernel_size, stride=stride_val, padding=padding_val), # -> N, 225, 8, 8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels_layer2, output_channels_layer3, 8) # -> N, 450, 1, 1\n",
    "        )\n",
    "        \n",
    "        # self.show_modules()\n",
    "        # self.show_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"This is the forward function\")\n",
    "        encoded = self.encoder(x)\n",
    "        return encoded\n",
    "    \n",
    "    def show_modules(self):\n",
    "        print(\"This is the new function\")\n",
    "        # print(self.modules())\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            print(m)\n",
    "            print(\"i is: \", i)\n",
    "            print(\"print the next module\")\n",
    "            i = i +1\n",
    "    \n",
    "    def show_weights(self):\n",
    "        print(\"This is the function for showing the initial weights\")\n",
    "        # print(self.modules())\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if i == 0:\n",
    "                    print(\"i is: \", i)\n",
    "                    print(\"The type of the module weight is: \", type(m.weight))\n",
    "                    print(\"The shape of the module weight is: \", m.weight.shape)\n",
    "                    print(\"print the next module\")\n",
    "                    i = i +1\n",
    "    def show_one_module_weights(self):\n",
    "        print(\"Showing only one module's weights\")\n",
    "        # print(self.modules())\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if i == 0:\n",
    "                    print(\"i is: \", i)\n",
    "                    print(\"The weights are: \", m.weight)\n",
    "                    i = i +1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder_latentSpace(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(110, 225, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(225, 450, kernel_size=(8, 8), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_encoder = Autoencoder_latentSpace()\n",
    "model_encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing only one module's weights\n",
      "i is:  0\n",
      "The weights are:  Parameter containing:\n",
      "tensor([[[[ 4.4871e-02,  2.9082e-02,  3.2841e-02,  ..., -4.0282e-02,\n",
      "           -1.7379e-02, -5.0551e-02],\n",
      "          [-1.4576e-02, -2.8838e-02, -2.4488e-02,  ..., -6.0105e-02,\n",
      "           -4.9931e-02, -6.2321e-02],\n",
      "          [-5.7696e-02,  5.3239e-02,  5.0371e-02,  ...,  2.5325e-02,\n",
      "           -3.2477e-02,  3.6619e-02],\n",
      "          ...,\n",
      "          [ 5.8053e-02,  1.9525e-02, -1.9289e-02,  ...,  3.8182e-02,\n",
      "            2.5268e-02, -6.1149e-02],\n",
      "          [ 5.3414e-02,  3.6838e-02, -6.2954e-02,  ...,  2.3757e-02,\n",
      "           -4.4671e-02, -4.1561e-02],\n",
      "          [ 3.3526e-02, -6.4007e-02, -8.9518e-03,  ...,  9.9564e-03,\n",
      "           -1.3091e-02,  6.2309e-02]],\n",
      "\n",
      "         [[-3.4604e-02,  2.8722e-02,  3.0524e-02,  ..., -3.1441e-02,\n",
      "            2.1474e-04, -4.5121e-02],\n",
      "          [ 6.2992e-02,  2.9784e-02, -3.2846e-02,  ...,  3.3754e-02,\n",
      "           -5.3615e-02, -3.2559e-02],\n",
      "          [-5.0462e-02, -3.7823e-02, -6.0304e-02,  ...,  3.3443e-03,\n",
      "           -9.0539e-04, -4.3056e-02],\n",
      "          ...,\n",
      "          [ 8.0806e-03,  3.0476e-02, -1.3950e-02,  ...,  4.2747e-02,\n",
      "            3.8569e-02, -3.1274e-02],\n",
      "          [-3.4277e-02, -5.7029e-02,  1.3882e-02,  ..., -4.2284e-02,\n",
      "           -1.4833e-02,  5.0523e-02],\n",
      "          [ 1.1452e-02,  2.5199e-02, -3.6694e-02,  ..., -6.2003e-02,\n",
      "            9.5583e-03,  4.0379e-02]],\n",
      "\n",
      "         [[ 6.2316e-02,  6.1222e-02,  3.1105e-02,  ..., -1.2007e-02,\n",
      "           -3.0346e-02, -7.3934e-03],\n",
      "          [ 5.6729e-02,  5.8467e-02,  6.1294e-02,  ...,  6.0271e-02,\n",
      "            6.1626e-02,  3.0573e-02],\n",
      "          [ 5.2806e-03,  6.0565e-03,  1.0223e-02,  ...,  3.7570e-02,\n",
      "           -1.8744e-02, -1.7292e-02],\n",
      "          ...,\n",
      "          [-3.1572e-02, -5.9454e-03,  2.1325e-02,  ...,  2.6015e-02,\n",
      "            3.6655e-02,  5.6205e-02],\n",
      "          [-4.9108e-02, -2.3021e-03, -1.9047e-02,  ...,  5.0550e-02,\n",
      "            1.5938e-03,  5.4871e-02],\n",
      "          [-1.3922e-02,  2.3520e-02,  1.6347e-02,  ..., -1.7999e-02,\n",
      "           -6.1390e-02,  2.5306e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.3369e-02, -1.0237e-02,  3.3306e-02,  ...,  7.8106e-03,\n",
      "           -3.6076e-02, -4.4883e-02],\n",
      "          [ 3.4424e-02,  5.5651e-02, -2.8678e-02,  ..., -4.6644e-02,\n",
      "           -4.2552e-02,  5.9862e-02],\n",
      "          [-1.1054e-03,  4.4784e-03,  4.1212e-02,  ...,  5.0133e-03,\n",
      "           -5.0897e-04,  4.5008e-02],\n",
      "          ...,\n",
      "          [-1.2122e-02, -9.1343e-03,  1.8185e-02,  ...,  1.6263e-02,\n",
      "           -3.8040e-02,  3.5754e-02],\n",
      "          [ 3.7925e-02,  3.2465e-02,  5.9554e-02,  ..., -1.9202e-02,\n",
      "           -9.6837e-04,  2.8234e-02],\n",
      "          [-3.6655e-02, -3.4326e-02,  4.3852e-02,  ..., -5.6674e-02,\n",
      "            1.9034e-02,  5.6831e-02]],\n",
      "\n",
      "         [[-6.2889e-02, -1.8587e-02, -3.2883e-02,  ..., -1.1866e-02,\n",
      "           -1.8419e-02,  4.1408e-02],\n",
      "          [-6.1056e-02, -9.0714e-03,  4.3334e-03,  ...,  7.1523e-03,\n",
      "            1.9657e-02, -4.4929e-02],\n",
      "          [-5.8849e-02,  5.4433e-02,  5.4409e-02,  ..., -5.9903e-02,\n",
      "            3.6428e-02,  3.4139e-02],\n",
      "          ...,\n",
      "          [ 1.6172e-02,  2.2232e-02,  6.1979e-02,  ..., -5.8594e-02,\n",
      "            1.1045e-02,  1.9518e-02],\n",
      "          [-5.3762e-02,  6.2550e-02,  5.3036e-02,  ..., -1.3830e-02,\n",
      "           -7.7241e-03, -5.3074e-02],\n",
      "          [ 1.2916e-02,  8.8162e-03, -4.8791e-02,  ..., -5.1562e-02,\n",
      "           -1.1728e-02,  3.6283e-02]],\n",
      "\n",
      "         [[-5.1500e-02,  4.4887e-02, -6.0997e-02,  ..., -1.0421e-02,\n",
      "            3.5197e-02, -4.4474e-02],\n",
      "          [ 3.9276e-02,  3.4999e-02,  3.1128e-03,  ..., -2.1155e-03,\n",
      "           -4.8337e-03, -5.0349e-02],\n",
      "          [-4.0673e-03, -2.7160e-02, -6.2799e-02,  ..., -5.4866e-02,\n",
      "           -5.6419e-02,  3.2413e-02],\n",
      "          ...,\n",
      "          [-8.4081e-03, -2.1003e-02,  2.8152e-02,  ..., -2.2473e-02,\n",
      "            3.7982e-03,  1.2466e-03],\n",
      "          [-3.8944e-03, -2.4026e-02, -1.1003e-02,  ..., -1.5920e-02,\n",
      "           -4.5533e-03,  2.6800e-02],\n",
      "          [-6.2653e-02,  1.5921e-02,  3.2903e-02,  ...,  2.9207e-02,\n",
      "            7.2578e-03, -3.8089e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9279e-02,  5.9251e-02, -3.6960e-03,  ...,  6.1856e-02,\n",
      "           -2.8085e-02,  3.1738e-02],\n",
      "          [ 6.0661e-02,  3.4244e-02, -5.8560e-02,  ...,  1.4454e-02,\n",
      "           -4.6838e-02, -2.4677e-02],\n",
      "          [-7.7319e-03, -5.1340e-02,  2.0652e-02,  ...,  1.9838e-03,\n",
      "            5.2055e-02, -1.8881e-02],\n",
      "          ...,\n",
      "          [ 6.2626e-02,  3.3136e-02,  2.7126e-03,  ..., -3.3459e-02,\n",
      "            5.5244e-02, -7.8207e-03],\n",
      "          [-4.9950e-02,  1.1479e-02, -4.8836e-02,  ..., -6.1059e-02,\n",
      "           -4.9073e-03,  7.0594e-04],\n",
      "          [ 5.6159e-02,  3.7167e-02, -1.0370e-02,  ..., -2.7144e-02,\n",
      "           -5.4975e-02,  5.6535e-02]],\n",
      "\n",
      "         [[-5.7336e-02,  1.5035e-02, -5.9518e-02,  ..., -6.3696e-02,\n",
      "           -2.1661e-02, -6.3468e-02],\n",
      "          [ 1.7792e-02,  2.0471e-02,  6.1426e-02,  ..., -2.4146e-02,\n",
      "           -2.3512e-02,  1.6291e-02],\n",
      "          [ 2.4510e-02,  2.4957e-02, -2.5780e-02,  ..., -3.8643e-02,\n",
      "            2.3387e-02,  5.7001e-02],\n",
      "          ...,\n",
      "          [-1.1827e-02, -2.5112e-02,  3.2155e-02,  ..., -1.1285e-02,\n",
      "            1.6120e-02,  1.1642e-02],\n",
      "          [ 4.2241e-02, -1.2483e-02, -6.3425e-02,  ...,  3.5999e-02,\n",
      "            4.2002e-02, -4.1750e-02],\n",
      "          [ 4.4120e-02, -4.8473e-02, -2.0769e-02,  ..., -5.6047e-02,\n",
      "           -4.1448e-02, -2.3643e-02]],\n",
      "\n",
      "         [[ 1.6933e-03,  2.2338e-02,  5.0045e-02,  ...,  6.7965e-03,\n",
      "           -3.6989e-02,  7.0084e-03],\n",
      "          [ 5.1025e-02, -6.3079e-02,  6.0590e-02,  ...,  3.2721e-02,\n",
      "           -1.0782e-02,  2.2525e-02],\n",
      "          [-1.6317e-02,  6.3999e-02,  2.1958e-02,  ...,  3.1263e-03,\n",
      "           -5.9269e-02,  5.0129e-02],\n",
      "          ...,\n",
      "          [ 6.6382e-04,  5.1215e-02,  2.3509e-02,  ...,  4.7979e-03,\n",
      "            1.9943e-02, -1.7389e-02],\n",
      "          [-2.1116e-02,  5.8834e-02, -4.6648e-02,  ...,  2.2520e-02,\n",
      "            5.3831e-02, -2.5609e-02],\n",
      "          [-1.6495e-02,  5.7946e-02,  6.0268e-02,  ..., -4.7556e-02,\n",
      "            4.4483e-02, -4.8163e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.5149e-02, -2.9428e-02,  3.1849e-03,  ..., -2.6377e-02,\n",
      "            5.6160e-02,  1.1736e-02],\n",
      "          [-5.7920e-02,  4.5438e-02,  3.8057e-02,  ..., -3.7474e-03,\n",
      "            5.8804e-02, -1.4499e-02],\n",
      "          [-9.5680e-03, -1.5200e-02, -3.7155e-02,  ...,  2.2453e-02,\n",
      "           -5.4800e-02, -3.2535e-02],\n",
      "          ...,\n",
      "          [-4.7906e-02, -3.5212e-02, -4.5032e-04,  ...,  4.3327e-02,\n",
      "            1.6148e-02, -1.2152e-02],\n",
      "          [-4.5715e-02, -6.2070e-02, -3.5841e-02,  ...,  2.4605e-02,\n",
      "            1.3188e-02, -2.7954e-02],\n",
      "          [ 5.7729e-02, -2.7799e-02,  3.1234e-02,  ...,  5.2463e-02,\n",
      "           -3.2148e-02, -4.2097e-02]],\n",
      "\n",
      "         [[-1.0333e-02, -2.3696e-02, -2.6282e-02,  ..., -5.2756e-02,\n",
      "            8.7528e-03, -5.1173e-02],\n",
      "          [ 9.6520e-03, -3.2727e-02,  2.0300e-02,  ..., -4.2058e-02,\n",
      "           -5.6481e-02,  2.7221e-02],\n",
      "          [ 5.7128e-03,  3.4794e-06,  5.8048e-02,  ..., -6.1272e-02,\n",
      "            5.4420e-02,  4.3437e-02],\n",
      "          ...,\n",
      "          [ 4.7091e-02,  2.6201e-02, -2.9940e-02,  ..., -4.9110e-03,\n",
      "            2.1701e-02, -3.1145e-03],\n",
      "          [ 5.9355e-02, -4.4234e-02,  4.7401e-02,  ..., -2.4304e-02,\n",
      "           -3.4946e-02, -5.3896e-02],\n",
      "          [-2.3503e-02,  4.3517e-02, -5.5018e-02,  ...,  2.8621e-02,\n",
      "            2.5572e-02, -5.3688e-02]],\n",
      "\n",
      "         [[-3.9783e-02, -3.2745e-02,  6.1083e-02,  ..., -3.4462e-02,\n",
      "            3.8350e-02,  3.6203e-02],\n",
      "          [-6.3539e-02, -6.2097e-03, -3.9266e-02,  ...,  5.4492e-02,\n",
      "            1.7131e-02, -3.3424e-02],\n",
      "          [-4.0033e-02,  2.5065e-02,  1.1473e-02,  ...,  1.0979e-02,\n",
      "            5.4668e-03,  5.9434e-02],\n",
      "          ...,\n",
      "          [-5.2309e-03,  2.9318e-02, -5.5908e-02,  ..., -5.9374e-02,\n",
      "           -3.8090e-02,  4.0394e-02],\n",
      "          [ 6.0865e-02,  2.3053e-02, -2.1542e-02,  ..., -5.6607e-02,\n",
      "           -5.6317e-02, -9.3205e-03],\n",
      "          [ 5.4344e-02, -2.1348e-02, -6.5593e-03,  ..., -4.6291e-02,\n",
      "           -5.2988e-02, -2.0225e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7093e-02,  2.6420e-02, -4.5346e-03,  ..., -5.0939e-02,\n",
      "           -4.9958e-02, -5.9896e-02],\n",
      "          [-2.4529e-02,  2.8293e-02,  1.5583e-02,  ..., -6.9573e-03,\n",
      "            2.1100e-02,  4.7059e-02],\n",
      "          [-8.3806e-03, -5.2107e-03, -2.2323e-02,  ..., -3.8001e-02,\n",
      "           -3.6254e-02, -4.9667e-02],\n",
      "          ...,\n",
      "          [ 6.2323e-02, -7.7506e-03, -2.3967e-02,  ...,  2.4712e-02,\n",
      "           -1.2715e-02,  3.1980e-02],\n",
      "          [-1.1001e-02,  2.0305e-02,  2.5206e-02,  ..., -2.3704e-02,\n",
      "           -5.0415e-02, -3.6386e-02],\n",
      "          [-5.7308e-02, -1.1049e-02,  2.2163e-02,  ...,  1.4629e-02,\n",
      "            9.6830e-03, -1.3802e-02]],\n",
      "\n",
      "         [[ 5.5399e-02, -4.2209e-02,  5.3082e-02,  ...,  5.8725e-02,\n",
      "           -5.7669e-02,  3.9792e-03],\n",
      "          [-1.8487e-02, -4.5215e-02, -1.4121e-03,  ..., -7.0084e-03,\n",
      "           -2.5045e-02,  3.4417e-02],\n",
      "          [-3.5627e-02, -4.0954e-02,  5.1600e-02,  ..., -3.8084e-02,\n",
      "            2.5455e-02, -1.8854e-02],\n",
      "          ...,\n",
      "          [-7.9376e-03,  7.1257e-05, -1.3446e-03,  ..., -2.1662e-02,\n",
      "           -3.7313e-03,  2.6159e-02],\n",
      "          [ 6.2298e-02, -1.0631e-02, -2.4900e-02,  ..., -3.2327e-02,\n",
      "            5.8997e-02,  5.1922e-02],\n",
      "          [-2.7939e-02, -7.9518e-03, -5.3316e-02,  ..., -5.7531e-02,\n",
      "            3.9340e-02,  3.2393e-02]],\n",
      "\n",
      "         [[-1.4145e-02,  2.0295e-02, -5.6458e-02,  ..., -4.4363e-03,\n",
      "            4.1287e-02,  4.3851e-02],\n",
      "          [-6.5427e-03,  3.8202e-02,  5.7915e-02,  ...,  5.3093e-02,\n",
      "            1.9535e-02,  3.6766e-02],\n",
      "          [ 2.6843e-02,  5.4966e-02,  5.3400e-02,  ...,  4.5230e-02,\n",
      "           -3.8009e-02,  5.3401e-02],\n",
      "          ...,\n",
      "          [-1.2860e-03, -4.3106e-02,  2.2600e-02,  ..., -4.0185e-02,\n",
      "            5.8123e-02, -6.6141e-03],\n",
      "          [ 1.2281e-02,  1.8425e-02, -3.6458e-02,  ..., -6.6471e-03,\n",
      "            5.1150e-02,  5.6877e-02],\n",
      "          [-5.5580e-03,  3.2505e-02,  1.0450e-03,  ..., -2.2909e-02,\n",
      "            2.1200e-02,  6.2660e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0788e-02, -1.8973e-02, -4.1607e-02,  ..., -2.0639e-02,\n",
      "           -3.6469e-02,  2.3915e-02],\n",
      "          [-1.2896e-02,  3.9287e-02,  6.1767e-02,  ..., -5.0010e-03,\n",
      "           -3.5253e-02,  2.0405e-02],\n",
      "          [-2.4196e-02,  4.7719e-02,  2.7283e-02,  ...,  3.2490e-02,\n",
      "            5.9594e-02,  1.9683e-03],\n",
      "          ...,\n",
      "          [ 4.5003e-03, -3.8391e-02, -4.2822e-02,  ..., -4.4208e-02,\n",
      "           -5.6147e-02, -6.2648e-02],\n",
      "          [-2.5630e-03,  4.1629e-02, -3.1671e-02,  ...,  2.4670e-02,\n",
      "           -1.0783e-02,  5.9424e-02],\n",
      "          [-2.1829e-03, -4.5144e-02, -4.3219e-04,  ...,  2.0084e-02,\n",
      "           -1.9613e-02, -3.3887e-02]],\n",
      "\n",
      "         [[ 7.3665e-03, -6.3088e-02, -6.2689e-02,  ..., -5.5631e-02,\n",
      "            8.2323e-03, -5.5517e-02],\n",
      "          [-3.1355e-02, -5.0370e-03, -2.0182e-02,  ..., -3.5787e-02,\n",
      "           -1.0022e-02,  6.1914e-02],\n",
      "          [ 2.5526e-02,  2.1587e-02,  3.6490e-02,  ...,  4.6776e-02,\n",
      "            5.0954e-03,  4.2169e-02],\n",
      "          ...,\n",
      "          [ 1.6349e-03, -3.5615e-02, -5.0887e-02,  ...,  6.0995e-02,\n",
      "            1.5564e-02, -4.6850e-03],\n",
      "          [ 2.2353e-02, -2.3405e-03,  4.7531e-03,  ..., -5.3321e-02,\n",
      "           -2.5368e-02, -2.4780e-02],\n",
      "          [ 1.9064e-02, -3.6612e-02,  3.6862e-02,  ...,  3.9598e-02,\n",
      "           -6.0033e-02,  7.9068e-03]],\n",
      "\n",
      "         [[ 6.7519e-03,  1.6881e-02, -9.3166e-03,  ..., -4.3167e-02,\n",
      "           -1.0861e-02, -4.4970e-02],\n",
      "          [ 2.2866e-02, -3.6419e-02,  2.1638e-02,  ..., -7.0980e-03,\n",
      "           -1.2494e-02, -4.0195e-02],\n",
      "          [ 2.9191e-02, -5.4141e-02, -4.6249e-02,  ..., -1.6278e-02,\n",
      "            5.3861e-02,  3.0707e-02],\n",
      "          ...,\n",
      "          [-1.6678e-02,  1.1976e-02,  2.5636e-02,  ..., -5.7385e-02,\n",
      "           -1.3469e-02, -1.1760e-02],\n",
      "          [ 1.2158e-02,  6.0101e-02, -4.6726e-02,  ...,  8.7935e-03,\n",
      "            6.1452e-02,  6.2216e-02],\n",
      "          [ 3.1352e-02, -5.4101e-02,  4.4027e-02,  ...,  5.2850e-02,\n",
      "           -3.3567e-02,  5.3866e-03]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model_encoder.show_one_module_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # N, 1, 28, 28\n",
    "        # 32, 3, 224, 224\n",
    "        input_channels = 3              # number of channels of the input image\n",
    "        output_channels = 110           # ~= 224/2. Shape of the input image \n",
    "        kernel_size = 9\n",
    "        padding_val = 1\n",
    "        stride_val = 5\n",
    "\n",
    "        \n",
    "        output_channels_layer2 = output_channels*2+5\n",
    "\n",
    "        output_channels_layer3 = output_channels_layer2*2\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size, stride=stride_val, padding=padding_val),         # input image channels, output channels, kernel size (filter). Dimension rseult: -> N, 110, 44, 44\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels, output_channels_layer2, kernel_size, stride=stride_val, padding=padding_val), # -> N, 225, 8, 8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels_layer2, output_channels_layer3, 8) # -> N, 450, 1, 1\n",
    "        )\n",
    "        \n",
    "        # N , 450, 1, 1\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(output_channels_layer3, output_channels_layer2, 8),  # -> 32, 225, 8, 8\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(output_channels_layer2, output_channels, kernel_size, stride=stride_val, padding=padding_val, output_padding=2), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(output_channels, input_channels, kernel_size, stride=stride_val, padding=padding_val, output_padding=2), # N, 3, 224, 224\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    " \n",
    "# Note: nn.MaxPool2d -> use nn.MaxUnpool2d, or use different kernelsize, stride etc to compensate...\n",
    "# Input [-1, +1] -> use nn.Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=1e-3, \n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(110, 225, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(225, 450, kernel_size=(8, 8), stride=(1, 1))\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(450, 225, kernel_size=(8, 8), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): ConvTranspose2d(225, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1), output_padding=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(110, 3, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1), output_padding=(2, 2))\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(110, 225, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(225, 450, kernel_size=(8, 8), stride=(1, 1))\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(450, 225, kernel_size=(8, 8), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): ConvTranspose2d(225, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1), output_padding=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(110, 3, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1), output_padding=(2, 2))\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"../../../BottlesAnomalies_TFM/models/pytorchModels/PytorchModel_withCUDA\"\n",
    "# For loading the model \n",
    "model.load_state_dict(torch.load(filepath))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is:  0\n",
      "The weights are:  Parameter containing:\n",
      "tensor([[[[-1.6085e-25, -1.6363e-25, -1.6663e-25,  ..., -1.7430e-25,\n",
      "           -1.7557e-25, -1.7903e-25],\n",
      "          [-2.2771e-25, -2.5256e-25, -2.5323e-25,  ..., -2.6019e-25,\n",
      "           -2.5946e-25, -2.5337e-25],\n",
      "          [-2.5053e-25, -2.6664e-25, -2.5478e-25,  ..., -2.7490e-25,\n",
      "           -2.6799e-25, -2.6038e-25],\n",
      "          ...,\n",
      "          [-2.6943e-25, -2.8397e-25, -2.8483e-25,  ..., -3.0378e-25,\n",
      "           -2.9532e-25, -2.8298e-25],\n",
      "          [-2.8312e-25, -2.8671e-25, -2.8712e-25,  ..., -2.9985e-25,\n",
      "           -2.9239e-25, -2.9911e-25],\n",
      "          [-2.9684e-25, -2.9257e-25, -2.9676e-25,  ..., -3.0312e-25,\n",
      "           -3.0702e-25, -3.0488e-25]],\n",
      "\n",
      "         [[-1.6082e-25, -1.6399e-25, -1.6598e-25,  ..., -1.7378e-25,\n",
      "           -1.7550e-25, -1.7926e-25],\n",
      "          [-2.2830e-25, -2.5180e-25, -2.5322e-25,  ..., -2.6058e-25,\n",
      "           -2.5928e-25, -2.5301e-25],\n",
      "          [-2.5050e-25, -2.6661e-25, -2.5564e-25,  ..., -2.7503e-25,\n",
      "           -2.6771e-25, -2.5857e-25],\n",
      "          ...,\n",
      "          [-2.6872e-25, -2.8534e-25, -2.8414e-25,  ..., -3.0381e-25,\n",
      "           -2.9534e-25, -2.8295e-25],\n",
      "          [-2.8099e-25, -2.8834e-25, -2.8683e-25,  ..., -2.9919e-25,\n",
      "           -2.9242e-25, -2.9741e-25],\n",
      "          [-2.9452e-25, -2.9257e-25, -2.9678e-25,  ..., -3.0313e-25,\n",
      "           -3.0708e-25, -3.0669e-25]],\n",
      "\n",
      "         [[-1.6087e-25, -1.6460e-25, -1.6687e-25,  ..., -1.7385e-25,\n",
      "           -1.7635e-25, -1.7635e-25],\n",
      "          [-2.2634e-25, -2.5031e-25, -2.5209e-25,  ..., -2.5893e-25,\n",
      "           -2.5896e-25, -2.5337e-25],\n",
      "          [-2.5050e-25, -2.6661e-25, -2.5441e-25,  ..., -2.7445e-25,\n",
      "           -2.6501e-25, -2.6041e-25],\n",
      "          ...,\n",
      "          [-2.6946e-25, -2.8447e-25, -2.8356e-25,  ..., -3.0337e-25,\n",
      "           -2.9386e-25, -2.8199e-25],\n",
      "          [-2.8318e-25, -2.8844e-25, -2.8712e-25,  ..., -2.9845e-25,\n",
      "           -2.8878e-25, -2.9910e-25],\n",
      "          [-2.9603e-25, -2.9085e-25, -2.9577e-25,  ..., -3.0305e-25,\n",
      "           -3.0709e-25, -3.0806e-25]]],\n",
      "\n",
      "\n",
      "        [[[-1.0727e-09, -1.2467e-09, -1.2752e-09,  ..., -1.3815e-09,\n",
      "           -1.3804e-09, -1.4093e-09],\n",
      "          [-4.8281e-09, -5.7444e-09, -5.5169e-09,  ..., -6.1804e-09,\n",
      "           -5.9607e-09, -5.9956e-09],\n",
      "          [-4.8653e-09, -5.8955e-09, -5.7366e-09,  ..., -6.5313e-09,\n",
      "           -6.3610e-09, -6.3550e-09],\n",
      "          ...,\n",
      "          [-6.5471e-09, -7.7374e-09, -7.6077e-09,  ..., -8.3837e-09,\n",
      "           -8.0526e-09, -8.0958e-09],\n",
      "          [-6.6398e-09, -7.9600e-09, -7.7515e-09,  ..., -8.6601e-09,\n",
      "           -8.5860e-09, -8.3701e-09],\n",
      "          [-5.9810e-09, -6.8377e-09, -7.0700e-09,  ..., -7.4223e-09,\n",
      "           -7.6548e-09, -7.9500e-09]],\n",
      "\n",
      "         [[-1.0509e-09, -1.2568e-09, -1.2899e-09,  ..., -1.3348e-09,\n",
      "           -1.4215e-09, -1.3866e-09],\n",
      "          [-4.8179e-09, -5.6788e-09, -5.5128e-09,  ..., -6.1494e-09,\n",
      "           -6.0008e-09, -5.9550e-09],\n",
      "          [-4.8721e-09, -5.9222e-09, -5.7540e-09,  ..., -6.5813e-09,\n",
      "           -6.3536e-09, -6.3902e-09],\n",
      "          ...,\n",
      "          [-6.4751e-09, -7.8155e-09, -7.5744e-09,  ..., -8.1879e-09,\n",
      "           -8.0351e-09, -8.1304e-09],\n",
      "          [-6.6994e-09, -7.9453e-09, -7.7833e-09,  ..., -8.6029e-09,\n",
      "           -8.5038e-09, -8.3584e-09],\n",
      "          [-5.9722e-09, -6.8607e-09, -7.0555e-09,  ..., -7.4304e-09,\n",
      "           -7.5727e-09, -8.0404e-09]],\n",
      "\n",
      "         [[-1.0659e-09, -1.2485e-09, -1.2510e-09,  ..., -1.3357e-09,\n",
      "           -1.4051e-09, -1.4058e-09],\n",
      "          [-4.8855e-09, -5.7471e-09, -5.5161e-09,  ..., -6.1354e-09,\n",
      "           -5.9259e-09, -5.9551e-09],\n",
      "          [-4.8592e-09, -5.9811e-09, -5.8038e-09,  ..., -6.5657e-09,\n",
      "           -6.4136e-09, -6.4005e-09],\n",
      "          ...,\n",
      "          [-6.5056e-09, -7.7086e-09, -7.5397e-09,  ..., -8.4107e-09,\n",
      "           -8.0907e-09, -8.0406e-09],\n",
      "          [-6.5938e-09, -7.9014e-09, -7.7055e-09,  ..., -8.7724e-09,\n",
      "           -8.3818e-09, -8.4589e-09],\n",
      "          [-6.0150e-09, -6.8437e-09, -7.0120e-09,  ..., -7.4443e-09,\n",
      "           -7.6710e-09, -8.0442e-09]]],\n",
      "\n",
      "\n",
      "        [[[-2.6066e-27, -2.6440e-27, -4.9623e-27,  ..., -2.9732e-26,\n",
      "           -6.4868e-26, -1.0348e-25],\n",
      "          [-1.2778e-26, -1.9173e-26, -1.7339e-26,  ..., -1.7092e-25,\n",
      "           -1.4028e-25, -3.3008e-25],\n",
      "          [-4.4636e-26, -5.2706e-26, -5.7231e-26,  ..., -5.8360e-25,\n",
      "           -5.6028e-25, -7.4895e-25],\n",
      "          ...,\n",
      "          [-7.8231e-24, -1.2416e-23, -1.1949e-23,  ..., -5.6591e-23,\n",
      "           -5.4827e-23, -9.1408e-23],\n",
      "          [-1.9654e-23, -2.4449e-23, -2.4558e-23,  ..., -1.2964e-22,\n",
      "           -1.1230e-22, -1.4785e-22],\n",
      "          [-5.7975e-23, -5.4478e-23, -6.5906e-23,  ..., -2.1614e-22,\n",
      "           -2.4514e-22, -3.7824e-22]],\n",
      "\n",
      "         [[-2.5950e-27, -2.7446e-27, -4.9581e-27,  ..., -2.9773e-26,\n",
      "           -6.5088e-26, -1.0299e-25],\n",
      "          [-1.2759e-26, -2.1130e-26, -1.9126e-26,  ..., -1.6566e-25,\n",
      "           -1.4725e-25, -3.1577e-25],\n",
      "          [-4.8367e-26, -5.0795e-26, -5.7363e-26,  ..., -5.7905e-25,\n",
      "           -5.5476e-25, -7.7029e-25],\n",
      "          ...,\n",
      "          [-7.4026e-24, -1.2841e-23, -1.1904e-23,  ..., -5.7266e-23,\n",
      "           -5.4594e-23, -9.4092e-23],\n",
      "          [-2.0808e-23, -2.4563e-23, -2.4248e-23,  ..., -1.2943e-22,\n",
      "           -1.1207e-22, -1.4847e-22],\n",
      "          [-5.6620e-23, -5.4047e-23, -6.6297e-23,  ..., -2.1606e-22,\n",
      "           -2.3991e-22, -3.9226e-22]],\n",
      "\n",
      "         [[-2.5946e-27, -2.5487e-27, -4.9748e-27,  ..., -2.9873e-26,\n",
      "           -6.3779e-26, -1.0315e-25],\n",
      "          [-1.3256e-26, -2.0755e-26, -1.7552e-26,  ..., -1.6917e-25,\n",
      "           -1.4074e-25, -3.0949e-25],\n",
      "          [-4.4654e-26, -5.0879e-26, -5.3299e-26,  ..., -5.9428e-25,\n",
      "           -5.4137e-25, -7.4841e-25],\n",
      "          ...,\n",
      "          [-7.4026e-24, -1.2751e-23, -1.1883e-23,  ..., -5.6067e-23,\n",
      "           -5.7030e-23, -9.3715e-23],\n",
      "          [-2.0306e-23, -2.4804e-23, -2.5719e-23,  ..., -1.3773e-22,\n",
      "           -1.1201e-22, -1.4915e-22],\n",
      "          [-5.7827e-23, -5.5108e-23, -6.9021e-23,  ..., -2.2170e-22,\n",
      "           -2.3665e-22, -3.7539e-22]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0892e-15, -1.0755e-15, -1.1745e-15,  ..., -1.6665e-15,\n",
      "           -1.9733e-15, -2.0502e-15],\n",
      "          [-1.9186e-15, -2.4382e-15, -2.2253e-15,  ..., -3.7527e-15,\n",
      "           -3.3366e-15, -3.9453e-15],\n",
      "          [-2.5877e-15, -3.3475e-15, -3.1562e-15,  ..., -5.7012e-15,\n",
      "           -5.2689e-15, -6.4900e-15],\n",
      "          ...,\n",
      "          [-1.3207e-14, -1.7622e-14, -1.5809e-14,  ..., -2.8195e-14,\n",
      "           -2.7347e-14, -3.0253e-14],\n",
      "          [-1.6497e-14, -2.0825e-14, -2.1442e-14,  ..., -3.4082e-14,\n",
      "           -3.0572e-14, -3.7111e-14],\n",
      "          [-2.0667e-14, -2.2141e-14, -2.5486e-14,  ..., -3.2622e-14,\n",
      "           -3.3609e-14, -4.5112e-14]],\n",
      "\n",
      "         [[-1.0704e-15, -1.1032e-15, -1.2795e-15,  ..., -1.7938e-15,\n",
      "           -2.0689e-15, -2.2529e-15],\n",
      "          [-2.0834e-15, -2.4744e-15, -2.1400e-15,  ..., -4.0476e-15,\n",
      "           -3.5665e-15, -3.8881e-15],\n",
      "          [-2.7400e-15, -3.3307e-15, -3.2788e-15,  ..., -5.3991e-15,\n",
      "           -5.0400e-15, -5.9682e-15],\n",
      "          ...,\n",
      "          [-1.3981e-14, -1.6756e-14, -1.5794e-14,  ..., -2.7355e-14,\n",
      "           -2.5654e-14, -3.2614e-14],\n",
      "          [-1.7907e-14, -2.0794e-14, -2.0192e-14,  ..., -3.7257e-14,\n",
      "           -3.1322e-14, -4.0265e-14],\n",
      "          [-2.0721e-14, -2.2071e-14, -2.4578e-14,  ..., -3.1260e-14,\n",
      "           -3.4042e-14, -4.4122e-14]],\n",
      "\n",
      "         [[-1.0786e-15, -1.1027e-15, -1.2469e-15,  ..., -1.6288e-15,\n",
      "           -2.0097e-15, -2.1589e-15],\n",
      "          [-2.0894e-15, -2.4421e-15, -2.1969e-15,  ..., -4.0649e-15,\n",
      "           -3.6823e-15, -4.0193e-15],\n",
      "          [-2.7608e-15, -3.1727e-15, -3.3105e-15,  ..., -5.5460e-15,\n",
      "           -5.0488e-15, -5.9713e-15],\n",
      "          ...,\n",
      "          [-1.4092e-14, -1.7128e-14, -1.5707e-14,  ..., -2.7449e-14,\n",
      "           -2.5677e-14, -3.0583e-14],\n",
      "          [-1.6742e-14, -2.1301e-14, -2.0304e-14,  ..., -3.4113e-14,\n",
      "           -3.0600e-14, -3.8048e-14],\n",
      "          [-2.1367e-14, -2.3545e-14, -2.4599e-14,  ..., -3.2266e-14,\n",
      "           -3.5968e-14, -4.3812e-14]]],\n",
      "\n",
      "\n",
      "        [[[-5.8022e-18, -4.4677e-18, -1.2542e-18,  ..., -1.4901e-17,\n",
      "            6.1056e-19, -1.3658e-17],\n",
      "          [-1.1210e-17, -1.4656e-17, -1.6481e-17,  ...,  2.5842e-17,\n",
      "            4.0384e-17, -4.1534e-17],\n",
      "          [-9.4559e-18,  3.5878e-18, -2.9488e-17,  ..., -2.9329e-17,\n",
      "           -4.1060e-17,  1.2622e-17],\n",
      "          ...,\n",
      "          [ 1.8748e-17,  1.0423e-17, -1.0530e-17,  ...,  6.2136e-18,\n",
      "            4.7048e-17,  3.4976e-17],\n",
      "          [ 4.2745e-17, -1.0426e-17, -2.8715e-17,  ...,  6.9697e-18,\n",
      "            2.6408e-17,  3.6244e-17],\n",
      "          [-1.7846e-17, -5.9400e-18,  9.7196e-18,  ..., -4.6297e-17,\n",
      "            2.3538e-17, -5.7339e-17]],\n",
      "\n",
      "         [[-2.2320e-18, -1.1382e-17,  4.2988e-20,  ..., -4.1990e-18,\n",
      "           -3.6122e-18, -9.0522e-18],\n",
      "          [-4.3768e-18,  1.9451e-17, -2.2040e-17,  ..., -3.1115e-18,\n",
      "           -1.2360e-17, -6.2767e-18],\n",
      "          [-2.4579e-18, -3.2304e-18,  6.6907e-19,  ...,  2.7848e-17,\n",
      "           -7.1587e-18, -1.7974e-19],\n",
      "          ...,\n",
      "          [ 2.3492e-17, -2.7479e-17,  2.1706e-17,  ...,  1.7218e-17,\n",
      "            2.9264e-17, -5.8105e-17],\n",
      "          [-2.7788e-17, -4.0736e-17, -2.0841e-17,  ..., -1.4975e-17,\n",
      "            8.8980e-17,  2.0083e-17],\n",
      "          [ 5.6872e-18,  2.9835e-17,  7.6219e-18,  ..., -3.7881e-17,\n",
      "            1.4488e-17,  1.3103e-17]],\n",
      "\n",
      "         [[-1.3909e-18, -9.4286e-18, -1.3700e-18,  ..., -2.5793e-18,\n",
      "           -1.8565e-17, -2.2894e-18],\n",
      "          [-1.4254e-17,  1.8022e-18, -8.1017e-18,  ..., -1.7627e-17,\n",
      "            1.8601e-17,  4.0351e-18],\n",
      "          [ 4.8563e-18, -2.1903e-17,  1.6503e-17,  ...,  1.7239e-17,\n",
      "            9.7816e-18,  2.5088e-17],\n",
      "          ...,\n",
      "          [-2.4515e-17, -1.0033e-17,  3.1701e-17,  ...,  1.7329e-17,\n",
      "           -1.0639e-17,  1.0607e-17],\n",
      "          [-3.8673e-18, -3.4532e-17,  2.2965e-17,  ...,  1.8086e-17,\n",
      "            5.9549e-17, -3.9527e-17],\n",
      "          [-8.3614e-18, -2.4074e-17, -2.0948e-17,  ..., -4.6452e-18,\n",
      "           -4.8435e-17,  2.4690e-17]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0718e-05, -8.3037e-07, -5.1335e-04,  ...,  1.8310e-04,\n",
      "            3.3631e-04, -4.8450e-04],\n",
      "          [-3.4495e-04, -2.4594e-04,  3.5630e-05,  ..., -5.2527e-05,\n",
      "            1.7967e-04, -1.6849e-04],\n",
      "          [ 3.0651e-04,  1.5168e-04, -4.7015e-04,  ..., -4.3360e-04,\n",
      "            4.1539e-04,  3.6103e-04],\n",
      "          ...,\n",
      "          [ 2.0312e-05,  3.1917e-04, -1.7852e-04,  ..., -9.2287e-05,\n",
      "            3.7217e-04, -4.1951e-04],\n",
      "          [ 3.0430e-04,  1.8958e-04,  1.5201e-04,  ..., -3.7113e-04,\n",
      "            1.4041e-04, -3.7126e-04],\n",
      "          [ 3.6718e-04,  3.4368e-04,  3.8236e-04,  ..., -3.8414e-04,\n",
      "            3.3926e-04, -4.0066e-04]],\n",
      "\n",
      "         [[ 5.6445e-05, -3.2983e-04, -1.7767e-04,  ...,  4.5748e-04,\n",
      "           -2.4202e-05,  3.6023e-04],\n",
      "          [-9.5743e-05, -2.9503e-04,  2.6095e-04,  ..., -4.3510e-04,\n",
      "            3.4200e-04,  2.5826e-04],\n",
      "          [ 4.2053e-04,  3.8670e-04, -4.1432e-04,  ...,  2.3891e-05,\n",
      "           -4.4327e-04,  3.9357e-04],\n",
      "          ...,\n",
      "          [-3.6729e-04, -2.7417e-04,  3.9562e-04,  ...,  6.7195e-05,\n",
      "           -6.1869e-05,  2.4896e-04],\n",
      "          [-1.7703e-04,  4.8066e-04, -3.6675e-04,  ...,  1.7645e-04,\n",
      "           -2.6430e-04,  1.5876e-04],\n",
      "          [ 1.1486e-05, -4.6011e-04,  2.9508e-05,  ...,  2.1002e-04,\n",
      "           -2.4195e-04, -6.4697e-05]],\n",
      "\n",
      "         [[ 4.9076e-04, -3.0006e-04, -6.0800e-05,  ...,  4.5619e-04,\n",
      "            9.6466e-05, -2.8134e-04],\n",
      "          [ 6.4173e-05, -4.5140e-04,  3.4104e-04,  ...,  5.1249e-05,\n",
      "            2.4474e-04,  5.7795e-05],\n",
      "          [ 2.6079e-04, -1.5957e-04, -4.1118e-04,  ...,  3.2108e-04,\n",
      "            4.3956e-04,  2.6250e-04],\n",
      "          ...,\n",
      "          [ 1.0539e-04,  4.1401e-04,  3.0641e-05,  ..., -1.5906e-04,\n",
      "           -2.0489e-04, -2.5976e-04],\n",
      "          [ 2.6158e-04, -2.1948e-05,  2.8889e-04,  ..., -9.8925e-05,\n",
      "           -1.8603e-04,  9.2031e-05],\n",
      "          [ 1.0292e-04,  1.9290e-04,  1.8561e-04,  ...,  5.1059e-05,\n",
      "           -4.2191e-04,  2.9483e-04]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "i = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        if i == index:\n",
    "            print(\"i is: \", i)\n",
    "            print(\"The weights are: \", m.weight)\n",
    "        i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of layers that the loaded model has, is:  3\n"
     ]
    }
   ],
   "source": [
    "layers_weights_list = []\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        weights = m.weight\n",
    "        layers_weights_list.append(weights)\n",
    "print(\"The number of layers that the loaded model has, is: \", len(layers_weights_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the module's weight from one model to another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_latentSpace(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # N, 1, 28, 28\n",
    "        # 32, 3, 224, 224\n",
    "        input_channels = 3              # number of channels of the input image\n",
    "        output_channels = 110           # ~= 224/2. Shape of the input image \n",
    "        kernel_size = 9\n",
    "        padding_val = 1\n",
    "        stride_val = 5\n",
    "\n",
    "        \n",
    "        output_channels_layer2 = output_channels*2+5\n",
    "\n",
    "        output_channels_layer3 = output_channels_layer2*2\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size, stride=stride_val, padding=padding_val),         # input image channels, output channels, kernel size (filter). Dimension rseult: -> N, 110, 44, 44\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels, output_channels_layer2, kernel_size, stride=stride_val, padding=padding_val), # -> N, 225, 8, 8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels_layer2, output_channels_layer3, 8) # -> N, 450, 1, 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"This is the forward function\")\n",
    "        encoded = self.encoder(x)\n",
    "        return encoded\n",
    "    \n",
    "    def show_modules(self):\n",
    "        print(\"This is the show modules function\")\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            print(m)\n",
    "            print(\"i is: \", i)\n",
    "            print(\"print the next module\")\n",
    "            i = i +1\n",
    "            \n",
    "    def show_one_layer_weights(self, index):\n",
    "        print(\"This is the one layer show function\")\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if i == index:\n",
    "                    print(\"i is: \", i)\n",
    "                    print(\"The weights are: \", m.weight)\n",
    "                i = i +1\n",
    "    \n",
    "    def update_weights(self):\n",
    "        print(\"updating weights function\")\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight = layers_weights_list[i]\n",
    "                i = i +1\n",
    "\n",
    "                                        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder_latentSpace(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(110, 225, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(225, 450, kernel_size=(8, 8), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_encoder = Autoencoder_latentSpace()\n",
    "model_encoder.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the one layer show function\n",
      "i is:  0\n",
      "The weights are:  Parameter containing:\n",
      "tensor([[[[-5.1781e-02, -4.8670e-02, -2.4642e-02,  ..., -1.2781e-02,\n",
      "           -2.0488e-02, -5.6888e-02],\n",
      "          [-5.0737e-02, -4.4106e-02,  2.3893e-02,  ..., -2.1544e-02,\n",
      "           -3.9290e-02, -2.4504e-02],\n",
      "          [-4.4710e-02, -5.5710e-02, -4.2813e-03,  ..., -4.3810e-02,\n",
      "           -1.9410e-02,  1.8635e-02],\n",
      "          ...,\n",
      "          [ 4.4297e-02,  1.7873e-02, -1.6774e-02,  ..., -3.1901e-03,\n",
      "            8.0985e-03,  1.2061e-02],\n",
      "          [ 5.7042e-03, -2.7436e-02, -1.7318e-02,  ..., -7.8742e-03,\n",
      "           -2.8842e-02,  3.1161e-02],\n",
      "          [ 3.4395e-02,  6.4042e-02, -5.8162e-03,  ...,  6.0890e-02,\n",
      "            5.3181e-02, -3.0882e-02]],\n",
      "\n",
      "         [[-1.1184e-02, -1.1377e-02, -2.7410e-02,  ...,  2.4217e-02,\n",
      "            3.1656e-02, -2.9425e-02],\n",
      "          [-4.3129e-02,  3.8920e-02, -1.4965e-02,  ...,  8.4295e-03,\n",
      "           -1.4563e-02,  5.4973e-02],\n",
      "          [-1.7095e-02,  6.4369e-03,  3.0061e-02,  ...,  3.2843e-02,\n",
      "            2.4625e-02,  1.9071e-02],\n",
      "          ...,\n",
      "          [-4.9717e-02,  6.3635e-02,  3.2458e-02,  ..., -2.6535e-02,\n",
      "           -5.8138e-02,  7.0299e-03],\n",
      "          [ 1.8555e-02, -5.0145e-02,  1.2795e-02,  ...,  4.0086e-02,\n",
      "            3.6091e-03, -2.2988e-02],\n",
      "          [-5.8840e-02,  1.6686e-02,  3.8212e-02,  ...,  1.0220e-02,\n",
      "            4.5651e-02, -3.1946e-02]],\n",
      "\n",
      "         [[ 1.1109e-02,  4.3957e-02,  1.7853e-02,  ...,  4.6716e-03,\n",
      "           -4.0372e-02,  3.8457e-02],\n",
      "          [-5.6789e-02, -2.7311e-02,  1.5552e-02,  ...,  1.6696e-02,\n",
      "            2.9268e-02,  3.9785e-02],\n",
      "          [ 8.6731e-03,  3.3736e-02,  3.3667e-02,  ...,  1.5326e-02,\n",
      "            1.7948e-02,  5.1395e-03],\n",
      "          ...,\n",
      "          [ 5.1886e-02, -6.3704e-03,  4.1807e-02,  ..., -8.4517e-03,\n",
      "           -4.3956e-02, -4.8593e-02],\n",
      "          [-1.1128e-02,  4.3771e-03, -1.9354e-02,  ..., -2.9833e-02,\n",
      "           -3.3587e-02,  4.9455e-02],\n",
      "          [ 6.6575e-03,  4.1478e-02, -3.0375e-02,  ..., -4.0910e-02,\n",
      "            3.9306e-02,  4.0467e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.6053e-02,  6.7565e-03,  2.3370e-02,  ...,  5.7115e-02,\n",
      "            5.9595e-02, -2.3469e-02],\n",
      "          [-5.4714e-03, -3.5416e-02,  4.0824e-02,  ...,  2.3863e-03,\n",
      "           -2.3505e-02, -3.7207e-02],\n",
      "          [ 1.6319e-02, -4.2736e-02,  2.0188e-02,  ..., -5.4576e-02,\n",
      "            5.2405e-02,  5.2457e-02],\n",
      "          ...,\n",
      "          [-9.2734e-03,  1.9313e-02, -3.2902e-02,  ..., -6.3360e-03,\n",
      "            1.6037e-02, -4.0238e-02],\n",
      "          [ 3.1590e-02,  8.2763e-03, -3.4229e-02,  ..., -2.6161e-02,\n",
      "            3.6457e-02, -5.1516e-02],\n",
      "          [-2.8633e-03,  2.5575e-02,  3.2128e-02,  ...,  5.4376e-02,\n",
      "           -7.8632e-03,  1.7307e-02]],\n",
      "\n",
      "         [[ 5.7278e-02,  5.1007e-02,  2.2189e-02,  ...,  3.5876e-02,\n",
      "           -1.4237e-02, -2.4747e-02],\n",
      "          [ 4.6162e-02,  3.7494e-03, -6.3317e-02,  ..., -6.6865e-03,\n",
      "           -3.6823e-02,  4.6276e-02],\n",
      "          [ 9.3769e-03,  4.2434e-02,  4.1016e-04,  ...,  5.7879e-03,\n",
      "            3.0864e-03, -1.7795e-02],\n",
      "          ...,\n",
      "          [-3.2667e-02,  5.0697e-02, -2.3264e-02,  ...,  2.0817e-02,\n",
      "           -4.7104e-02,  6.2878e-02],\n",
      "          [-2.1680e-02,  2.5190e-02, -4.9727e-02,  ...,  5.5901e-02,\n",
      "            3.1335e-02,  3.5845e-02],\n",
      "          [ 3.8434e-02,  3.1500e-02,  2.2759e-02,  ..., -6.1200e-02,\n",
      "           -4.8766e-02,  3.0635e-03]],\n",
      "\n",
      "         [[-2.8817e-02,  5.9897e-02, -5.6289e-02,  ..., -3.1698e-02,\n",
      "            5.9406e-04, -1.1338e-02],\n",
      "          [ 2.8942e-02,  6.0745e-03, -4.9476e-02,  ...,  2.6848e-02,\n",
      "           -4.9475e-02,  3.3648e-02],\n",
      "          [ 5.0701e-02,  2.8973e-02,  4.8070e-02,  ..., -1.6840e-02,\n",
      "           -3.5233e-03, -9.5098e-03],\n",
      "          ...,\n",
      "          [ 4.1168e-02, -3.1445e-02,  3.8896e-02,  ...,  4.8112e-02,\n",
      "            3.6674e-02,  6.3924e-02],\n",
      "          [-4.7458e-02, -5.4128e-02,  4.7243e-02,  ...,  2.9442e-02,\n",
      "           -5.1855e-02,  4.9078e-02],\n",
      "          [ 3.0377e-03, -4.8738e-02,  3.2964e-03,  ..., -2.7636e-02,\n",
      "           -5.6967e-03, -2.1464e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5628e-02,  3.3448e-02, -5.0787e-02,  ...,  1.1495e-02,\n",
      "            2.9918e-04,  3.2868e-02],\n",
      "          [-5.4321e-02,  3.1596e-02,  3.2573e-02,  ..., -5.3040e-02,\n",
      "           -5.3628e-02, -3.8986e-02],\n",
      "          [-1.4428e-03, -6.1846e-02,  4.9070e-02,  ...,  4.2308e-02,\n",
      "           -4.3966e-02,  4.4326e-02],\n",
      "          ...,\n",
      "          [-6.0867e-02,  3.6752e-02, -3.1306e-02,  ...,  2.5138e-02,\n",
      "           -1.1690e-02, -2.9617e-02],\n",
      "          [-4.2883e-02, -5.8392e-03, -3.3106e-02,  ..., -9.2398e-03,\n",
      "           -6.1355e-02,  2.3299e-02],\n",
      "          [-1.1598e-02,  5.9915e-02,  7.7999e-04,  ...,  2.6295e-02,\n",
      "            2.1968e-02,  2.0490e-02]],\n",
      "\n",
      "         [[ 3.5581e-02, -4.8270e-03,  5.1511e-03,  ...,  4.8288e-02,\n",
      "            5.5852e-02, -4.3319e-02],\n",
      "          [-6.5047e-03,  9.4045e-04, -4.9128e-02,  ..., -3.5829e-03,\n",
      "           -5.4136e-02, -5.1749e-02],\n",
      "          [-1.1157e-02,  7.5238e-03,  4.6026e-02,  ..., -5.8662e-02,\n",
      "            3.0582e-02, -9.1853e-03],\n",
      "          ...,\n",
      "          [ 5.2859e-02, -1.4813e-02, -5.1370e-04,  ..., -3.9842e-02,\n",
      "            1.0322e-02,  4.5386e-02],\n",
      "          [-5.8232e-02, -6.6763e-03, -3.2660e-03,  ..., -3.5300e-02,\n",
      "           -5.6004e-02, -6.3942e-02],\n",
      "          [ 1.7954e-02, -2.4909e-02, -3.2783e-02,  ..., -5.3920e-02,\n",
      "            4.5621e-02, -4.5619e-02]],\n",
      "\n",
      "         [[-4.1966e-02, -1.7177e-02,  3.4811e-02,  ...,  3.9411e-02,\n",
      "           -5.3701e-02,  6.1832e-02],\n",
      "          [ 6.0118e-02, -5.4639e-02, -5.5096e-02,  ...,  6.2762e-02,\n",
      "            5.0342e-02, -6.2268e-02],\n",
      "          [-5.5739e-02,  5.1716e-02,  1.2476e-02,  ..., -1.2928e-03,\n",
      "            8.2263e-03,  5.5775e-03],\n",
      "          ...,\n",
      "          [ 6.3013e-02,  3.2967e-02,  1.4837e-02,  ..., -2.1302e-02,\n",
      "           -8.2113e-03, -9.0217e-03],\n",
      "          [ 2.5498e-02,  3.5262e-03,  5.6530e-02,  ..., -3.4471e-02,\n",
      "           -5.7209e-02, -3.4359e-02],\n",
      "          [ 3.9866e-03, -3.4175e-02, -1.1101e-02,  ..., -5.4599e-02,\n",
      "            1.1573e-02,  5.3929e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.1148e-02, -4.1578e-02,  3.9656e-02,  ..., -3.6163e-02,\n",
      "            4.6560e-02,  5.2050e-03],\n",
      "          [-6.5286e-04, -2.6196e-02,  3.8660e-02,  ...,  1.7566e-02,\n",
      "           -1.8555e-02, -1.7703e-02],\n",
      "          [ 2.9372e-02,  1.6877e-02, -6.3103e-03,  ...,  2.2499e-02,\n",
      "           -5.7994e-02,  2.4673e-02],\n",
      "          ...,\n",
      "          [-2.2503e-02, -6.1735e-02, -3.7166e-02,  ..., -1.9619e-02,\n",
      "            3.6700e-02, -3.3328e-02],\n",
      "          [ 2.3404e-02, -3.8184e-03,  4.7809e-02,  ..., -4.6606e-02,\n",
      "           -1.3525e-02, -2.3045e-04],\n",
      "          [ 3.4613e-02,  4.3363e-02,  4.3614e-02,  ...,  2.7357e-02,\n",
      "           -2.1680e-02, -7.5562e-04]],\n",
      "\n",
      "         [[ 4.8806e-02,  4.9560e-02, -5.4654e-02,  ..., -5.8969e-02,\n",
      "           -1.1264e-03, -3.6740e-02],\n",
      "          [-6.2215e-02, -5.5699e-02,  2.9931e-02,  ..., -3.6894e-02,\n",
      "           -3.5872e-02,  6.1154e-02],\n",
      "          [-4.3068e-02, -2.7277e-02,  2.5138e-02,  ...,  1.0372e-02,\n",
      "           -1.9635e-02,  3.1070e-03],\n",
      "          ...,\n",
      "          [-6.6402e-03, -5.7818e-02, -1.6326e-02,  ...,  5.4626e-02,\n",
      "            4.7912e-02,  2.0494e-02],\n",
      "          [ 3.7073e-02,  4.5567e-02, -4.7901e-02,  ...,  3.9899e-03,\n",
      "            5.7669e-02, -3.3094e-03],\n",
      "          [-6.2011e-02, -3.8220e-02,  4.6936e-02,  ..., -8.8309e-03,\n",
      "           -4.6254e-02,  6.2667e-02]],\n",
      "\n",
      "         [[ 3.9227e-02, -5.0671e-02, -2.1893e-02,  ...,  1.5906e-02,\n",
      "            1.9287e-02, -4.6673e-02],\n",
      "          [-2.9737e-02, -9.6634e-03,  5.8638e-02,  ..., -1.6932e-02,\n",
      "           -4.5944e-02,  2.7026e-02],\n",
      "          [-2.8182e-03, -6.1934e-02,  4.2580e-02,  ..., -4.1725e-02,\n",
      "            4.7066e-03, -5.2069e-02],\n",
      "          ...,\n",
      "          [-3.2619e-02, -4.7296e-02,  2.3864e-02,  ...,  1.1885e-03,\n",
      "            6.5331e-03,  1.7426e-02],\n",
      "          [ 3.2378e-02, -1.5689e-02, -2.5460e-02,  ...,  3.5053e-02,\n",
      "            2.8886e-02, -4.9553e-02],\n",
      "          [ 1.0593e-03, -1.6654e-02, -4.7358e-02,  ..., -5.0783e-02,\n",
      "            3.0542e-02, -6.3349e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8975e-04,  8.6846e-03, -3.9891e-02,  ...,  6.1816e-02,\n",
      "            3.8867e-02,  1.8062e-02],\n",
      "          [-2.1840e-02, -3.5364e-02, -4.0159e-02,  ...,  1.2380e-02,\n",
      "           -4.3867e-02, -2.6823e-02],\n",
      "          [ 2.4760e-02,  1.7468e-02,  3.9679e-02,  ..., -3.3774e-02,\n",
      "            2.4796e-02, -2.6764e-02],\n",
      "          ...,\n",
      "          [ 6.3210e-02,  9.7287e-04,  4.7523e-02,  ..., -3.7832e-02,\n",
      "            3.0333e-02,  2.0104e-02],\n",
      "          [-2.1253e-02, -3.4004e-02, -2.8004e-02,  ..., -2.5410e-02,\n",
      "            1.9856e-02, -1.5078e-02],\n",
      "          [ 3.8335e-02,  3.5379e-02, -3.2127e-02,  ...,  9.8321e-03,\n",
      "            1.2268e-02, -2.9785e-02]],\n",
      "\n",
      "         [[-1.5243e-02,  6.0243e-03,  2.2715e-03,  ...,  5.7869e-02,\n",
      "            1.0373e-02, -4.3844e-02],\n",
      "          [-5.5179e-02,  5.9109e-02,  3.7257e-02,  ..., -5.5303e-02,\n",
      "           -5.5108e-02,  5.7132e-02],\n",
      "          [ 5.4296e-02, -3.7844e-02, -3.4301e-02,  ..., -2.7016e-02,\n",
      "            3.1742e-02, -3.4819e-02],\n",
      "          ...,\n",
      "          [ 5.2185e-02, -5.0140e-02, -4.3149e-02,  ...,  5.4757e-02,\n",
      "           -9.7873e-03, -1.0674e-02],\n",
      "          [ 1.1017e-02, -4.1898e-02, -1.7128e-02,  ...,  4.3173e-02,\n",
      "            6.4578e-03, -5.0404e-02],\n",
      "          [-1.1719e-02,  4.2543e-02,  8.8974e-03,  ...,  4.9836e-02,\n",
      "            2.8419e-02, -2.0397e-03]],\n",
      "\n",
      "         [[-1.0713e-02, -1.5411e-02,  6.3372e-02,  ..., -6.4438e-03,\n",
      "            4.8136e-02,  3.5848e-02],\n",
      "          [-7.3216e-03,  4.4608e-02,  1.8245e-02,  ..., -2.7932e-02,\n",
      "            5.3820e-02,  1.3268e-02],\n",
      "          [ 4.7344e-02,  3.1176e-02,  5.1360e-02,  ..., -1.1290e-02,\n",
      "            2.6709e-02,  6.4472e-03],\n",
      "          ...,\n",
      "          [ 6.2681e-02, -3.6524e-02,  3.0580e-02,  ...,  1.4601e-03,\n",
      "           -5.5592e-02, -2.6201e-02],\n",
      "          [-4.6864e-02, -4.3639e-02,  4.1165e-02,  ...,  5.3664e-02,\n",
      "            4.9297e-03,  2.2101e-02],\n",
      "          [-5.3510e-02,  4.1199e-02, -4.1397e-02,  ..., -1.0146e-02,\n",
      "            3.5279e-02, -1.2282e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1073e-02,  4.5022e-04, -5.6436e-02,  ...,  3.2279e-02,\n",
      "            4.0018e-02,  4.0639e-02],\n",
      "          [-2.5930e-02, -4.0569e-02,  5.9237e-02,  ...,  3.4892e-02,\n",
      "            1.5275e-02, -3.2933e-02],\n",
      "          [ 6.0456e-02,  2.6802e-02,  3.9011e-02,  ..., -7.2945e-03,\n",
      "            2.8684e-02,  9.4328e-03],\n",
      "          ...,\n",
      "          [-4.9982e-02,  8.1947e-03, -5.9949e-02,  ..., -3.2661e-02,\n",
      "           -5.0448e-02, -5.1357e-02],\n",
      "          [ 2.8025e-02, -4.6511e-03,  2.5593e-02,  ..., -1.2796e-02,\n",
      "            5.7031e-02,  4.1437e-02],\n",
      "          [ 2.8540e-02,  2.9332e-02, -2.0952e-02,  ...,  5.6648e-02,\n",
      "            6.1524e-02,  1.5039e-02]],\n",
      "\n",
      "         [[-3.6391e-02, -5.9705e-03, -6.2547e-02,  ...,  4.0600e-02,\n",
      "           -3.6505e-02,  3.8781e-02],\n",
      "          [-4.9663e-02,  4.4647e-02,  2.5590e-02,  ...,  1.8637e-02,\n",
      "            1.2380e-02,  6.1958e-02],\n",
      "          [-6.3839e-02,  1.9517e-02, -1.8027e-02,  ..., -2.3914e-02,\n",
      "            8.4338e-03, -5.7580e-02],\n",
      "          ...,\n",
      "          [ 5.6524e-02,  4.5127e-02, -4.9485e-02,  ...,  1.2602e-03,\n",
      "           -4.8720e-02, -6.2602e-03],\n",
      "          [-1.3067e-04,  2.2098e-03,  1.3946e-02,  ...,  2.6133e-02,\n",
      "            6.0118e-02, -1.5872e-02],\n",
      "          [-2.2551e-02, -3.7732e-02, -5.8835e-02,  ..., -5.9756e-02,\n",
      "            6.3043e-02,  4.2109e-02]],\n",
      "\n",
      "         [[ 2.2829e-02, -4.6323e-02,  1.8023e-02,  ..., -1.4978e-02,\n",
      "           -3.7201e-02, -6.2519e-02],\n",
      "          [-4.6350e-02, -2.4901e-02, -1.6447e-04,  ...,  2.0736e-02,\n",
      "           -1.0117e-02,  4.8222e-04],\n",
      "          [ 5.7037e-02, -4.0313e-02, -1.8342e-02,  ...,  5.6734e-02,\n",
      "            4.2976e-03,  1.8747e-02],\n",
      "          ...,\n",
      "          [-6.7398e-05, -1.0013e-02, -2.9049e-02,  ..., -4.2673e-02,\n",
      "           -3.9986e-02, -3.6762e-02],\n",
      "          [ 9.5766e-03, -5.7237e-02,  4.8356e-02,  ...,  4.2699e-02,\n",
      "           -6.3723e-02,  4.2079e-02],\n",
      "          [-5.9945e-02,  5.0946e-02, -2.9141e-02,  ..., -3.9721e-02,\n",
      "           -2.2814e-02, -1.3513e-02]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model_encoder.show_one_layer_weights(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating weights function\n"
     ]
    }
   ],
   "source": [
    "model_encoder.update_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the one layer show function\n",
      "i is:  0\n",
      "The weights are:  Parameter containing:\n",
      "tensor([[[[-1.6085e-25, -1.6363e-25, -1.6663e-25,  ..., -1.7430e-25,\n",
      "           -1.7557e-25, -1.7903e-25],\n",
      "          [-2.2771e-25, -2.5256e-25, -2.5323e-25,  ..., -2.6019e-25,\n",
      "           -2.5946e-25, -2.5337e-25],\n",
      "          [-2.5053e-25, -2.6664e-25, -2.5478e-25,  ..., -2.7490e-25,\n",
      "           -2.6799e-25, -2.6038e-25],\n",
      "          ...,\n",
      "          [-2.6943e-25, -2.8397e-25, -2.8483e-25,  ..., -3.0378e-25,\n",
      "           -2.9532e-25, -2.8298e-25],\n",
      "          [-2.8312e-25, -2.8671e-25, -2.8712e-25,  ..., -2.9985e-25,\n",
      "           -2.9239e-25, -2.9911e-25],\n",
      "          [-2.9684e-25, -2.9257e-25, -2.9676e-25,  ..., -3.0312e-25,\n",
      "           -3.0702e-25, -3.0488e-25]],\n",
      "\n",
      "         [[-1.6082e-25, -1.6399e-25, -1.6598e-25,  ..., -1.7378e-25,\n",
      "           -1.7550e-25, -1.7926e-25],\n",
      "          [-2.2830e-25, -2.5180e-25, -2.5322e-25,  ..., -2.6058e-25,\n",
      "           -2.5928e-25, -2.5301e-25],\n",
      "          [-2.5050e-25, -2.6661e-25, -2.5564e-25,  ..., -2.7503e-25,\n",
      "           -2.6771e-25, -2.5857e-25],\n",
      "          ...,\n",
      "          [-2.6872e-25, -2.8534e-25, -2.8414e-25,  ..., -3.0381e-25,\n",
      "           -2.9534e-25, -2.8295e-25],\n",
      "          [-2.8099e-25, -2.8834e-25, -2.8683e-25,  ..., -2.9919e-25,\n",
      "           -2.9242e-25, -2.9741e-25],\n",
      "          [-2.9452e-25, -2.9257e-25, -2.9678e-25,  ..., -3.0313e-25,\n",
      "           -3.0708e-25, -3.0669e-25]],\n",
      "\n",
      "         [[-1.6087e-25, -1.6460e-25, -1.6687e-25,  ..., -1.7385e-25,\n",
      "           -1.7635e-25, -1.7635e-25],\n",
      "          [-2.2634e-25, -2.5031e-25, -2.5209e-25,  ..., -2.5893e-25,\n",
      "           -2.5896e-25, -2.5337e-25],\n",
      "          [-2.5050e-25, -2.6661e-25, -2.5441e-25,  ..., -2.7445e-25,\n",
      "           -2.6501e-25, -2.6041e-25],\n",
      "          ...,\n",
      "          [-2.6946e-25, -2.8447e-25, -2.8356e-25,  ..., -3.0337e-25,\n",
      "           -2.9386e-25, -2.8199e-25],\n",
      "          [-2.8318e-25, -2.8844e-25, -2.8712e-25,  ..., -2.9845e-25,\n",
      "           -2.8878e-25, -2.9910e-25],\n",
      "          [-2.9603e-25, -2.9085e-25, -2.9577e-25,  ..., -3.0305e-25,\n",
      "           -3.0709e-25, -3.0806e-25]]],\n",
      "\n",
      "\n",
      "        [[[-1.0727e-09, -1.2467e-09, -1.2752e-09,  ..., -1.3815e-09,\n",
      "           -1.3804e-09, -1.4093e-09],\n",
      "          [-4.8281e-09, -5.7444e-09, -5.5169e-09,  ..., -6.1804e-09,\n",
      "           -5.9607e-09, -5.9956e-09],\n",
      "          [-4.8653e-09, -5.8955e-09, -5.7366e-09,  ..., -6.5313e-09,\n",
      "           -6.3610e-09, -6.3550e-09],\n",
      "          ...,\n",
      "          [-6.5471e-09, -7.7374e-09, -7.6077e-09,  ..., -8.3837e-09,\n",
      "           -8.0526e-09, -8.0958e-09],\n",
      "          [-6.6398e-09, -7.9600e-09, -7.7515e-09,  ..., -8.6601e-09,\n",
      "           -8.5860e-09, -8.3701e-09],\n",
      "          [-5.9810e-09, -6.8377e-09, -7.0700e-09,  ..., -7.4223e-09,\n",
      "           -7.6548e-09, -7.9500e-09]],\n",
      "\n",
      "         [[-1.0509e-09, -1.2568e-09, -1.2899e-09,  ..., -1.3348e-09,\n",
      "           -1.4215e-09, -1.3866e-09],\n",
      "          [-4.8179e-09, -5.6788e-09, -5.5128e-09,  ..., -6.1494e-09,\n",
      "           -6.0008e-09, -5.9550e-09],\n",
      "          [-4.8721e-09, -5.9222e-09, -5.7540e-09,  ..., -6.5813e-09,\n",
      "           -6.3536e-09, -6.3902e-09],\n",
      "          ...,\n",
      "          [-6.4751e-09, -7.8155e-09, -7.5744e-09,  ..., -8.1879e-09,\n",
      "           -8.0351e-09, -8.1304e-09],\n",
      "          [-6.6994e-09, -7.9453e-09, -7.7833e-09,  ..., -8.6029e-09,\n",
      "           -8.5038e-09, -8.3584e-09],\n",
      "          [-5.9722e-09, -6.8607e-09, -7.0555e-09,  ..., -7.4304e-09,\n",
      "           -7.5727e-09, -8.0404e-09]],\n",
      "\n",
      "         [[-1.0659e-09, -1.2485e-09, -1.2510e-09,  ..., -1.3357e-09,\n",
      "           -1.4051e-09, -1.4058e-09],\n",
      "          [-4.8855e-09, -5.7471e-09, -5.5161e-09,  ..., -6.1354e-09,\n",
      "           -5.9259e-09, -5.9551e-09],\n",
      "          [-4.8592e-09, -5.9811e-09, -5.8038e-09,  ..., -6.5657e-09,\n",
      "           -6.4136e-09, -6.4005e-09],\n",
      "          ...,\n",
      "          [-6.5056e-09, -7.7086e-09, -7.5397e-09,  ..., -8.4107e-09,\n",
      "           -8.0907e-09, -8.0406e-09],\n",
      "          [-6.5938e-09, -7.9014e-09, -7.7055e-09,  ..., -8.7724e-09,\n",
      "           -8.3818e-09, -8.4589e-09],\n",
      "          [-6.0150e-09, -6.8437e-09, -7.0120e-09,  ..., -7.4443e-09,\n",
      "           -7.6710e-09, -8.0442e-09]]],\n",
      "\n",
      "\n",
      "        [[[-2.6066e-27, -2.6440e-27, -4.9623e-27,  ..., -2.9732e-26,\n",
      "           -6.4868e-26, -1.0348e-25],\n",
      "          [-1.2778e-26, -1.9173e-26, -1.7339e-26,  ..., -1.7092e-25,\n",
      "           -1.4028e-25, -3.3008e-25],\n",
      "          [-4.4636e-26, -5.2706e-26, -5.7231e-26,  ..., -5.8360e-25,\n",
      "           -5.6028e-25, -7.4895e-25],\n",
      "          ...,\n",
      "          [-7.8231e-24, -1.2416e-23, -1.1949e-23,  ..., -5.6591e-23,\n",
      "           -5.4827e-23, -9.1408e-23],\n",
      "          [-1.9654e-23, -2.4449e-23, -2.4558e-23,  ..., -1.2964e-22,\n",
      "           -1.1230e-22, -1.4785e-22],\n",
      "          [-5.7975e-23, -5.4478e-23, -6.5906e-23,  ..., -2.1614e-22,\n",
      "           -2.4514e-22, -3.7824e-22]],\n",
      "\n",
      "         [[-2.5950e-27, -2.7446e-27, -4.9581e-27,  ..., -2.9773e-26,\n",
      "           -6.5088e-26, -1.0299e-25],\n",
      "          [-1.2759e-26, -2.1130e-26, -1.9126e-26,  ..., -1.6566e-25,\n",
      "           -1.4725e-25, -3.1577e-25],\n",
      "          [-4.8367e-26, -5.0795e-26, -5.7363e-26,  ..., -5.7905e-25,\n",
      "           -5.5476e-25, -7.7029e-25],\n",
      "          ...,\n",
      "          [-7.4026e-24, -1.2841e-23, -1.1904e-23,  ..., -5.7266e-23,\n",
      "           -5.4594e-23, -9.4092e-23],\n",
      "          [-2.0808e-23, -2.4563e-23, -2.4248e-23,  ..., -1.2943e-22,\n",
      "           -1.1207e-22, -1.4847e-22],\n",
      "          [-5.6620e-23, -5.4047e-23, -6.6297e-23,  ..., -2.1606e-22,\n",
      "           -2.3991e-22, -3.9226e-22]],\n",
      "\n",
      "         [[-2.5946e-27, -2.5487e-27, -4.9748e-27,  ..., -2.9873e-26,\n",
      "           -6.3779e-26, -1.0315e-25],\n",
      "          [-1.3256e-26, -2.0755e-26, -1.7552e-26,  ..., -1.6917e-25,\n",
      "           -1.4074e-25, -3.0949e-25],\n",
      "          [-4.4654e-26, -5.0879e-26, -5.3299e-26,  ..., -5.9428e-25,\n",
      "           -5.4137e-25, -7.4841e-25],\n",
      "          ...,\n",
      "          [-7.4026e-24, -1.2751e-23, -1.1883e-23,  ..., -5.6067e-23,\n",
      "           -5.7030e-23, -9.3715e-23],\n",
      "          [-2.0306e-23, -2.4804e-23, -2.5719e-23,  ..., -1.3773e-22,\n",
      "           -1.1201e-22, -1.4915e-22],\n",
      "          [-5.7827e-23, -5.5108e-23, -6.9021e-23,  ..., -2.2170e-22,\n",
      "           -2.3665e-22, -3.7539e-22]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0892e-15, -1.0755e-15, -1.1745e-15,  ..., -1.6665e-15,\n",
      "           -1.9733e-15, -2.0502e-15],\n",
      "          [-1.9186e-15, -2.4382e-15, -2.2253e-15,  ..., -3.7527e-15,\n",
      "           -3.3366e-15, -3.9453e-15],\n",
      "          [-2.5877e-15, -3.3475e-15, -3.1562e-15,  ..., -5.7012e-15,\n",
      "           -5.2689e-15, -6.4900e-15],\n",
      "          ...,\n",
      "          [-1.3207e-14, -1.7622e-14, -1.5809e-14,  ..., -2.8195e-14,\n",
      "           -2.7347e-14, -3.0253e-14],\n",
      "          [-1.6497e-14, -2.0825e-14, -2.1442e-14,  ..., -3.4082e-14,\n",
      "           -3.0572e-14, -3.7111e-14],\n",
      "          [-2.0667e-14, -2.2141e-14, -2.5486e-14,  ..., -3.2622e-14,\n",
      "           -3.3609e-14, -4.5112e-14]],\n",
      "\n",
      "         [[-1.0704e-15, -1.1032e-15, -1.2795e-15,  ..., -1.7938e-15,\n",
      "           -2.0689e-15, -2.2529e-15],\n",
      "          [-2.0834e-15, -2.4744e-15, -2.1400e-15,  ..., -4.0476e-15,\n",
      "           -3.5665e-15, -3.8881e-15],\n",
      "          [-2.7400e-15, -3.3307e-15, -3.2788e-15,  ..., -5.3991e-15,\n",
      "           -5.0400e-15, -5.9682e-15],\n",
      "          ...,\n",
      "          [-1.3981e-14, -1.6756e-14, -1.5794e-14,  ..., -2.7355e-14,\n",
      "           -2.5654e-14, -3.2614e-14],\n",
      "          [-1.7907e-14, -2.0794e-14, -2.0192e-14,  ..., -3.7257e-14,\n",
      "           -3.1322e-14, -4.0265e-14],\n",
      "          [-2.0721e-14, -2.2071e-14, -2.4578e-14,  ..., -3.1260e-14,\n",
      "           -3.4042e-14, -4.4122e-14]],\n",
      "\n",
      "         [[-1.0786e-15, -1.1027e-15, -1.2469e-15,  ..., -1.6288e-15,\n",
      "           -2.0097e-15, -2.1589e-15],\n",
      "          [-2.0894e-15, -2.4421e-15, -2.1969e-15,  ..., -4.0649e-15,\n",
      "           -3.6823e-15, -4.0193e-15],\n",
      "          [-2.7608e-15, -3.1727e-15, -3.3105e-15,  ..., -5.5460e-15,\n",
      "           -5.0488e-15, -5.9713e-15],\n",
      "          ...,\n",
      "          [-1.4092e-14, -1.7128e-14, -1.5707e-14,  ..., -2.7449e-14,\n",
      "           -2.5677e-14, -3.0583e-14],\n",
      "          [-1.6742e-14, -2.1301e-14, -2.0304e-14,  ..., -3.4113e-14,\n",
      "           -3.0600e-14, -3.8048e-14],\n",
      "          [-2.1367e-14, -2.3545e-14, -2.4599e-14,  ..., -3.2266e-14,\n",
      "           -3.5968e-14, -4.3812e-14]]],\n",
      "\n",
      "\n",
      "        [[[-5.8022e-18, -4.4677e-18, -1.2542e-18,  ..., -1.4901e-17,\n",
      "            6.1056e-19, -1.3658e-17],\n",
      "          [-1.1210e-17, -1.4656e-17, -1.6481e-17,  ...,  2.5842e-17,\n",
      "            4.0384e-17, -4.1534e-17],\n",
      "          [-9.4559e-18,  3.5878e-18, -2.9488e-17,  ..., -2.9329e-17,\n",
      "           -4.1060e-17,  1.2622e-17],\n",
      "          ...,\n",
      "          [ 1.8748e-17,  1.0423e-17, -1.0530e-17,  ...,  6.2136e-18,\n",
      "            4.7048e-17,  3.4976e-17],\n",
      "          [ 4.2745e-17, -1.0426e-17, -2.8715e-17,  ...,  6.9697e-18,\n",
      "            2.6408e-17,  3.6244e-17],\n",
      "          [-1.7846e-17, -5.9400e-18,  9.7196e-18,  ..., -4.6297e-17,\n",
      "            2.3538e-17, -5.7339e-17]],\n",
      "\n",
      "         [[-2.2320e-18, -1.1382e-17,  4.2988e-20,  ..., -4.1990e-18,\n",
      "           -3.6122e-18, -9.0522e-18],\n",
      "          [-4.3768e-18,  1.9451e-17, -2.2040e-17,  ..., -3.1115e-18,\n",
      "           -1.2360e-17, -6.2767e-18],\n",
      "          [-2.4579e-18, -3.2304e-18,  6.6907e-19,  ...,  2.7848e-17,\n",
      "           -7.1587e-18, -1.7974e-19],\n",
      "          ...,\n",
      "          [ 2.3492e-17, -2.7479e-17,  2.1706e-17,  ...,  1.7218e-17,\n",
      "            2.9264e-17, -5.8105e-17],\n",
      "          [-2.7788e-17, -4.0736e-17, -2.0841e-17,  ..., -1.4975e-17,\n",
      "            8.8980e-17,  2.0083e-17],\n",
      "          [ 5.6872e-18,  2.9835e-17,  7.6219e-18,  ..., -3.7881e-17,\n",
      "            1.4488e-17,  1.3103e-17]],\n",
      "\n",
      "         [[-1.3909e-18, -9.4286e-18, -1.3700e-18,  ..., -2.5793e-18,\n",
      "           -1.8565e-17, -2.2894e-18],\n",
      "          [-1.4254e-17,  1.8022e-18, -8.1017e-18,  ..., -1.7627e-17,\n",
      "            1.8601e-17,  4.0351e-18],\n",
      "          [ 4.8563e-18, -2.1903e-17,  1.6503e-17,  ...,  1.7239e-17,\n",
      "            9.7816e-18,  2.5088e-17],\n",
      "          ...,\n",
      "          [-2.4515e-17, -1.0033e-17,  3.1701e-17,  ...,  1.7329e-17,\n",
      "           -1.0639e-17,  1.0607e-17],\n",
      "          [-3.8673e-18, -3.4532e-17,  2.2965e-17,  ...,  1.8086e-17,\n",
      "            5.9549e-17, -3.9527e-17],\n",
      "          [-8.3614e-18, -2.4074e-17, -2.0948e-17,  ..., -4.6452e-18,\n",
      "           -4.8435e-17,  2.4690e-17]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0718e-05, -8.3037e-07, -5.1335e-04,  ...,  1.8310e-04,\n",
      "            3.3631e-04, -4.8450e-04],\n",
      "          [-3.4495e-04, -2.4594e-04,  3.5630e-05,  ..., -5.2527e-05,\n",
      "            1.7967e-04, -1.6849e-04],\n",
      "          [ 3.0651e-04,  1.5168e-04, -4.7015e-04,  ..., -4.3360e-04,\n",
      "            4.1539e-04,  3.6103e-04],\n",
      "          ...,\n",
      "          [ 2.0312e-05,  3.1917e-04, -1.7852e-04,  ..., -9.2287e-05,\n",
      "            3.7217e-04, -4.1951e-04],\n",
      "          [ 3.0430e-04,  1.8958e-04,  1.5201e-04,  ..., -3.7113e-04,\n",
      "            1.4041e-04, -3.7126e-04],\n",
      "          [ 3.6718e-04,  3.4368e-04,  3.8236e-04,  ..., -3.8414e-04,\n",
      "            3.3926e-04, -4.0066e-04]],\n",
      "\n",
      "         [[ 5.6445e-05, -3.2983e-04, -1.7767e-04,  ...,  4.5748e-04,\n",
      "           -2.4202e-05,  3.6023e-04],\n",
      "          [-9.5743e-05, -2.9503e-04,  2.6095e-04,  ..., -4.3510e-04,\n",
      "            3.4200e-04,  2.5826e-04],\n",
      "          [ 4.2053e-04,  3.8670e-04, -4.1432e-04,  ...,  2.3891e-05,\n",
      "           -4.4327e-04,  3.9357e-04],\n",
      "          ...,\n",
      "          [-3.6729e-04, -2.7417e-04,  3.9562e-04,  ...,  6.7195e-05,\n",
      "           -6.1869e-05,  2.4896e-04],\n",
      "          [-1.7703e-04,  4.8066e-04, -3.6675e-04,  ...,  1.7645e-04,\n",
      "           -2.6430e-04,  1.5876e-04],\n",
      "          [ 1.1486e-05, -4.6011e-04,  2.9508e-05,  ...,  2.1002e-04,\n",
      "           -2.4195e-04, -6.4697e-05]],\n",
      "\n",
      "         [[ 4.9076e-04, -3.0006e-04, -6.0800e-05,  ...,  4.5619e-04,\n",
      "            9.6466e-05, -2.8134e-04],\n",
      "          [ 6.4173e-05, -4.5140e-04,  3.4104e-04,  ...,  5.1249e-05,\n",
      "            2.4474e-04,  5.7795e-05],\n",
      "          [ 2.6079e-04, -1.5957e-04, -4.1118e-04,  ...,  3.2108e-04,\n",
      "            4.3956e-04,  2.6250e-04],\n",
      "          ...,\n",
      "          [ 1.0539e-04,  4.1401e-04,  3.0641e-05,  ..., -1.5906e-04,\n",
      "           -2.0489e-04, -2.5976e-04],\n",
      "          [ 2.6158e-04, -2.1948e-05,  2.8889e-04,  ..., -9.8925e-05,\n",
      "           -1.8603e-04,  9.2031e-05],\n",
      "          [ 1.0292e-04,  1.9290e-04,  1.8561e-04,  ...,  5.1059e-05,\n",
      "           -4.2191e-04,  2.9483e-04]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model_encoder.show_one_layer_weights(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Calculate KDE using sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "#Get encoded output of input images = Latent space\n",
    "# encoded_images = model_encoder(images)\n",
    "encoded_images = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    X = dataset[i]\n",
    "    image_in_tensor = X[0]\n",
    "    image_in_tensor = image_in_tensor.cuda()            # Because GPU is being used\n",
    "    with torch.no_grad():\n",
    "        Y = model_encoder(image_in_tensor)  # should be same as X\n",
    "    encoded_images.append(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(len(encoded_images))\n",
    "print(type(encoded_images))\n",
    "print(type(encoded_images[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that it is 179 length because it corresponds to all the images that belong to the training dataset. \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert \"encoded_images\" to a np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_encoded_images = []\n",
    "for i in range (len(encoded_images)):\n",
    "    # np_conversion = encoded_images[i].detach().numpy()        # If not using GPU\n",
    "    np_conversion = encoded_images[i].cpu().detach().numpy()    # If using GPU\n",
    "    np_encoded_images.append(np_conversion)\n",
    "np_encoded_images = np.array(np_encoded_images)\n",
    "print(type(np_encoded_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 450, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np_encoded_images.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, see above the shape of the representation of the original images has been lowered to (1, 1) as specified in the model structure. The number 450, on the other hand, corresponds to the channels of the image; this value started at 3 and layer by layer it incremented until reaching 450."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to flatten the data in order to apply kernel density on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "model_encoder_output_shape = (450,1,1)\n",
    "print(model_encoder_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vector_shape = model_encoder_output_shape[0]*model_encoder_output_shape[1]*model_encoder_output_shape[2]\n",
    "encoded_images_vector = [np.reshape(img, (out_vector_shape)) for img in np_encoded_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_images_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_images_vector[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(encoded_images_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function fits a kernel density estimation to the data that is provided, that is, to the \"encoded_images_vector\" variable. It does so using a Guassian kernel of bandwidth 0.2.\n",
    "\n",
    "The badnwidth parameter affects on how the selected kernel will fit each sample of the given data. For example for the case in which the kernel is a Gaussian distribution, the bandwidth parameter would affect in how thin or wide is the Gaussian distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in the variable \"kde\" we have some numbers that are the result of fitting Gaussian functions to the given data points in the variable \"encoded_images_vecotr\". We will use the \"kde\" variable later for scoring with it, some given data points; the scoring will be given depending on how similar are the given data points to the ones that it had estimated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below, it is shown the kde values corresponding to each encoded sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 306.23048203 306.23048203 306.23048203 306.23048203 306.23048203\n",
      " 306.23048203 306.23048203 306.2304823  306.2304823  306.23048203\n",
      " 306.23048203 306.23048203 306.23048203 306.23048203 306.23048203\n",
      " 306.23048203 306.23048215 306.23048215 306.23048203 306.23048203\n",
      " 306.23048203 306.23048203 306.23048203 306.23048203 306.23048203\n",
      " 306.23048203 306.23048203 306.2304823  306.2304823  306.23048203\n",
      " 306.23048203 306.23048203 306.23048203 306.23048203 306.23048203\n",
      " 306.23048203 306.23048215 306.23048215 306.23048203 306.23048203\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733486 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733486 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.56239848 305.53733953 305.56240304\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53740421 305.53740421 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733497 305.53733485 305.53733497\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485]\n"
     ]
    }
   ],
   "source": [
    "density_vals = kde.score_samples(encoded_images_vector)\n",
    "print(density_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the above density values are pretty much the same among them. This has to do with the new model that was trained. The previous model from the \"Pt_latentSpace_DS1\" program, makes these value to be more different among them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, the mean and standard deviation of these values are computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg of the density values is:  305.6925089493738\n",
      "The stdev_density of the density values is:  0.28860324374992247\n"
     ]
    }
   ],
   "source": [
    "average_density = np.mean(density_vals)\n",
    "stdev_density = np.std(density_vals)\n",
    "print(\"The avg of the density values is: \", average_density)\n",
    "print(\"The stdev_density of the density values is: \", stdev_density)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, the density calculation, was computed, in the video reference (https://www.youtube.com/watch?v=q_tpFGHiRgg&t=1140s&ab_channel=DigitalSreeni), in this manner.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg of the density values is:  305.6925089493738\n",
      "The stdev_density of the density values is:  0.28860324374992247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Calculate density and reconstruction error to find their means values for\n",
    "density_lst = []\n",
    "\n",
    "X = dataset[0]\n",
    "image_in_tensor = X[0]\n",
    "\n",
    "model_encoder_output_shape = (450,1,1)          # This is the shape of the last layer of the encoder model\n",
    "out_vector_shape = model_encoder_output_shape[0]*model_encoder_output_shape[1]*model_encoder_output_shape[2]\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    X = dataset[i]\n",
    "    image_in_tensor = X[0]\n",
    "    image_in_tensor = image_in_tensor.cuda()            # Because GPU is being used\n",
    "    with torch.no_grad():\n",
    "        Y = model_encoder(image_in_tensor)  # should be same as X\n",
    "    # np_converted_encoded_img = Y.detach().numpy()     # If GPU is not used\n",
    "    np_converted_encoded_img = Y.cpu().detach().numpy() # If GPU is used\n",
    "    flattened = np.reshape(np_converted_encoded_img, (out_vector_shape))\n",
    "    density = kde.score_samples([flattened])[0]\n",
    "    density_lst.append(density)\n",
    "average_density = np.mean(np.array(density_lst))  \n",
    "stdev_density = np.std(np.array(density_lst)) \n",
    "print(\"The avg of the density values is: \", average_density)\n",
    "print(\"The stdev_density of the density values is: \", stdev_density)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code above is not relevant to execute, since it only shows an alternative way of computing the density mean and std values. See that the results from this code block and the one above of it, are the same. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it will be shown the density mean and std deviation of the set of anomalies samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_anomalies = '../../../Images/BottleStoodUp_atNight/Anomalies2.0'      #This is for the home laptop\n",
    "# data_anomalies = '../../../Images/BottleStoodUp_atNight/Anomalies2.0'      #This is for the work laptop\n",
    "transform_characteristics = transforms.Compose([transforms.ToTensor(),\n",
    "                                                transforms.Resize(255),\n",
    "                                                transforms.CenterCrop(224)])\n",
    "dataset_anomalies = datasets.ImageFolder(data_anomalies, transform=transform_characteristics)\n",
    "dataloader_anomalies = torch.utils.data.DataLoader(dataset_anomalies, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Get encoded output of input images = Latent space\n",
    "encoded_anomalies_images = []\n",
    "\n",
    "for i in range(len(dataset_anomalies)):\n",
    "    X = dataset_anomalies[i]\n",
    "    image_in_tensor = X[0]\n",
    "    image_in_tensor = image_in_tensor.cuda()            # Because GPU is being used\n",
    "    with torch.no_grad():\n",
    "        Y = model_encoder(image_in_tensor)  # should be same as X\n",
    "    encoded_anomalies_images.append(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_encoded_anomaly_images = []\n",
    "for i in range (len(encoded_anomalies_images)):\n",
    "    # np_conversion = encoded_anomalies_images[i].detach().numpy()      # If GPU is not used\n",
    "    np_conversion = encoded_anomalies_images[i].cpu().detach().numpy()    # If GPU is used\n",
    "    np_encoded_anomaly_images.append(np_conversion)\n",
    "np_encoded_anomaly_images = np.array(np_encoded_anomaly_images)\n",
    "print(type(np_encoded_anomaly_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_anomaly_images_vector = [np.reshape(img_encoded, (out_vector_shape)) for img_encoded in np_encoded_anomaly_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[298.60225774  63.75064794 224.22969716 284.25558446 280.04700797\n",
      " 238.75390245]\n"
     ]
    }
   ],
   "source": [
    "density_vals_anomalies = kde.score_samples(encoded_anomaly_images_vector)\n",
    "print(density_vals_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg of the density values is:  231.6065162868862\n",
      "The stdev_density of the density values is:  79.46480364757964\n"
     ]
    }
   ],
   "source": [
    "average_density_anomalies = np.mean(density_vals_anomalies)\n",
    "stdev_density_anomalies = np.std(density_vals_anomalies)\n",
    "print(\"The avg of the density values is: \", average_density_anomalies)\n",
    "print(\"The stdev_density of the density values is: \", stdev_density_anomalies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that the std deviation along with the mean of these density values will overlap the mean of the non-anomaly images. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the situation of the overlapping commented above, given a density value, it will be built a function that:\n",
    "- Assigns a percentage value according to the proximity to the mean of the non-anomaly images. For example: \n",
    "    - If the densitiy value is 305.69 (the mean of the density values of the non-anomaly images), then this density value should have 100% chance to be considered as non-anomaly.\n",
    "    - If the densitiy value is 305.4014 (the mean of the density values of the non-anomaly minus the std deviation of the same set), then this density value should have 50% chance to be considered as non-anomaly.\n",
    "- Assigns a percentage value according to the proximity to the mean of the anomaly images. For example: \n",
    "    - If the densitiy value is 231.6065 (the mean of the density values of the anomaly images), then this density value should have 100% chance to be considered as an anomaly image.\n",
    "    - If the densitiy value is 311.0713 (the mean of the density values of the anomaly plus the std deviation of the same set), then this density value should have 50% chance to be considered as an anomaly.\n",
    "- The two percentage values from above will be summed up assigning the following weights to the equation:\n",
    "\n",
    "        = perc_NOanomaly*0.75 + perc_anomaly*0.25\n",
    "        \n",
    "    More weight is assigned to the non-anomaly images because there are more samples of this kind of images.\n",
    "- After the weighted sum, the result will be subtracted from 100, to finally output the probability of an image to be an anomaly image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranges_mapper(value, leftMin, leftMax, rightMin, rightMax):\n",
    "    # if(value>leftMax):\n",
    "    #     return rightMax\n",
    "    # Figure out how 'wide' each range is\n",
    "    leftSpan = leftMax - leftMin\n",
    "    rightSpan = rightMax - rightMin\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    valueScaled = float(value - leftMin) / float(leftSpan)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return rightMin + (valueScaled * rightSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_kde2prob_list(input_list):\n",
    "    threshold_NOanomaly = average_density          # The mean of the density values corresponding to the non-anomaly images\n",
    "    std_dev_NOanomaly = stdev_density            # The std deviation of the density values corresponding to the non-anomaly images\n",
    "\n",
    "    threshold_anomaly = average_density_anomalies          # The mean of the density values corresponding to the anomaly images\n",
    "    std_dev_anomaly = stdev_density_anomalies            # The std deviation of the density values corresponding to the anomaly images\n",
    "    prob_score_list = []\n",
    "\n",
    "    for i in range (len(input_list)):\n",
    "        score_NOanomaly = input_list[i] - threshold_NOanomaly\n",
    "\n",
    "        perc_NOanomaly = ranges_mapper(abs(score_NOanomaly), 0, std_dev_NOanomaly, 100, 50)\n",
    "        if perc_NOanomaly<0:\n",
    "            perc_NOanomaly = 0\n",
    "        if perc_NOanomaly>100:\n",
    "            perc_NOanomaly = 100\n",
    "\n",
    "        score_anomaly = input_list[i] - threshold_anomaly\n",
    "\n",
    "        perc_anomaly = ranges_mapper(abs(score_anomaly), 0, std_dev_anomaly, 100, 50)\n",
    "        if perc_anomaly<0:\n",
    "            perc_anomaly = 0\n",
    "        if perc_anomaly>100:\n",
    "            perc_anomaly = 100\n",
    "        \n",
    "        prob_score = 100 - (perc_NOanomaly*0.75+perc_anomaly*0.25)\n",
    "        prob_score_list.append(prob_score)\n",
    "    return prob_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_kde2prob(value):\n",
    "    threshold_NOanomaly = average_density          # The mean of the density values corresponding to the non-anomaly images\n",
    "    std_dev_NOanomaly = stdev_density            # The std deviation of the density values corresponding to the non-anomaly images\n",
    "\n",
    "    threshold_anomaly = average_density_anomalies          # The mean of the density values corresponding to the anomaly images\n",
    "    std_dev_anomaly = stdev_density_anomalies            # The std deviation of the density values corresponding to the anomaly images\n",
    "    score_NOanomaly = value - threshold_NOanomaly\n",
    "\n",
    "    perc_NOanomaly = ranges_mapper(abs(score_NOanomaly), 0, std_dev_NOanomaly, 100, 50)\n",
    "    if perc_NOanomaly<0:\n",
    "        perc_NOanomaly = 0\n",
    "    if perc_NOanomaly>100:\n",
    "        perc_NOanomaly = 100\n",
    "\n",
    "    score_anomaly = value - threshold_anomaly\n",
    "\n",
    "    perc_anomaly = ranges_mapper(abs(score_anomaly), 0, std_dev_anomaly, 100, 50)\n",
    "    if perc_anomaly<0:\n",
    "        perc_anomaly = 0\n",
    "    if perc_anomaly>100:\n",
    "        perc_anomaly = 100\n",
    "    \n",
    "    prob_score = 100 - (perc_NOanomaly*0.75+perc_anomaly*0.25)\n",
    "  \n",
    "    return prob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.5\n"
     ]
    }
   ],
   "source": [
    "print(map_kde2prob(231.6065+79.4648))\n",
    "# print(map_kde2prob(231.6065+75.4648))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePred(kde_value):\n",
    "    pred = 0\n",
    "    prob_anomaly = map_kde2prob(kde_value)/100\n",
    "    if prob_anomaly > 0.5:\n",
    "        pred = 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prob of the kde value of being anomaly image is:  50.17501155625721\n",
      "Given the probability, it is actually predicted as: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"The prob of the kde value of being anomaly image is: \", map_kde2prob(average_density+stdev_density))\n",
    "print(\"Given the probability, it is actually predicted as:\", computePred(average_density+stdev_density))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the kde thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../../../Images/BottleStoodUp_atNight/Evaluation'      #This is for the home laptop\n",
    "transform_characteristics = transforms.Compose([transforms.ToTensor(),\n",
    "                                                transforms.Resize(255),\n",
    "                                                transforms.CenterCrop(224)])\n",
    "\n",
    "dataset_test = datasets.ImageFolder(test_dir, transform=transform_characteristics)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
    "classes = ('non-anomaly','anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Get encoded output of input images = Latent space\n",
    "encoded_test_imgs = []\n",
    "\n",
    "\n",
    "for i in range(len(dataset_test)):\n",
    "    X = dataset_test[i]\n",
    "    image_in_tensor = X[0]\n",
    "    image_in_tensor = image_in_tensor.cuda()     \n",
    "    with torch.no_grad():\n",
    "        Y = model_encoder(image_in_tensor)  # should be same as X\n",
    "    # np_conversion = Y.detach().numpy()\n",
    "    np_conversion = Y.cpu().detach().numpy()\n",
    "    encoded_test_imgs.append(np_conversion)\n",
    "np_encoded_test_images = np.array(encoded_test_imgs)\n",
    "print(type(np_encoded_test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "encoded_test_images_vector = [np.reshape(img, (out_vector_shape)) for img in np_encoded_test_images]\n",
    "print(len(encoded_test_images_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -350.67522441   -693.63549459  -2023.2241612   -2184.82534615\n",
      "  -2799.39007047  -3267.02837392  -5174.08288287  -2772.38539377\n",
      "  -1147.55379623  -2420.5401337     116.3121348     146.8796439\n",
      "    270.02545513    -76.71125116   -564.48883414     74.13091853\n",
      " -20701.70905962 -16413.89368952  -1592.81200715   -267.54464273\n",
      "   -236.72965081   -544.44303225   -661.39524567   -561.63829861\n",
      "   -609.95590391   -950.1247644    -915.71611702  -1473.93517446\n",
      "  -1746.24829226  -1102.07361035]\n"
     ]
    }
   ],
   "source": [
    "density_vals_test = kde.score_samples(encoded_test_images_vector)\n",
    "print(density_vals_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shown values are REALLY strange. It was not expected to have negative values in the density numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_test = map_kde2prob_list(density_vals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 93.13607490326693, 88.32773380461066, 81.04339203237086, 100.0, 100.0, 99.77127946392781, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "print(prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# Grabbing only the first image of the anomalies dataset\n",
    "X = dataset_test[0]\n",
    "image_in_tensor = X[0]\n",
    " \n",
    "n_features = len(image_in_tensor[0])  # Get the size of one image of the anomaly images dataset. This is supposed to be 224\n",
    "for i in range(len(dataset_test)):\n",
    "    X = dataset_test[i]\n",
    "    image_in_tensor = X[0]\n",
    "    image_in_tensor = image_in_tensor.cuda() \n",
    "    ground_truth = X[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Y = model_encoder(image_in_tensor)  # should be same as X\n",
    "    np_converted_encoded_img = Y.cpu().detach().numpy()\n",
    "    flattened = np.reshape(np_converted_encoded_img, (out_vector_shape))\n",
    "    density = kde.score_samples([flattened])[0]\n",
    "    prediction = computePred(density)\n",
    "    y_pred.append(prediction) # Save Prediction\n",
    "    y_true.append(ground_truth) # Save Truth\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, it can be seen that all the images are predicted to be anomaly images. This is good for the TPR but it is terrible for the FPR. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
