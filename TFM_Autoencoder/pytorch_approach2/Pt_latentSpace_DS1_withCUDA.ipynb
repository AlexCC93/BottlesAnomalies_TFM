{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x0000029ED95FD700>\n",
      "GeForce RTX 2080 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '../../../../BottleStoodUp_atNight/Positive/'        #For the work laptop\n",
    "data_dir = '../../../Images/BottleStoodUp_atNight/Positive'        #For the home laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_characteristics = transforms.Compose([transforms.Resize(255),\n",
    "#                                 transforms.CenterCrop(224),\n",
    "#                                 transforms.ToTensor()])\n",
    "\n",
    "transform_characteristics = transforms.Compose([transforms.ToTensor(),\n",
    "                                                transforms.Resize(255),\n",
    "                                                transforms.CenterCrop(224)])\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform_characteristics)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only the encoder part of the nertwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_latentSpace(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # N, 1, 28, 28\n",
    "        # 32, 3, 224, 224\n",
    "        input_channels = 3              # number of channels of the input image\n",
    "        output_channels = 110           # ~= 224/2. Shape of the input image \n",
    "        kernel_size = 9\n",
    "        padding_val = 1\n",
    "        stride_val = 5\n",
    "\n",
    "        output_channels_layer2 = output_channels*2+5\n",
    "\n",
    "        output_channels_layer3 = output_channels_layer2*2\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size, stride=stride_val, padding=padding_val),         # input image channels, output channels, kernel size (filter). Dimension rseult: -> N, 110, 44, 44\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels, output_channels_layer2, kernel_size, stride=stride_val, padding=padding_val), # -> N, 225, 8, 8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels_layer2, output_channels_layer3, 8) # -> N, 450, 1, 1\n",
    "        )\n",
    "        \n",
    "        # self.show_modules()\n",
    "        # self.show_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"This is the forward function\")\n",
    "        encoded = self.encoder(x)\n",
    "        return encoded\n",
    "    \n",
    "    def show_modules(self):\n",
    "        print(\"This is the new function\")\n",
    "        # print(self.modules())\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            print(m)\n",
    "            print(\"i is: \", i)\n",
    "            print(\"print the next module\")\n",
    "            i = i +1\n",
    "    \n",
    "    def show_weights(self):\n",
    "        print(\"This is the function for showing the initial weights\")\n",
    "        # print(self.modules())\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if i == 0:\n",
    "                    print(\"i is: \", i)\n",
    "                    print(\"The type of the module weight is: \", type(m.weight))\n",
    "                    print(\"The shape of the module weight is: \", m.weight.shape)\n",
    "                    print(\"print the next module\")\n",
    "                    i = i +1\n",
    "    def show_one_module_weights(self):\n",
    "        print(\"Showing only one module's weights\")\n",
    "        # print(self.modules())\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if i == 0:\n",
    "                    print(\"i is: \", i)\n",
    "                    print(\"The weights are: \", m.weight)\n",
    "                    i = i +1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder_latentSpace(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(110, 225, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(225, 450, kernel_size=(8, 8), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_encoder = Autoencoder_latentSpace()\n",
    "model_encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing only one module's weights\n",
      "i is:  0\n",
      "The weights are:  Parameter containing:\n",
      "tensor([[[[-0.0364,  0.0054, -0.0622,  ...,  0.0456, -0.0026, -0.0059],\n",
      "          [-0.0289,  0.0113,  0.0103,  ...,  0.0617, -0.0265,  0.0292],\n",
      "          [-0.0509, -0.0079, -0.0342,  ..., -0.0301,  0.0391,  0.0148],\n",
      "          ...,\n",
      "          [ 0.0007,  0.0262, -0.0364,  ..., -0.0335,  0.0057, -0.0320],\n",
      "          [-0.0166, -0.0174, -0.0188,  ..., -0.0088,  0.0404,  0.0232],\n",
      "          [ 0.0620, -0.0485, -0.0329,  ..., -0.0255,  0.0384,  0.0390]],\n",
      "\n",
      "         [[ 0.0593, -0.0595,  0.0574,  ...,  0.0594,  0.0433,  0.0166],\n",
      "          [ 0.0037, -0.0382, -0.0189,  ..., -0.0511,  0.0142,  0.0518],\n",
      "          [ 0.0291, -0.0362,  0.0059,  ..., -0.0608, -0.0620,  0.0135],\n",
      "          ...,\n",
      "          [-0.0263, -0.0408, -0.0121,  ..., -0.0269,  0.0560,  0.0248],\n",
      "          [ 0.0216,  0.0004,  0.0025,  ..., -0.0194, -0.0002, -0.0011],\n",
      "          [-0.0418,  0.0336, -0.0632,  ..., -0.0340,  0.0153, -0.0036]],\n",
      "\n",
      "         [[ 0.0580, -0.0464, -0.0486,  ...,  0.0251, -0.0172,  0.0393],\n",
      "          [ 0.0375,  0.0206,  0.0195,  ..., -0.0054, -0.0031,  0.0421],\n",
      "          [ 0.0227, -0.0472, -0.0290,  ..., -0.0117,  0.0585,  0.0565],\n",
      "          ...,\n",
      "          [ 0.0238, -0.0516, -0.0460,  ...,  0.0558,  0.0174,  0.0406],\n",
      "          [ 0.0198,  0.0393, -0.0435,  ...,  0.0310,  0.0266,  0.0213],\n",
      "          [-0.0311, -0.0434,  0.0482,  ...,  0.0003,  0.0558, -0.0157]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0514, -0.0113,  0.0373,  ...,  0.0424,  0.0257, -0.0017],\n",
      "          [-0.0086, -0.0218,  0.0568,  ..., -0.0105, -0.0259, -0.0014],\n",
      "          [ 0.0493,  0.0246,  0.0598,  ...,  0.0083, -0.0386,  0.0236],\n",
      "          ...,\n",
      "          [ 0.0507, -0.0038,  0.0612,  ...,  0.0024,  0.0467,  0.0462],\n",
      "          [ 0.0478, -0.0640, -0.0292,  ...,  0.0462, -0.0131, -0.0620],\n",
      "          [-0.0286,  0.0072,  0.0119,  ...,  0.0463,  0.0012,  0.0041]],\n",
      "\n",
      "         [[ 0.0639, -0.0050,  0.0203,  ..., -0.0305, -0.0580,  0.0429],\n",
      "          [-0.0277,  0.0490,  0.0633,  ..., -0.0371,  0.0207,  0.0165],\n",
      "          [ 0.0528,  0.0008,  0.0539,  ..., -0.0340, -0.0300, -0.0168],\n",
      "          ...,\n",
      "          [-0.0356, -0.0552,  0.0541,  ..., -0.0178, -0.0256,  0.0388],\n",
      "          [ 0.0023, -0.0004, -0.0310,  ...,  0.0554,  0.0237, -0.0565],\n",
      "          [ 0.0406,  0.0108, -0.0012,  ..., -0.0377,  0.0445,  0.0108]],\n",
      "\n",
      "         [[ 0.0290, -0.0104, -0.0600,  ..., -0.0496,  0.0596,  0.0376],\n",
      "          [ 0.0017, -0.0235, -0.0032,  ..., -0.0160, -0.0044, -0.0242],\n",
      "          [-0.0562,  0.0449,  0.0607,  ...,  0.0480,  0.0416, -0.0524],\n",
      "          ...,\n",
      "          [-0.0309,  0.0296,  0.0447,  ...,  0.0303, -0.0517, -0.0306],\n",
      "          [-0.0081,  0.0054,  0.0609,  ...,  0.0169, -0.0491, -0.0006],\n",
      "          [ 0.0590, -0.0521,  0.0523,  ..., -0.0588,  0.0554, -0.0587]]],\n",
      "\n",
      "\n",
      "        [[[-0.0173,  0.0308, -0.0253,  ...,  0.0461,  0.0297, -0.0398],\n",
      "          [ 0.0514,  0.0057,  0.0126,  ..., -0.0314, -0.0317,  0.0307],\n",
      "          [ 0.0135, -0.0438, -0.0470,  ..., -0.0031, -0.0600,  0.0063],\n",
      "          ...,\n",
      "          [ 0.0078,  0.0184,  0.0522,  ...,  0.0210,  0.0210,  0.0584],\n",
      "          [-0.0355,  0.0138, -0.0472,  ..., -0.0447, -0.0409, -0.0410],\n",
      "          [ 0.0217, -0.0038,  0.0080,  ...,  0.0528, -0.0095, -0.0198]],\n",
      "\n",
      "         [[-0.0300, -0.0249, -0.0545,  ..., -0.0213,  0.0287,  0.0519],\n",
      "          [-0.0134,  0.0230, -0.0540,  ...,  0.0618,  0.0309,  0.0388],\n",
      "          [ 0.0490, -0.0403, -0.0394,  ..., -0.0457, -0.0433, -0.0506],\n",
      "          ...,\n",
      "          [-0.0213,  0.0563,  0.0167,  ...,  0.0466,  0.0466, -0.0443],\n",
      "          [-0.0129,  0.0040,  0.0177,  ..., -0.0361, -0.0209, -0.0521],\n",
      "          [ 0.0357, -0.0319,  0.0278,  ...,  0.0279,  0.0268, -0.0100]],\n",
      "\n",
      "         [[ 0.0269, -0.0222,  0.0280,  ...,  0.0363,  0.0257, -0.0079],\n",
      "          [ 0.0414,  0.0437,  0.0067,  ...,  0.0108, -0.0091, -0.0540],\n",
      "          [ 0.0071, -0.0118, -0.0329,  ...,  0.0190, -0.0427, -0.0419],\n",
      "          ...,\n",
      "          [-0.0490, -0.0385,  0.0451,  ...,  0.0233, -0.0060,  0.0016],\n",
      "          [-0.0096, -0.0584,  0.0323,  ..., -0.0324, -0.0048, -0.0541],\n",
      "          [-0.0553,  0.0602, -0.0381,  ..., -0.0064,  0.0457, -0.0021]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0007, -0.0346,  0.0009,  ..., -0.0223,  0.0039,  0.0164],\n",
      "          [-0.0157,  0.0259, -0.0520,  ..., -0.0607,  0.0321, -0.0470],\n",
      "          [ 0.0432, -0.0484,  0.0389,  ...,  0.0602,  0.0243, -0.0604],\n",
      "          ...,\n",
      "          [ 0.0241,  0.0308,  0.0557,  ..., -0.0548,  0.0450,  0.0250],\n",
      "          [-0.0288,  0.0319, -0.0324,  ..., -0.0323,  0.0356,  0.0532],\n",
      "          [-0.0517, -0.0538,  0.0097,  ..., -0.0328,  0.0578, -0.0627]],\n",
      "\n",
      "         [[ 0.0557, -0.0017, -0.0589,  ..., -0.0246, -0.0346, -0.0282],\n",
      "          [ 0.0062,  0.0335,  0.0304,  ...,  0.0516, -0.0495,  0.0456],\n",
      "          [ 0.0004, -0.0441, -0.0482,  ...,  0.0263,  0.0574, -0.0417],\n",
      "          ...,\n",
      "          [ 0.0146,  0.0269,  0.0360,  ..., -0.0302, -0.0278,  0.0283],\n",
      "          [-0.0074, -0.0542, -0.0392,  ..., -0.0034,  0.0286, -0.0078],\n",
      "          [ 0.0246,  0.0266,  0.0495,  ..., -0.0392, -0.0354, -0.0271]],\n",
      "\n",
      "         [[-0.0408, -0.0286,  0.0130,  ..., -0.0410,  0.0212, -0.0135],\n",
      "          [ 0.0008,  0.0484, -0.0489,  ..., -0.0584,  0.0484, -0.0622],\n",
      "          [-0.0199,  0.0436, -0.0061,  ...,  0.0539, -0.0604, -0.0479],\n",
      "          ...,\n",
      "          [-0.0153, -0.0535, -0.0009,  ..., -0.0034,  0.0445, -0.0311],\n",
      "          [-0.0105, -0.0383,  0.0301,  ..., -0.0281,  0.0634, -0.0284],\n",
      "          [ 0.0343,  0.0102, -0.0089,  ...,  0.0482, -0.0168,  0.0311]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0418,  0.0399,  0.0043,  ..., -0.0395,  0.0617, -0.0449],\n",
      "          [-0.0321, -0.0098,  0.0156,  ..., -0.0543,  0.0115,  0.0579],\n",
      "          [-0.0352,  0.0602,  0.0629,  ...,  0.0619,  0.0337, -0.0092],\n",
      "          ...,\n",
      "          [-0.0431,  0.0120,  0.0557,  ...,  0.0575,  0.0049,  0.0623],\n",
      "          [ 0.0059,  0.0323,  0.0022,  ..., -0.0597,  0.0377, -0.0608],\n",
      "          [ 0.0334,  0.0222, -0.0054,  ...,  0.0582,  0.0225, -0.0483]],\n",
      "\n",
      "         [[ 0.0576,  0.0634,  0.0146,  ..., -0.0418,  0.0285, -0.0423],\n",
      "          [ 0.0002, -0.0266, -0.0378,  ...,  0.0509,  0.0302, -0.0496],\n",
      "          [ 0.0011,  0.0094, -0.0610,  ..., -0.0014,  0.0385, -0.0583],\n",
      "          ...,\n",
      "          [-0.0078, -0.0236,  0.0012,  ..., -0.0585, -0.0002, -0.0443],\n",
      "          [ 0.0216, -0.0294,  0.0324,  ...,  0.0050, -0.0576, -0.0494],\n",
      "          [ 0.0079,  0.0638,  0.0372,  ...,  0.0290,  0.0181,  0.0100]],\n",
      "\n",
      "         [[-0.0608, -0.0238,  0.0549,  ...,  0.0422,  0.0365, -0.0516],\n",
      "          [-0.0534, -0.0090,  0.0052,  ...,  0.0636, -0.0340, -0.0235],\n",
      "          [ 0.0028,  0.0612, -0.0383,  ...,  0.0114, -0.0500, -0.0476],\n",
      "          ...,\n",
      "          [ 0.0536, -0.0509, -0.0489,  ..., -0.0443, -0.0064, -0.0632],\n",
      "          [ 0.0434, -0.0095,  0.0241,  ..., -0.0169, -0.0422,  0.0019],\n",
      "          [-0.0027,  0.0203, -0.0124,  ..., -0.0097, -0.0256, -0.0293]]],\n",
      "\n",
      "\n",
      "        [[[-0.0262, -0.0500,  0.0476,  ...,  0.0394, -0.0046,  0.0532],\n",
      "          [-0.0155, -0.0565,  0.0429,  ...,  0.0620, -0.0237,  0.0273],\n",
      "          [ 0.0094, -0.0178, -0.0286,  ...,  0.0004, -0.0626,  0.0576],\n",
      "          ...,\n",
      "          [-0.0025,  0.0614,  0.0148,  ..., -0.0334, -0.0590,  0.0347],\n",
      "          [-0.0275,  0.0406, -0.0564,  ..., -0.0580,  0.0451, -0.0293],\n",
      "          [-0.0192,  0.0283, -0.0598,  ...,  0.0617,  0.0587,  0.0014]],\n",
      "\n",
      "         [[-0.0452,  0.0533,  0.0390,  ..., -0.0036,  0.0011,  0.0463],\n",
      "          [ 0.0571,  0.0523,  0.0138,  ...,  0.0444,  0.0530, -0.0100],\n",
      "          [ 0.0061, -0.0044, -0.0208,  ..., -0.0478,  0.0169, -0.0102],\n",
      "          ...,\n",
      "          [ 0.0510, -0.0594, -0.0062,  ...,  0.0315,  0.0435,  0.0532],\n",
      "          [ 0.0055, -0.0149,  0.0026,  ..., -0.0397, -0.0081, -0.0312],\n",
      "          [-0.0049, -0.0485, -0.0614,  ..., -0.0072,  0.0406, -0.0079]],\n",
      "\n",
      "         [[-0.0035,  0.0495,  0.0406,  ...,  0.0257,  0.0080, -0.0195],\n",
      "          [-0.0182,  0.0326, -0.0359,  ..., -0.0472,  0.0315, -0.0261],\n",
      "          [ 0.0598,  0.0238,  0.0514,  ..., -0.0207, -0.0428, -0.0050],\n",
      "          ...,\n",
      "          [ 0.0630, -0.0278,  0.0246,  ...,  0.0263, -0.0144,  0.0130],\n",
      "          [ 0.0009,  0.0063,  0.0451,  ...,  0.0218,  0.0549, -0.0098],\n",
      "          [-0.0504, -0.0514,  0.0212,  ..., -0.0459,  0.0055, -0.0320]]]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model_encoder.show_one_module_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # N, 1, 28, 28\n",
    "        # 32, 3, 224, 224\n",
    "        input_channels = 3              # number of channels of the input image\n",
    "        output_channels = 110           # ~= 224/2. Shape of the input image \n",
    "        kernel_size = 9\n",
    "        padding_val = 1\n",
    "        stride_val = 5\n",
    "\n",
    "        \n",
    "        output_channels_layer2 = output_channels*2+5\n",
    "\n",
    "        output_channels_layer3 = output_channels_layer2*2\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size, stride=stride_val, padding=padding_val),         # input image channels, output channels, kernel size (filter). Dimension rseult: -> N, 110, 44, 44\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels, output_channels_layer2, kernel_size, stride=stride_val, padding=padding_val), # -> N, 225, 8, 8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels_layer2, output_channels_layer3, 8) # -> N, 450, 1, 1\n",
    "        )\n",
    "        \n",
    "        # N , 450, 1, 1\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(output_channels_layer3, output_channels_layer2, 8),  # -> 32, 225, 8, 8\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(output_channels_layer2, output_channels, kernel_size, stride=stride_val, padding=padding_val, output_padding=2), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(output_channels, input_channels, kernel_size, stride=stride_val, padding=padding_val, output_padding=2), # N, 3, 224, 224\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    " \n",
    "# Note: nn.MaxPool2d -> use nn.MaxUnpool2d, or use different kernelsize, stride etc to compensate...\n",
    "# Input [-1, +1] -> use nn.Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=1e-3, \n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(110, 225, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(225, 450, kernel_size=(8, 8), stride=(1, 1))\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(450, 225, kernel_size=(8, 8), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): ConvTranspose2d(225, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1), output_padding=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(110, 3, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1), output_padding=(2, 2))\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(110, 225, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(225, 450, kernel_size=(8, 8), stride=(1, 1))\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(450, 225, kernel_size=(8, 8), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): ConvTranspose2d(225, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1), output_padding=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(110, 3, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1), output_padding=(2, 2))\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"../../../BottlesAnomalies_TFM/models/pytorchModels/PytorchModel_withCUDA\"\n",
    "# For loading the model \n",
    "model.load_state_dict(torch.load(filepath))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is:  0\n",
      "The weights are:  Parameter containing:\n",
      "tensor([[[[-1.6085e-25, -1.6363e-25, -1.6663e-25,  ..., -1.7430e-25,\n",
      "           -1.7557e-25, -1.7903e-25],\n",
      "          [-2.2771e-25, -2.5256e-25, -2.5323e-25,  ..., -2.6019e-25,\n",
      "           -2.5946e-25, -2.5337e-25],\n",
      "          [-2.5053e-25, -2.6664e-25, -2.5478e-25,  ..., -2.7490e-25,\n",
      "           -2.6799e-25, -2.6038e-25],\n",
      "          ...,\n",
      "          [-2.6943e-25, -2.8397e-25, -2.8483e-25,  ..., -3.0378e-25,\n",
      "           -2.9532e-25, -2.8298e-25],\n",
      "          [-2.8312e-25, -2.8671e-25, -2.8712e-25,  ..., -2.9985e-25,\n",
      "           -2.9239e-25, -2.9911e-25],\n",
      "          [-2.9684e-25, -2.9257e-25, -2.9676e-25,  ..., -3.0312e-25,\n",
      "           -3.0702e-25, -3.0488e-25]],\n",
      "\n",
      "         [[-1.6082e-25, -1.6399e-25, -1.6598e-25,  ..., -1.7378e-25,\n",
      "           -1.7550e-25, -1.7926e-25],\n",
      "          [-2.2830e-25, -2.5180e-25, -2.5322e-25,  ..., -2.6058e-25,\n",
      "           -2.5928e-25, -2.5301e-25],\n",
      "          [-2.5050e-25, -2.6661e-25, -2.5564e-25,  ..., -2.7503e-25,\n",
      "           -2.6771e-25, -2.5857e-25],\n",
      "          ...,\n",
      "          [-2.6872e-25, -2.8534e-25, -2.8414e-25,  ..., -3.0381e-25,\n",
      "           -2.9534e-25, -2.8295e-25],\n",
      "          [-2.8099e-25, -2.8834e-25, -2.8683e-25,  ..., -2.9919e-25,\n",
      "           -2.9242e-25, -2.9741e-25],\n",
      "          [-2.9452e-25, -2.9257e-25, -2.9678e-25,  ..., -3.0313e-25,\n",
      "           -3.0708e-25, -3.0669e-25]],\n",
      "\n",
      "         [[-1.6087e-25, -1.6460e-25, -1.6687e-25,  ..., -1.7385e-25,\n",
      "           -1.7635e-25, -1.7635e-25],\n",
      "          [-2.2634e-25, -2.5031e-25, -2.5209e-25,  ..., -2.5893e-25,\n",
      "           -2.5896e-25, -2.5337e-25],\n",
      "          [-2.5050e-25, -2.6661e-25, -2.5441e-25,  ..., -2.7445e-25,\n",
      "           -2.6501e-25, -2.6041e-25],\n",
      "          ...,\n",
      "          [-2.6946e-25, -2.8447e-25, -2.8356e-25,  ..., -3.0337e-25,\n",
      "           -2.9386e-25, -2.8199e-25],\n",
      "          [-2.8318e-25, -2.8844e-25, -2.8712e-25,  ..., -2.9845e-25,\n",
      "           -2.8878e-25, -2.9910e-25],\n",
      "          [-2.9603e-25, -2.9085e-25, -2.9577e-25,  ..., -3.0305e-25,\n",
      "           -3.0709e-25, -3.0806e-25]]],\n",
      "\n",
      "\n",
      "        [[[-1.0727e-09, -1.2467e-09, -1.2752e-09,  ..., -1.3815e-09,\n",
      "           -1.3804e-09, -1.4093e-09],\n",
      "          [-4.8281e-09, -5.7444e-09, -5.5169e-09,  ..., -6.1804e-09,\n",
      "           -5.9607e-09, -5.9956e-09],\n",
      "          [-4.8653e-09, -5.8955e-09, -5.7366e-09,  ..., -6.5313e-09,\n",
      "           -6.3610e-09, -6.3550e-09],\n",
      "          ...,\n",
      "          [-6.5471e-09, -7.7374e-09, -7.6077e-09,  ..., -8.3837e-09,\n",
      "           -8.0526e-09, -8.0958e-09],\n",
      "          [-6.6398e-09, -7.9600e-09, -7.7515e-09,  ..., -8.6601e-09,\n",
      "           -8.5860e-09, -8.3701e-09],\n",
      "          [-5.9810e-09, -6.8377e-09, -7.0700e-09,  ..., -7.4223e-09,\n",
      "           -7.6548e-09, -7.9500e-09]],\n",
      "\n",
      "         [[-1.0509e-09, -1.2568e-09, -1.2899e-09,  ..., -1.3348e-09,\n",
      "           -1.4215e-09, -1.3866e-09],\n",
      "          [-4.8179e-09, -5.6788e-09, -5.5128e-09,  ..., -6.1494e-09,\n",
      "           -6.0008e-09, -5.9550e-09],\n",
      "          [-4.8721e-09, -5.9222e-09, -5.7540e-09,  ..., -6.5813e-09,\n",
      "           -6.3536e-09, -6.3902e-09],\n",
      "          ...,\n",
      "          [-6.4751e-09, -7.8155e-09, -7.5744e-09,  ..., -8.1879e-09,\n",
      "           -8.0351e-09, -8.1304e-09],\n",
      "          [-6.6994e-09, -7.9453e-09, -7.7833e-09,  ..., -8.6029e-09,\n",
      "           -8.5038e-09, -8.3584e-09],\n",
      "          [-5.9722e-09, -6.8607e-09, -7.0555e-09,  ..., -7.4304e-09,\n",
      "           -7.5727e-09, -8.0404e-09]],\n",
      "\n",
      "         [[-1.0659e-09, -1.2485e-09, -1.2510e-09,  ..., -1.3357e-09,\n",
      "           -1.4051e-09, -1.4058e-09],\n",
      "          [-4.8855e-09, -5.7471e-09, -5.5161e-09,  ..., -6.1354e-09,\n",
      "           -5.9259e-09, -5.9551e-09],\n",
      "          [-4.8592e-09, -5.9811e-09, -5.8038e-09,  ..., -6.5657e-09,\n",
      "           -6.4136e-09, -6.4005e-09],\n",
      "          ...,\n",
      "          [-6.5056e-09, -7.7086e-09, -7.5397e-09,  ..., -8.4107e-09,\n",
      "           -8.0907e-09, -8.0406e-09],\n",
      "          [-6.5938e-09, -7.9014e-09, -7.7055e-09,  ..., -8.7724e-09,\n",
      "           -8.3818e-09, -8.4589e-09],\n",
      "          [-6.0150e-09, -6.8437e-09, -7.0120e-09,  ..., -7.4443e-09,\n",
      "           -7.6710e-09, -8.0442e-09]]],\n",
      "\n",
      "\n",
      "        [[[-2.6066e-27, -2.6440e-27, -4.9623e-27,  ..., -2.9732e-26,\n",
      "           -6.4868e-26, -1.0348e-25],\n",
      "          [-1.2778e-26, -1.9173e-26, -1.7339e-26,  ..., -1.7092e-25,\n",
      "           -1.4028e-25, -3.3008e-25],\n",
      "          [-4.4636e-26, -5.2706e-26, -5.7231e-26,  ..., -5.8360e-25,\n",
      "           -5.6028e-25, -7.4895e-25],\n",
      "          ...,\n",
      "          [-7.8231e-24, -1.2416e-23, -1.1949e-23,  ..., -5.6591e-23,\n",
      "           -5.4827e-23, -9.1408e-23],\n",
      "          [-1.9654e-23, -2.4449e-23, -2.4558e-23,  ..., -1.2964e-22,\n",
      "           -1.1230e-22, -1.4785e-22],\n",
      "          [-5.7975e-23, -5.4478e-23, -6.5906e-23,  ..., -2.1614e-22,\n",
      "           -2.4514e-22, -3.7824e-22]],\n",
      "\n",
      "         [[-2.5950e-27, -2.7446e-27, -4.9581e-27,  ..., -2.9773e-26,\n",
      "           -6.5088e-26, -1.0299e-25],\n",
      "          [-1.2759e-26, -2.1130e-26, -1.9126e-26,  ..., -1.6566e-25,\n",
      "           -1.4725e-25, -3.1577e-25],\n",
      "          [-4.8367e-26, -5.0795e-26, -5.7363e-26,  ..., -5.7905e-25,\n",
      "           -5.5476e-25, -7.7029e-25],\n",
      "          ...,\n",
      "          [-7.4026e-24, -1.2841e-23, -1.1904e-23,  ..., -5.7266e-23,\n",
      "           -5.4594e-23, -9.4092e-23],\n",
      "          [-2.0808e-23, -2.4563e-23, -2.4248e-23,  ..., -1.2943e-22,\n",
      "           -1.1207e-22, -1.4847e-22],\n",
      "          [-5.6620e-23, -5.4047e-23, -6.6297e-23,  ..., -2.1606e-22,\n",
      "           -2.3991e-22, -3.9226e-22]],\n",
      "\n",
      "         [[-2.5946e-27, -2.5487e-27, -4.9748e-27,  ..., -2.9873e-26,\n",
      "           -6.3779e-26, -1.0315e-25],\n",
      "          [-1.3256e-26, -2.0755e-26, -1.7552e-26,  ..., -1.6917e-25,\n",
      "           -1.4074e-25, -3.0949e-25],\n",
      "          [-4.4654e-26, -5.0879e-26, -5.3299e-26,  ..., -5.9428e-25,\n",
      "           -5.4137e-25, -7.4841e-25],\n",
      "          ...,\n",
      "          [-7.4026e-24, -1.2751e-23, -1.1883e-23,  ..., -5.6067e-23,\n",
      "           -5.7030e-23, -9.3715e-23],\n",
      "          [-2.0306e-23, -2.4804e-23, -2.5719e-23,  ..., -1.3773e-22,\n",
      "           -1.1201e-22, -1.4915e-22],\n",
      "          [-5.7827e-23, -5.5108e-23, -6.9021e-23,  ..., -2.2170e-22,\n",
      "           -2.3665e-22, -3.7539e-22]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0892e-15, -1.0755e-15, -1.1745e-15,  ..., -1.6665e-15,\n",
      "           -1.9733e-15, -2.0502e-15],\n",
      "          [-1.9186e-15, -2.4382e-15, -2.2253e-15,  ..., -3.7527e-15,\n",
      "           -3.3366e-15, -3.9453e-15],\n",
      "          [-2.5877e-15, -3.3475e-15, -3.1562e-15,  ..., -5.7012e-15,\n",
      "           -5.2689e-15, -6.4900e-15],\n",
      "          ...,\n",
      "          [-1.3207e-14, -1.7622e-14, -1.5809e-14,  ..., -2.8195e-14,\n",
      "           -2.7347e-14, -3.0253e-14],\n",
      "          [-1.6497e-14, -2.0825e-14, -2.1442e-14,  ..., -3.4082e-14,\n",
      "           -3.0572e-14, -3.7111e-14],\n",
      "          [-2.0667e-14, -2.2141e-14, -2.5486e-14,  ..., -3.2622e-14,\n",
      "           -3.3609e-14, -4.5112e-14]],\n",
      "\n",
      "         [[-1.0704e-15, -1.1032e-15, -1.2795e-15,  ..., -1.7938e-15,\n",
      "           -2.0689e-15, -2.2529e-15],\n",
      "          [-2.0834e-15, -2.4744e-15, -2.1400e-15,  ..., -4.0476e-15,\n",
      "           -3.5665e-15, -3.8881e-15],\n",
      "          [-2.7400e-15, -3.3307e-15, -3.2788e-15,  ..., -5.3991e-15,\n",
      "           -5.0400e-15, -5.9682e-15],\n",
      "          ...,\n",
      "          [-1.3981e-14, -1.6756e-14, -1.5794e-14,  ..., -2.7355e-14,\n",
      "           -2.5654e-14, -3.2614e-14],\n",
      "          [-1.7907e-14, -2.0794e-14, -2.0192e-14,  ..., -3.7257e-14,\n",
      "           -3.1322e-14, -4.0265e-14],\n",
      "          [-2.0721e-14, -2.2071e-14, -2.4578e-14,  ..., -3.1260e-14,\n",
      "           -3.4042e-14, -4.4122e-14]],\n",
      "\n",
      "         [[-1.0786e-15, -1.1027e-15, -1.2469e-15,  ..., -1.6288e-15,\n",
      "           -2.0097e-15, -2.1589e-15],\n",
      "          [-2.0894e-15, -2.4421e-15, -2.1969e-15,  ..., -4.0649e-15,\n",
      "           -3.6823e-15, -4.0193e-15],\n",
      "          [-2.7608e-15, -3.1727e-15, -3.3105e-15,  ..., -5.5460e-15,\n",
      "           -5.0488e-15, -5.9713e-15],\n",
      "          ...,\n",
      "          [-1.4092e-14, -1.7128e-14, -1.5707e-14,  ..., -2.7449e-14,\n",
      "           -2.5677e-14, -3.0583e-14],\n",
      "          [-1.6742e-14, -2.1301e-14, -2.0304e-14,  ..., -3.4113e-14,\n",
      "           -3.0600e-14, -3.8048e-14],\n",
      "          [-2.1367e-14, -2.3545e-14, -2.4599e-14,  ..., -3.2266e-14,\n",
      "           -3.5968e-14, -4.3812e-14]]],\n",
      "\n",
      "\n",
      "        [[[-5.8022e-18, -4.4677e-18, -1.2542e-18,  ..., -1.4901e-17,\n",
      "            6.1056e-19, -1.3658e-17],\n",
      "          [-1.1210e-17, -1.4656e-17, -1.6481e-17,  ...,  2.5842e-17,\n",
      "            4.0384e-17, -4.1534e-17],\n",
      "          [-9.4559e-18,  3.5878e-18, -2.9488e-17,  ..., -2.9329e-17,\n",
      "           -4.1060e-17,  1.2622e-17],\n",
      "          ...,\n",
      "          [ 1.8748e-17,  1.0423e-17, -1.0530e-17,  ...,  6.2136e-18,\n",
      "            4.7048e-17,  3.4976e-17],\n",
      "          [ 4.2745e-17, -1.0426e-17, -2.8715e-17,  ...,  6.9697e-18,\n",
      "            2.6408e-17,  3.6244e-17],\n",
      "          [-1.7846e-17, -5.9400e-18,  9.7196e-18,  ..., -4.6297e-17,\n",
      "            2.3538e-17, -5.7339e-17]],\n",
      "\n",
      "         [[-2.2320e-18, -1.1382e-17,  4.2988e-20,  ..., -4.1990e-18,\n",
      "           -3.6122e-18, -9.0522e-18],\n",
      "          [-4.3768e-18,  1.9451e-17, -2.2040e-17,  ..., -3.1115e-18,\n",
      "           -1.2360e-17, -6.2767e-18],\n",
      "          [-2.4579e-18, -3.2304e-18,  6.6907e-19,  ...,  2.7848e-17,\n",
      "           -7.1587e-18, -1.7974e-19],\n",
      "          ...,\n",
      "          [ 2.3492e-17, -2.7479e-17,  2.1706e-17,  ...,  1.7218e-17,\n",
      "            2.9264e-17, -5.8105e-17],\n",
      "          [-2.7788e-17, -4.0736e-17, -2.0841e-17,  ..., -1.4975e-17,\n",
      "            8.8980e-17,  2.0083e-17],\n",
      "          [ 5.6872e-18,  2.9835e-17,  7.6219e-18,  ..., -3.7881e-17,\n",
      "            1.4488e-17,  1.3103e-17]],\n",
      "\n",
      "         [[-1.3909e-18, -9.4286e-18, -1.3700e-18,  ..., -2.5793e-18,\n",
      "           -1.8565e-17, -2.2894e-18],\n",
      "          [-1.4254e-17,  1.8022e-18, -8.1017e-18,  ..., -1.7627e-17,\n",
      "            1.8601e-17,  4.0351e-18],\n",
      "          [ 4.8563e-18, -2.1903e-17,  1.6503e-17,  ...,  1.7239e-17,\n",
      "            9.7816e-18,  2.5088e-17],\n",
      "          ...,\n",
      "          [-2.4515e-17, -1.0033e-17,  3.1701e-17,  ...,  1.7329e-17,\n",
      "           -1.0639e-17,  1.0607e-17],\n",
      "          [-3.8673e-18, -3.4532e-17,  2.2965e-17,  ...,  1.8086e-17,\n",
      "            5.9549e-17, -3.9527e-17],\n",
      "          [-8.3614e-18, -2.4074e-17, -2.0948e-17,  ..., -4.6452e-18,\n",
      "           -4.8435e-17,  2.4690e-17]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0718e-05, -8.3037e-07, -5.1335e-04,  ...,  1.8310e-04,\n",
      "            3.3631e-04, -4.8450e-04],\n",
      "          [-3.4495e-04, -2.4594e-04,  3.5630e-05,  ..., -5.2527e-05,\n",
      "            1.7967e-04, -1.6849e-04],\n",
      "          [ 3.0651e-04,  1.5168e-04, -4.7015e-04,  ..., -4.3360e-04,\n",
      "            4.1539e-04,  3.6103e-04],\n",
      "          ...,\n",
      "          [ 2.0312e-05,  3.1917e-04, -1.7852e-04,  ..., -9.2287e-05,\n",
      "            3.7217e-04, -4.1951e-04],\n",
      "          [ 3.0430e-04,  1.8958e-04,  1.5201e-04,  ..., -3.7113e-04,\n",
      "            1.4041e-04, -3.7126e-04],\n",
      "          [ 3.6718e-04,  3.4368e-04,  3.8236e-04,  ..., -3.8414e-04,\n",
      "            3.3926e-04, -4.0066e-04]],\n",
      "\n",
      "         [[ 5.6445e-05, -3.2983e-04, -1.7767e-04,  ...,  4.5748e-04,\n",
      "           -2.4202e-05,  3.6023e-04],\n",
      "          [-9.5743e-05, -2.9503e-04,  2.6095e-04,  ..., -4.3510e-04,\n",
      "            3.4200e-04,  2.5826e-04],\n",
      "          [ 4.2053e-04,  3.8670e-04, -4.1432e-04,  ...,  2.3891e-05,\n",
      "           -4.4327e-04,  3.9357e-04],\n",
      "          ...,\n",
      "          [-3.6729e-04, -2.7417e-04,  3.9562e-04,  ...,  6.7195e-05,\n",
      "           -6.1869e-05,  2.4896e-04],\n",
      "          [-1.7703e-04,  4.8066e-04, -3.6675e-04,  ...,  1.7645e-04,\n",
      "           -2.6430e-04,  1.5876e-04],\n",
      "          [ 1.1486e-05, -4.6011e-04,  2.9508e-05,  ...,  2.1002e-04,\n",
      "           -2.4195e-04, -6.4697e-05]],\n",
      "\n",
      "         [[ 4.9076e-04, -3.0006e-04, -6.0800e-05,  ...,  4.5619e-04,\n",
      "            9.6466e-05, -2.8134e-04],\n",
      "          [ 6.4173e-05, -4.5140e-04,  3.4104e-04,  ...,  5.1249e-05,\n",
      "            2.4474e-04,  5.7795e-05],\n",
      "          [ 2.6079e-04, -1.5957e-04, -4.1118e-04,  ...,  3.2108e-04,\n",
      "            4.3956e-04,  2.6250e-04],\n",
      "          ...,\n",
      "          [ 1.0539e-04,  4.1401e-04,  3.0641e-05,  ..., -1.5906e-04,\n",
      "           -2.0489e-04, -2.5976e-04],\n",
      "          [ 2.6158e-04, -2.1948e-05,  2.8889e-04,  ..., -9.8925e-05,\n",
      "           -1.8603e-04,  9.2031e-05],\n",
      "          [ 1.0292e-04,  1.9290e-04,  1.8561e-04,  ...,  5.1059e-05,\n",
      "           -4.2191e-04,  2.9483e-04]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "i = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        if i == index:\n",
    "            print(\"i is: \", i)\n",
    "            print(\"The weights are: \", m.weight)\n",
    "        i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of layers that the loaded model has, is:  3\n"
     ]
    }
   ],
   "source": [
    "layers_weights_list = []\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        weights = m.weight\n",
    "        layers_weights_list.append(weights)\n",
    "print(\"The number of layers that the loaded model has, is: \", len(layers_weights_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the module's weight from one model to another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_latentSpace(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # N, 1, 28, 28\n",
    "        # 32, 3, 224, 224\n",
    "        input_channels = 3              # number of channels of the input image\n",
    "        output_channels = 110           # ~= 224/2. Shape of the input image \n",
    "        kernel_size = 9\n",
    "        padding_val = 1\n",
    "        stride_val = 5\n",
    "\n",
    "        \n",
    "        output_channels_layer2 = output_channels*2+5\n",
    "\n",
    "        output_channels_layer3 = output_channels_layer2*2\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size, stride=stride_val, padding=padding_val),         # input image channels, output channels, kernel size (filter). Dimension rseult: -> N, 110, 44, 44\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels, output_channels_layer2, kernel_size, stride=stride_val, padding=padding_val), # -> N, 225, 8, 8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels_layer2, output_channels_layer3, 8) # -> N, 450, 1, 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"This is the forward function\")\n",
    "        encoded = self.encoder(x)\n",
    "        return encoded\n",
    "    \n",
    "    def show_modules(self):\n",
    "        print(\"This is the show modules function\")\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            print(m)\n",
    "            print(\"i is: \", i)\n",
    "            print(\"print the next module\")\n",
    "            i = i +1\n",
    "            \n",
    "    def show_one_layer_weights(self, index):\n",
    "        print(\"This is the one layer show function\")\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if i == index:\n",
    "                    print(\"i is: \", i)\n",
    "                    print(\"The weights are: \", m.weight)\n",
    "                i = i +1\n",
    "    \n",
    "    def update_weights(self):\n",
    "        print(\"updating weights function\")\n",
    "        i = 0\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight = layers_weights_list[i]\n",
    "                i = i +1\n",
    "\n",
    "                                        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder_latentSpace(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 110, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(110, 225, kernel_size=(9, 9), stride=(5, 5), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(225, 450, kernel_size=(8, 8), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_encoder = Autoencoder_latentSpace()\n",
    "model_encoder.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the one layer show function\n",
      "i is:  0\n",
      "The weights are:  Parameter containing:\n",
      "tensor([[[[ 3.3392e-02,  2.2409e-02, -3.8792e-02,  ...,  5.4667e-02,\n",
      "            5.9006e-02,  5.3364e-02],\n",
      "          [ 1.6736e-02, -7.1535e-03,  2.0550e-02,  ...,  1.8592e-02,\n",
      "            4.5952e-02, -1.2595e-02],\n",
      "          [-6.1557e-02, -6.4580e-03,  5.1659e-02,  ...,  5.3984e-02,\n",
      "            4.5898e-02, -4.1804e-02],\n",
      "          ...,\n",
      "          [-2.3153e-02,  5.7760e-02,  1.6386e-02,  ...,  4.0419e-02,\n",
      "            4.5814e-03,  7.0551e-03],\n",
      "          [-1.6938e-02, -5.6432e-02, -2.7853e-02,  ..., -9.7158e-03,\n",
      "            5.7616e-02, -4.4329e-02],\n",
      "          [ 3.4902e-02, -3.4814e-02,  6.0527e-03,  ...,  6.0996e-02,\n",
      "            5.6372e-02,  3.7518e-03]],\n",
      "\n",
      "         [[ 6.0134e-02,  1.2237e-02,  5.0106e-02,  ...,  5.8166e-02,\n",
      "           -1.9240e-02,  4.3080e-02],\n",
      "          [ 4.1988e-02,  1.3859e-02, -1.8777e-02,  ...,  2.8582e-03,\n",
      "            2.7002e-02, -3.0450e-02],\n",
      "          [-4.9714e-02,  5.1276e-02, -1.7133e-02,  ..., -2.6592e-03,\n",
      "            6.7957e-03,  1.8360e-02],\n",
      "          ...,\n",
      "          [-2.2355e-02, -1.2716e-02,  3.4367e-02,  ..., -3.3518e-02,\n",
      "            5.3369e-05, -1.8085e-02],\n",
      "          [-3.0328e-02, -6.3069e-02,  6.8803e-03,  ..., -2.1833e-02,\n",
      "            4.0449e-02,  3.1221e-02],\n",
      "          [-5.4424e-02, -3.7407e-02, -2.7330e-02,  ...,  2.7002e-02,\n",
      "           -2.3166e-02,  2.5744e-02]],\n",
      "\n",
      "         [[ 4.7325e-02,  2.5352e-02, -5.1483e-02,  ..., -4.3688e-02,\n",
      "            1.0419e-02,  2.8770e-02],\n",
      "          [ 1.1770e-02,  5.5749e-02,  5.2993e-02,  ...,  5.8084e-02,\n",
      "            3.5219e-02, -1.9219e-02],\n",
      "          [ 7.3001e-03,  1.9685e-02, -4.0550e-02,  ...,  1.3211e-02,\n",
      "           -3.0625e-02, -4.8096e-03],\n",
      "          ...,\n",
      "          [ 5.2665e-02, -1.2349e-02,  7.8293e-03,  ..., -1.1212e-02,\n",
      "           -1.0824e-03, -1.0100e-02],\n",
      "          [ 6.3475e-02, -5.5569e-03,  5.5699e-03,  ..., -1.7355e-02,\n",
      "            2.1717e-03,  6.2661e-02],\n",
      "          [ 5.2457e-02,  6.0094e-02,  4.7106e-02,  ..., -5.5956e-02,\n",
      "           -5.1991e-02, -2.2296e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6622e-03, -4.2107e-02,  1.4920e-02,  ..., -1.6167e-02,\n",
      "           -3.5825e-02, -1.3570e-02],\n",
      "          [-2.4213e-02, -6.1671e-02,  1.9342e-02,  ..., -3.4322e-02,\n",
      "            6.2381e-02, -3.0019e-02],\n",
      "          [ 4.9423e-02,  1.3827e-02,  1.1330e-02,  ..., -2.7776e-02,\n",
      "           -5.3333e-02,  6.1714e-02],\n",
      "          ...,\n",
      "          [ 3.6424e-02,  4.5209e-02, -2.5413e-02,  ..., -7.1288e-03,\n",
      "            1.6641e-02,  2.3775e-02],\n",
      "          [-1.0016e-03, -2.1634e-02, -3.9600e-02,  ..., -7.7698e-03,\n",
      "            3.3888e-03, -7.7919e-03],\n",
      "          [ 2.8251e-02, -6.1558e-02, -1.3219e-02,  ..., -1.7194e-02,\n",
      "           -2.3099e-02, -1.1188e-02]],\n",
      "\n",
      "         [[ 4.5494e-02, -2.2811e-02,  5.2150e-02,  ..., -4.2954e-02,\n",
      "           -4.6841e-02,  7.4720e-04],\n",
      "          [ 4.9180e-02, -6.3490e-02, -1.5239e-02,  ..., -5.7232e-02,\n",
      "           -5.2396e-02, -3.9563e-03],\n",
      "          [ 1.1743e-02,  5.9073e-02, -5.8459e-02,  ...,  6.4086e-02,\n",
      "            1.7673e-02, -8.2145e-03],\n",
      "          ...,\n",
      "          [-4.4043e-02, -3.3390e-02,  3.2372e-02,  ..., -1.2326e-02,\n",
      "            2.8145e-02,  3.8482e-02],\n",
      "          [-2.6904e-02,  6.1291e-02, -2.3318e-02,  ...,  3.3309e-02,\n",
      "            6.2865e-02,  8.6896e-03],\n",
      "          [ 5.1840e-02, -3.1867e-02,  7.7216e-03,  ...,  3.7011e-02,\n",
      "            1.8805e-02,  6.1473e-02]],\n",
      "\n",
      "         [[ 3.3507e-02, -3.9698e-02, -1.3636e-02,  ...,  4.7441e-02,\n",
      "            3.9850e-02, -3.1170e-02],\n",
      "          [ 2.3384e-02, -1.0345e-02, -3.0346e-02,  ...,  5.1760e-02,\n",
      "           -6.8599e-04,  6.2895e-02],\n",
      "          [-5.6116e-02, -4.7250e-02, -5.5028e-02,  ..., -2.0328e-02,\n",
      "            4.6938e-02,  2.0030e-02],\n",
      "          ...,\n",
      "          [ 1.7389e-02, -3.5635e-02,  3.8047e-02,  ...,  5.5939e-02,\n",
      "           -2.6164e-02, -1.0917e-03],\n",
      "          [ 4.0283e-02, -1.4097e-02,  3.4168e-02,  ...,  3.4779e-02,\n",
      "            3.1434e-02,  4.2574e-02],\n",
      "          [-4.1360e-02,  5.8976e-02, -4.7214e-02,  ..., -5.5081e-02,\n",
      "           -2.9735e-03,  4.6815e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.0456e-02, -4.5972e-04,  1.2322e-02,  ..., -3.9578e-02,\n",
      "            3.4114e-02, -5.7286e-02],\n",
      "          [ 1.3444e-02,  5.3858e-02,  3.3084e-02,  ..., -2.0635e-02,\n",
      "            4.3199e-02, -3.5338e-02],\n",
      "          [ 3.8936e-02, -4.5623e-02,  5.8052e-02,  ..., -5.5517e-02,\n",
      "           -2.8106e-02,  7.9640e-03],\n",
      "          ...,\n",
      "          [-2.7774e-02,  7.7142e-03, -3.1100e-02,  ..., -2.7147e-02,\n",
      "           -5.6665e-02,  1.4170e-03],\n",
      "          [ 4.5721e-02,  1.9952e-02, -1.1553e-02,  ..., -6.1592e-02,\n",
      "           -4.0203e-02, -2.2280e-03],\n",
      "          [-8.5645e-03,  3.4494e-02, -4.9760e-02,  ..., -3.4996e-03,\n",
      "            4.8233e-02, -5.8426e-02]],\n",
      "\n",
      "         [[ 2.3276e-02, -2.0258e-02,  1.9724e-02,  ..., -2.8443e-02,\n",
      "           -1.8336e-02, -4.0673e-02],\n",
      "          [-4.3543e-02,  6.0672e-02,  4.8833e-02,  ...,  5.0458e-02,\n",
      "           -4.0132e-02, -2.0528e-02],\n",
      "          [ 3.1806e-02,  4.6112e-02,  3.5832e-02,  ...,  6.1468e-02,\n",
      "           -2.5420e-02, -4.0976e-02],\n",
      "          ...,\n",
      "          [-5.3747e-02,  1.9144e-02, -1.7202e-02,  ..., -9.1734e-03,\n",
      "           -6.4468e-03, -3.8813e-02],\n",
      "          [ 5.5818e-02,  1.2343e-02,  3.0303e-02,  ...,  4.7777e-02,\n",
      "           -3.0552e-02, -4.7572e-02],\n",
      "          [ 5.6057e-02, -4.2578e-02,  5.2154e-02,  ...,  5.1443e-02,\n",
      "            2.1874e-03, -6.4423e-03]],\n",
      "\n",
      "         [[-1.9309e-02, -2.7050e-02, -2.3194e-02,  ..., -4.3176e-02,\n",
      "           -6.1486e-02, -1.9025e-02],\n",
      "          [-4.8466e-02,  5.8164e-02,  4.5307e-02,  ...,  1.8006e-03,\n",
      "           -1.9728e-02,  1.9524e-02],\n",
      "          [ 9.0608e-03,  1.7524e-03, -5.9240e-02,  ..., -1.1934e-02,\n",
      "           -2.2335e-02, -5.2730e-02],\n",
      "          ...,\n",
      "          [ 4.1038e-02, -3.2648e-02, -6.7155e-03,  ...,  7.2152e-03,\n",
      "            3.8145e-02,  4.7480e-02],\n",
      "          [-3.6841e-02,  3.8531e-02, -6.2672e-02,  ...,  5.8281e-02,\n",
      "           -4.8256e-03, -2.0764e-02],\n",
      "          [-2.8094e-02,  7.5292e-03, -2.0195e-02,  ...,  1.7644e-02,\n",
      "           -3.3497e-02, -1.3097e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.9953e-03,  1.2423e-02,  2.4169e-02,  ..., -1.3474e-02,\n",
      "           -9.5377e-03, -5.3616e-02],\n",
      "          [-5.1637e-02,  2.2446e-02, -6.1960e-03,  ..., -5.7300e-02,\n",
      "            4.2132e-02,  3.9151e-03],\n",
      "          [ 3.7680e-02, -4.0308e-02, -5.0571e-02,  ...,  4.0598e-02,\n",
      "           -1.7967e-02,  4.1440e-02],\n",
      "          ...,\n",
      "          [ 4.8941e-02,  1.5831e-02,  2.3599e-02,  ..., -4.7648e-02,\n",
      "           -5.1477e-02,  5.9891e-02],\n",
      "          [ 2.6997e-02, -8.5740e-03, -4.1246e-02,  ..., -5.2151e-02,\n",
      "            1.8041e-03,  3.7464e-04],\n",
      "          [ 5.3442e-02, -5.8287e-02,  2.1674e-03,  ..., -2.7086e-02,\n",
      "            5.7076e-02, -5.3599e-02]],\n",
      "\n",
      "         [[ 5.9386e-02, -4.3715e-02, -4.6667e-02,  ..., -2.2922e-02,\n",
      "            3.5115e-02, -3.5298e-02],\n",
      "          [ 2.8480e-02, -2.9464e-02, -3.7292e-02,  ...,  2.8856e-02,\n",
      "           -7.1152e-03, -1.6289e-02],\n",
      "          [ 3.1105e-02, -5.7532e-02, -8.6090e-03,  ...,  1.7137e-02,\n",
      "           -3.9768e-03, -4.6112e-02],\n",
      "          ...,\n",
      "          [ 6.0875e-02, -4.4364e-02,  1.8442e-02,  ..., -2.5706e-02,\n",
      "            3.0126e-02, -4.5456e-02],\n",
      "          [ 3.7132e-02, -5.4252e-02,  6.5911e-03,  ...,  2.3083e-03,\n",
      "            5.2496e-02, -3.6330e-02],\n",
      "          [-2.4965e-02, -4.9388e-02, -1.1544e-03,  ...,  3.5498e-02,\n",
      "           -7.5238e-03,  4.7471e-02]],\n",
      "\n",
      "         [[ 3.2172e-02, -7.8977e-03, -5.3659e-05,  ..., -4.5006e-02,\n",
      "            9.3809e-03,  4.1908e-02],\n",
      "          [ 9.9450e-05, -3.9945e-02, -1.8033e-02,  ...,  6.3857e-02,\n",
      "            5.0176e-02,  6.0822e-02],\n",
      "          [ 4.0594e-02,  4.3117e-02, -5.3807e-02,  ...,  7.4991e-03,\n",
      "            5.1559e-02, -5.9831e-02],\n",
      "          ...,\n",
      "          [ 5.5395e-02, -3.7706e-02, -1.0486e-02,  ...,  5.6312e-02,\n",
      "            2.6788e-02,  1.4980e-02],\n",
      "          [-2.3397e-02, -3.1592e-03,  1.9970e-02,  ...,  5.3209e-02,\n",
      "            3.2401e-03,  6.5677e-03],\n",
      "          [ 9.1692e-03, -1.0046e-02, -2.4973e-02,  ..., -2.7673e-02,\n",
      "            7.1942e-03, -6.4074e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.6861e-03,  4.5149e-02,  6.2111e-02,  ..., -1.8633e-03,\n",
      "           -3.1730e-03,  3.6126e-02],\n",
      "          [ 3.7874e-02, -3.2119e-04, -2.6004e-03,  ..., -7.6013e-03,\n",
      "           -3.5383e-02, -5.4999e-02],\n",
      "          [-5.3222e-02, -6.2091e-02,  2.9334e-02,  ..., -4.6450e-03,\n",
      "            6.2916e-02, -3.5600e-02],\n",
      "          ...,\n",
      "          [-5.3494e-02, -3.1991e-02, -5.2904e-02,  ..., -5.1697e-02,\n",
      "            3.7527e-02, -2.8422e-02],\n",
      "          [ 2.8641e-02, -3.2805e-02,  5.7201e-02,  ...,  5.1807e-02,\n",
      "            4.5486e-02, -4.2166e-02],\n",
      "          [ 3.9368e-03,  3.5285e-02, -3.9844e-02,  ...,  3.9149e-02,\n",
      "           -2.0743e-02,  3.0252e-04]],\n",
      "\n",
      "         [[-2.7658e-02,  5.5452e-02, -6.0442e-02,  ...,  2.5527e-02,\n",
      "            3.6443e-02, -5.0618e-03],\n",
      "          [ 3.7638e-03,  1.8421e-03, -6.2447e-02,  ..., -1.6976e-02,\n",
      "           -5.5748e-03,  3.9063e-02],\n",
      "          [-3.8075e-02,  6.3068e-02,  1.5262e-02,  ...,  2.3443e-03,\n",
      "           -2.1133e-03,  4.8371e-03],\n",
      "          ...,\n",
      "          [ 1.6753e-02, -1.6703e-02,  4.4700e-02,  ...,  1.9882e-02,\n",
      "            5.9546e-02, -2.3014e-02],\n",
      "          [-1.3776e-02, -2.0348e-02, -6.1973e-03,  ...,  5.1652e-02,\n",
      "            2.9168e-02, -1.7475e-02],\n",
      "          [ 3.0315e-02,  7.8484e-05, -6.0198e-02,  ...,  5.4355e-02,\n",
      "           -4.5291e-02, -3.8031e-02]],\n",
      "\n",
      "         [[ 2.2734e-02,  4.0535e-02,  4.7661e-02,  ..., -1.8499e-03,\n",
      "            2.4867e-02, -5.0281e-02],\n",
      "          [ 1.8438e-02,  1.7083e-02, -6.0310e-02,  ...,  1.2008e-02,\n",
      "           -3.1466e-02, -6.0376e-02],\n",
      "          [ 5.2867e-03,  3.0423e-03, -6.4024e-02,  ...,  4.2561e-02,\n",
      "           -1.1210e-02, -6.3132e-02],\n",
      "          ...,\n",
      "          [ 2.2593e-02,  6.1236e-02, -9.4199e-03,  ...,  5.5455e-02,\n",
      "           -1.9951e-02,  5.6055e-02],\n",
      "          [-4.8804e-02, -4.8896e-02, -2.5136e-02,  ..., -4.7483e-02,\n",
      "            5.4334e-02,  3.5702e-02],\n",
      "          [ 6.0871e-02,  3.4730e-02, -2.1096e-02,  ...,  1.9460e-02,\n",
      "            7.2394e-03,  2.4974e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6832e-02,  5.8683e-02,  5.4708e-02,  ..., -3.6514e-02,\n",
      "            5.2624e-02,  2.3501e-02],\n",
      "          [-3.9888e-03,  4.2071e-02, -5.1915e-02,  ..., -1.7305e-02,\n",
      "            5.2720e-02, -1.2811e-02],\n",
      "          [-3.7213e-02, -9.2465e-04, -5.7880e-02,  ...,  3.7568e-02,\n",
      "           -6.2604e-02,  3.6088e-03],\n",
      "          ...,\n",
      "          [ 5.7199e-02, -5.1817e-02, -4.1494e-02,  ..., -2.3963e-02,\n",
      "           -2.4045e-02, -6.1064e-02],\n",
      "          [ 4.5361e-02,  2.1983e-02,  2.2987e-02,  ..., -4.6641e-02,\n",
      "            4.8505e-02,  1.8957e-02],\n",
      "          [-3.4105e-03,  1.8057e-02,  1.8824e-02,  ...,  5.8879e-02,\n",
      "           -5.5291e-02,  4.2733e-02]],\n",
      "\n",
      "         [[ 4.9580e-02,  2.3859e-03,  5.0385e-02,  ...,  4.8462e-02,\n",
      "            2.2780e-02,  2.9510e-04],\n",
      "          [-5.8264e-02,  4.7458e-02, -2.3948e-02,  ..., -5.3988e-02,\n",
      "            5.5417e-02, -4.0340e-02],\n",
      "          [-9.4271e-04,  5.2752e-02, -1.7009e-02,  ..., -6.3611e-02,\n",
      "            5.6456e-02, -4.1818e-03],\n",
      "          ...,\n",
      "          [-7.7320e-03, -2.4222e-02, -5.8916e-02,  ...,  3.7773e-02,\n",
      "            3.6271e-03, -3.7773e-02],\n",
      "          [-3.7985e-02,  7.6699e-04,  9.5160e-03,  ...,  2.7652e-02,\n",
      "           -4.3883e-02,  5.0436e-02],\n",
      "          [ 4.3104e-02,  6.0521e-02, -1.4946e-02,  ..., -6.0259e-02,\n",
      "            4.1459e-02, -9.2306e-03]],\n",
      "\n",
      "         [[ 1.8685e-02, -4.6466e-02, -5.0519e-02,  ...,  5.4119e-02,\n",
      "           -3.1669e-02,  1.4920e-02],\n",
      "          [ 1.5605e-02, -3.9499e-02,  2.9712e-02,  ..., -2.5881e-02,\n",
      "            3.8563e-03,  3.1948e-02],\n",
      "          [-4.1704e-02, -9.8256e-03, -4.3224e-02,  ...,  4.2208e-02,\n",
      "            1.2107e-02, -4.0336e-02],\n",
      "          ...,\n",
      "          [-5.7412e-02,  2.6019e-02, -1.7833e-03,  ..., -3.1536e-02,\n",
      "           -6.2814e-02, -3.9693e-02],\n",
      "          [ 6.0802e-02,  5.6483e-02,  3.0505e-02,  ..., -1.0978e-02,\n",
      "            6.2349e-02,  5.1617e-02],\n",
      "          [ 4.0071e-02,  2.3678e-04, -1.0312e-02,  ..., -7.1175e-03,\n",
      "            4.7168e-03, -1.8796e-02]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model_encoder.show_one_layer_weights(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating weights function\n"
     ]
    }
   ],
   "source": [
    "model_encoder.update_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the one layer show function\n",
      "i is:  0\n",
      "The weights are:  Parameter containing:\n",
      "tensor([[[[-1.6085e-25, -1.6363e-25, -1.6663e-25,  ..., -1.7430e-25,\n",
      "           -1.7557e-25, -1.7903e-25],\n",
      "          [-2.2771e-25, -2.5256e-25, -2.5323e-25,  ..., -2.6019e-25,\n",
      "           -2.5946e-25, -2.5337e-25],\n",
      "          [-2.5053e-25, -2.6664e-25, -2.5478e-25,  ..., -2.7490e-25,\n",
      "           -2.6799e-25, -2.6038e-25],\n",
      "          ...,\n",
      "          [-2.6943e-25, -2.8397e-25, -2.8483e-25,  ..., -3.0378e-25,\n",
      "           -2.9532e-25, -2.8298e-25],\n",
      "          [-2.8312e-25, -2.8671e-25, -2.8712e-25,  ..., -2.9985e-25,\n",
      "           -2.9239e-25, -2.9911e-25],\n",
      "          [-2.9684e-25, -2.9257e-25, -2.9676e-25,  ..., -3.0312e-25,\n",
      "           -3.0702e-25, -3.0488e-25]],\n",
      "\n",
      "         [[-1.6082e-25, -1.6399e-25, -1.6598e-25,  ..., -1.7378e-25,\n",
      "           -1.7550e-25, -1.7926e-25],\n",
      "          [-2.2830e-25, -2.5180e-25, -2.5322e-25,  ..., -2.6058e-25,\n",
      "           -2.5928e-25, -2.5301e-25],\n",
      "          [-2.5050e-25, -2.6661e-25, -2.5564e-25,  ..., -2.7503e-25,\n",
      "           -2.6771e-25, -2.5857e-25],\n",
      "          ...,\n",
      "          [-2.6872e-25, -2.8534e-25, -2.8414e-25,  ..., -3.0381e-25,\n",
      "           -2.9534e-25, -2.8295e-25],\n",
      "          [-2.8099e-25, -2.8834e-25, -2.8683e-25,  ..., -2.9919e-25,\n",
      "           -2.9242e-25, -2.9741e-25],\n",
      "          [-2.9452e-25, -2.9257e-25, -2.9678e-25,  ..., -3.0313e-25,\n",
      "           -3.0708e-25, -3.0669e-25]],\n",
      "\n",
      "         [[-1.6087e-25, -1.6460e-25, -1.6687e-25,  ..., -1.7385e-25,\n",
      "           -1.7635e-25, -1.7635e-25],\n",
      "          [-2.2634e-25, -2.5031e-25, -2.5209e-25,  ..., -2.5893e-25,\n",
      "           -2.5896e-25, -2.5337e-25],\n",
      "          [-2.5050e-25, -2.6661e-25, -2.5441e-25,  ..., -2.7445e-25,\n",
      "           -2.6501e-25, -2.6041e-25],\n",
      "          ...,\n",
      "          [-2.6946e-25, -2.8447e-25, -2.8356e-25,  ..., -3.0337e-25,\n",
      "           -2.9386e-25, -2.8199e-25],\n",
      "          [-2.8318e-25, -2.8844e-25, -2.8712e-25,  ..., -2.9845e-25,\n",
      "           -2.8878e-25, -2.9910e-25],\n",
      "          [-2.9603e-25, -2.9085e-25, -2.9577e-25,  ..., -3.0305e-25,\n",
      "           -3.0709e-25, -3.0806e-25]]],\n",
      "\n",
      "\n",
      "        [[[-1.0727e-09, -1.2467e-09, -1.2752e-09,  ..., -1.3815e-09,\n",
      "           -1.3804e-09, -1.4093e-09],\n",
      "          [-4.8281e-09, -5.7444e-09, -5.5169e-09,  ..., -6.1804e-09,\n",
      "           -5.9607e-09, -5.9956e-09],\n",
      "          [-4.8653e-09, -5.8955e-09, -5.7366e-09,  ..., -6.5313e-09,\n",
      "           -6.3610e-09, -6.3550e-09],\n",
      "          ...,\n",
      "          [-6.5471e-09, -7.7374e-09, -7.6077e-09,  ..., -8.3837e-09,\n",
      "           -8.0526e-09, -8.0958e-09],\n",
      "          [-6.6398e-09, -7.9600e-09, -7.7515e-09,  ..., -8.6601e-09,\n",
      "           -8.5860e-09, -8.3701e-09],\n",
      "          [-5.9810e-09, -6.8377e-09, -7.0700e-09,  ..., -7.4223e-09,\n",
      "           -7.6548e-09, -7.9500e-09]],\n",
      "\n",
      "         [[-1.0509e-09, -1.2568e-09, -1.2899e-09,  ..., -1.3348e-09,\n",
      "           -1.4215e-09, -1.3866e-09],\n",
      "          [-4.8179e-09, -5.6788e-09, -5.5128e-09,  ..., -6.1494e-09,\n",
      "           -6.0008e-09, -5.9550e-09],\n",
      "          [-4.8721e-09, -5.9222e-09, -5.7540e-09,  ..., -6.5813e-09,\n",
      "           -6.3536e-09, -6.3902e-09],\n",
      "          ...,\n",
      "          [-6.4751e-09, -7.8155e-09, -7.5744e-09,  ..., -8.1879e-09,\n",
      "           -8.0351e-09, -8.1304e-09],\n",
      "          [-6.6994e-09, -7.9453e-09, -7.7833e-09,  ..., -8.6029e-09,\n",
      "           -8.5038e-09, -8.3584e-09],\n",
      "          [-5.9722e-09, -6.8607e-09, -7.0555e-09,  ..., -7.4304e-09,\n",
      "           -7.5727e-09, -8.0404e-09]],\n",
      "\n",
      "         [[-1.0659e-09, -1.2485e-09, -1.2510e-09,  ..., -1.3357e-09,\n",
      "           -1.4051e-09, -1.4058e-09],\n",
      "          [-4.8855e-09, -5.7471e-09, -5.5161e-09,  ..., -6.1354e-09,\n",
      "           -5.9259e-09, -5.9551e-09],\n",
      "          [-4.8592e-09, -5.9811e-09, -5.8038e-09,  ..., -6.5657e-09,\n",
      "           -6.4136e-09, -6.4005e-09],\n",
      "          ...,\n",
      "          [-6.5056e-09, -7.7086e-09, -7.5397e-09,  ..., -8.4107e-09,\n",
      "           -8.0907e-09, -8.0406e-09],\n",
      "          [-6.5938e-09, -7.9014e-09, -7.7055e-09,  ..., -8.7724e-09,\n",
      "           -8.3818e-09, -8.4589e-09],\n",
      "          [-6.0150e-09, -6.8437e-09, -7.0120e-09,  ..., -7.4443e-09,\n",
      "           -7.6710e-09, -8.0442e-09]]],\n",
      "\n",
      "\n",
      "        [[[-2.6066e-27, -2.6440e-27, -4.9623e-27,  ..., -2.9732e-26,\n",
      "           -6.4868e-26, -1.0348e-25],\n",
      "          [-1.2778e-26, -1.9173e-26, -1.7339e-26,  ..., -1.7092e-25,\n",
      "           -1.4028e-25, -3.3008e-25],\n",
      "          [-4.4636e-26, -5.2706e-26, -5.7231e-26,  ..., -5.8360e-25,\n",
      "           -5.6028e-25, -7.4895e-25],\n",
      "          ...,\n",
      "          [-7.8231e-24, -1.2416e-23, -1.1949e-23,  ..., -5.6591e-23,\n",
      "           -5.4827e-23, -9.1408e-23],\n",
      "          [-1.9654e-23, -2.4449e-23, -2.4558e-23,  ..., -1.2964e-22,\n",
      "           -1.1230e-22, -1.4785e-22],\n",
      "          [-5.7975e-23, -5.4478e-23, -6.5906e-23,  ..., -2.1614e-22,\n",
      "           -2.4514e-22, -3.7824e-22]],\n",
      "\n",
      "         [[-2.5950e-27, -2.7446e-27, -4.9581e-27,  ..., -2.9773e-26,\n",
      "           -6.5088e-26, -1.0299e-25],\n",
      "          [-1.2759e-26, -2.1130e-26, -1.9126e-26,  ..., -1.6566e-25,\n",
      "           -1.4725e-25, -3.1577e-25],\n",
      "          [-4.8367e-26, -5.0795e-26, -5.7363e-26,  ..., -5.7905e-25,\n",
      "           -5.5476e-25, -7.7029e-25],\n",
      "          ...,\n",
      "          [-7.4026e-24, -1.2841e-23, -1.1904e-23,  ..., -5.7266e-23,\n",
      "           -5.4594e-23, -9.4092e-23],\n",
      "          [-2.0808e-23, -2.4563e-23, -2.4248e-23,  ..., -1.2943e-22,\n",
      "           -1.1207e-22, -1.4847e-22],\n",
      "          [-5.6620e-23, -5.4047e-23, -6.6297e-23,  ..., -2.1606e-22,\n",
      "           -2.3991e-22, -3.9226e-22]],\n",
      "\n",
      "         [[-2.5946e-27, -2.5487e-27, -4.9748e-27,  ..., -2.9873e-26,\n",
      "           -6.3779e-26, -1.0315e-25],\n",
      "          [-1.3256e-26, -2.0755e-26, -1.7552e-26,  ..., -1.6917e-25,\n",
      "           -1.4074e-25, -3.0949e-25],\n",
      "          [-4.4654e-26, -5.0879e-26, -5.3299e-26,  ..., -5.9428e-25,\n",
      "           -5.4137e-25, -7.4841e-25],\n",
      "          ...,\n",
      "          [-7.4026e-24, -1.2751e-23, -1.1883e-23,  ..., -5.6067e-23,\n",
      "           -5.7030e-23, -9.3715e-23],\n",
      "          [-2.0306e-23, -2.4804e-23, -2.5719e-23,  ..., -1.3773e-22,\n",
      "           -1.1201e-22, -1.4915e-22],\n",
      "          [-5.7827e-23, -5.5108e-23, -6.9021e-23,  ..., -2.2170e-22,\n",
      "           -2.3665e-22, -3.7539e-22]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0892e-15, -1.0755e-15, -1.1745e-15,  ..., -1.6665e-15,\n",
      "           -1.9733e-15, -2.0502e-15],\n",
      "          [-1.9186e-15, -2.4382e-15, -2.2253e-15,  ..., -3.7527e-15,\n",
      "           -3.3366e-15, -3.9453e-15],\n",
      "          [-2.5877e-15, -3.3475e-15, -3.1562e-15,  ..., -5.7012e-15,\n",
      "           -5.2689e-15, -6.4900e-15],\n",
      "          ...,\n",
      "          [-1.3207e-14, -1.7622e-14, -1.5809e-14,  ..., -2.8195e-14,\n",
      "           -2.7347e-14, -3.0253e-14],\n",
      "          [-1.6497e-14, -2.0825e-14, -2.1442e-14,  ..., -3.4082e-14,\n",
      "           -3.0572e-14, -3.7111e-14],\n",
      "          [-2.0667e-14, -2.2141e-14, -2.5486e-14,  ..., -3.2622e-14,\n",
      "           -3.3609e-14, -4.5112e-14]],\n",
      "\n",
      "         [[-1.0704e-15, -1.1032e-15, -1.2795e-15,  ..., -1.7938e-15,\n",
      "           -2.0689e-15, -2.2529e-15],\n",
      "          [-2.0834e-15, -2.4744e-15, -2.1400e-15,  ..., -4.0476e-15,\n",
      "           -3.5665e-15, -3.8881e-15],\n",
      "          [-2.7400e-15, -3.3307e-15, -3.2788e-15,  ..., -5.3991e-15,\n",
      "           -5.0400e-15, -5.9682e-15],\n",
      "          ...,\n",
      "          [-1.3981e-14, -1.6756e-14, -1.5794e-14,  ..., -2.7355e-14,\n",
      "           -2.5654e-14, -3.2614e-14],\n",
      "          [-1.7907e-14, -2.0794e-14, -2.0192e-14,  ..., -3.7257e-14,\n",
      "           -3.1322e-14, -4.0265e-14],\n",
      "          [-2.0721e-14, -2.2071e-14, -2.4578e-14,  ..., -3.1260e-14,\n",
      "           -3.4042e-14, -4.4122e-14]],\n",
      "\n",
      "         [[-1.0786e-15, -1.1027e-15, -1.2469e-15,  ..., -1.6288e-15,\n",
      "           -2.0097e-15, -2.1589e-15],\n",
      "          [-2.0894e-15, -2.4421e-15, -2.1969e-15,  ..., -4.0649e-15,\n",
      "           -3.6823e-15, -4.0193e-15],\n",
      "          [-2.7608e-15, -3.1727e-15, -3.3105e-15,  ..., -5.5460e-15,\n",
      "           -5.0488e-15, -5.9713e-15],\n",
      "          ...,\n",
      "          [-1.4092e-14, -1.7128e-14, -1.5707e-14,  ..., -2.7449e-14,\n",
      "           -2.5677e-14, -3.0583e-14],\n",
      "          [-1.6742e-14, -2.1301e-14, -2.0304e-14,  ..., -3.4113e-14,\n",
      "           -3.0600e-14, -3.8048e-14],\n",
      "          [-2.1367e-14, -2.3545e-14, -2.4599e-14,  ..., -3.2266e-14,\n",
      "           -3.5968e-14, -4.3812e-14]]],\n",
      "\n",
      "\n",
      "        [[[-5.8022e-18, -4.4677e-18, -1.2542e-18,  ..., -1.4901e-17,\n",
      "            6.1056e-19, -1.3658e-17],\n",
      "          [-1.1210e-17, -1.4656e-17, -1.6481e-17,  ...,  2.5842e-17,\n",
      "            4.0384e-17, -4.1534e-17],\n",
      "          [-9.4559e-18,  3.5878e-18, -2.9488e-17,  ..., -2.9329e-17,\n",
      "           -4.1060e-17,  1.2622e-17],\n",
      "          ...,\n",
      "          [ 1.8748e-17,  1.0423e-17, -1.0530e-17,  ...,  6.2136e-18,\n",
      "            4.7048e-17,  3.4976e-17],\n",
      "          [ 4.2745e-17, -1.0426e-17, -2.8715e-17,  ...,  6.9697e-18,\n",
      "            2.6408e-17,  3.6244e-17],\n",
      "          [-1.7846e-17, -5.9400e-18,  9.7196e-18,  ..., -4.6297e-17,\n",
      "            2.3538e-17, -5.7339e-17]],\n",
      "\n",
      "         [[-2.2320e-18, -1.1382e-17,  4.2988e-20,  ..., -4.1990e-18,\n",
      "           -3.6122e-18, -9.0522e-18],\n",
      "          [-4.3768e-18,  1.9451e-17, -2.2040e-17,  ..., -3.1115e-18,\n",
      "           -1.2360e-17, -6.2767e-18],\n",
      "          [-2.4579e-18, -3.2304e-18,  6.6907e-19,  ...,  2.7848e-17,\n",
      "           -7.1587e-18, -1.7974e-19],\n",
      "          ...,\n",
      "          [ 2.3492e-17, -2.7479e-17,  2.1706e-17,  ...,  1.7218e-17,\n",
      "            2.9264e-17, -5.8105e-17],\n",
      "          [-2.7788e-17, -4.0736e-17, -2.0841e-17,  ..., -1.4975e-17,\n",
      "            8.8980e-17,  2.0083e-17],\n",
      "          [ 5.6872e-18,  2.9835e-17,  7.6219e-18,  ..., -3.7881e-17,\n",
      "            1.4488e-17,  1.3103e-17]],\n",
      "\n",
      "         [[-1.3909e-18, -9.4286e-18, -1.3700e-18,  ..., -2.5793e-18,\n",
      "           -1.8565e-17, -2.2894e-18],\n",
      "          [-1.4254e-17,  1.8022e-18, -8.1017e-18,  ..., -1.7627e-17,\n",
      "            1.8601e-17,  4.0351e-18],\n",
      "          [ 4.8563e-18, -2.1903e-17,  1.6503e-17,  ...,  1.7239e-17,\n",
      "            9.7816e-18,  2.5088e-17],\n",
      "          ...,\n",
      "          [-2.4515e-17, -1.0033e-17,  3.1701e-17,  ...,  1.7329e-17,\n",
      "           -1.0639e-17,  1.0607e-17],\n",
      "          [-3.8673e-18, -3.4532e-17,  2.2965e-17,  ...,  1.8086e-17,\n",
      "            5.9549e-17, -3.9527e-17],\n",
      "          [-8.3614e-18, -2.4074e-17, -2.0948e-17,  ..., -4.6452e-18,\n",
      "           -4.8435e-17,  2.4690e-17]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0718e-05, -8.3037e-07, -5.1335e-04,  ...,  1.8310e-04,\n",
      "            3.3631e-04, -4.8450e-04],\n",
      "          [-3.4495e-04, -2.4594e-04,  3.5630e-05,  ..., -5.2527e-05,\n",
      "            1.7967e-04, -1.6849e-04],\n",
      "          [ 3.0651e-04,  1.5168e-04, -4.7015e-04,  ..., -4.3360e-04,\n",
      "            4.1539e-04,  3.6103e-04],\n",
      "          ...,\n",
      "          [ 2.0312e-05,  3.1917e-04, -1.7852e-04,  ..., -9.2287e-05,\n",
      "            3.7217e-04, -4.1951e-04],\n",
      "          [ 3.0430e-04,  1.8958e-04,  1.5201e-04,  ..., -3.7113e-04,\n",
      "            1.4041e-04, -3.7126e-04],\n",
      "          [ 3.6718e-04,  3.4368e-04,  3.8236e-04,  ..., -3.8414e-04,\n",
      "            3.3926e-04, -4.0066e-04]],\n",
      "\n",
      "         [[ 5.6445e-05, -3.2983e-04, -1.7767e-04,  ...,  4.5748e-04,\n",
      "           -2.4202e-05,  3.6023e-04],\n",
      "          [-9.5743e-05, -2.9503e-04,  2.6095e-04,  ..., -4.3510e-04,\n",
      "            3.4200e-04,  2.5826e-04],\n",
      "          [ 4.2053e-04,  3.8670e-04, -4.1432e-04,  ...,  2.3891e-05,\n",
      "           -4.4327e-04,  3.9357e-04],\n",
      "          ...,\n",
      "          [-3.6729e-04, -2.7417e-04,  3.9562e-04,  ...,  6.7195e-05,\n",
      "           -6.1869e-05,  2.4896e-04],\n",
      "          [-1.7703e-04,  4.8066e-04, -3.6675e-04,  ...,  1.7645e-04,\n",
      "           -2.6430e-04,  1.5876e-04],\n",
      "          [ 1.1486e-05, -4.6011e-04,  2.9508e-05,  ...,  2.1002e-04,\n",
      "           -2.4195e-04, -6.4697e-05]],\n",
      "\n",
      "         [[ 4.9076e-04, -3.0006e-04, -6.0800e-05,  ...,  4.5619e-04,\n",
      "            9.6466e-05, -2.8134e-04],\n",
      "          [ 6.4173e-05, -4.5140e-04,  3.4104e-04,  ...,  5.1249e-05,\n",
      "            2.4474e-04,  5.7795e-05],\n",
      "          [ 2.6079e-04, -1.5957e-04, -4.1118e-04,  ...,  3.2108e-04,\n",
      "            4.3956e-04,  2.6250e-04],\n",
      "          ...,\n",
      "          [ 1.0539e-04,  4.1401e-04,  3.0641e-05,  ..., -1.5906e-04,\n",
      "           -2.0489e-04, -2.5976e-04],\n",
      "          [ 2.6158e-04, -2.1948e-05,  2.8889e-04,  ..., -9.8925e-05,\n",
      "           -1.8603e-04,  9.2031e-05],\n",
      "          [ 1.0292e-04,  1.9290e-04,  1.8561e-04,  ...,  5.1059e-05,\n",
      "           -4.2191e-04,  2.9483e-04]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model_encoder.show_one_layer_weights(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Calculate KDE using sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "#Get encoded output of input images = Latent space\n",
    "# encoded_images = model_encoder(images)\n",
    "encoded_images = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    X = dataset[i]\n",
    "    image_in_tensor = X[0]\n",
    "    image_in_tensor = image_in_tensor.cuda()            # Because GPU is being used\n",
    "    with torch.no_grad():\n",
    "        Y = model_encoder(image_in_tensor)  # should be same as X\n",
    "    encoded_images.append(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(len(encoded_images))\n",
    "print(type(encoded_images))\n",
    "print(type(encoded_images[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that it is 179 length because it corresponds to all the images that belong to the training dataset. \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert \"encoded_images\" to a np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_encoded_images = []\n",
    "for i in range (len(encoded_images)):\n",
    "    # np_conversion = encoded_images[i].detach().numpy()        # If not using GPU\n",
    "    np_conversion = encoded_images[i].cpu().detach().numpy()    # If using GPU\n",
    "    np_encoded_images.append(np_conversion)\n",
    "np_encoded_images = np.array(np_encoded_images)\n",
    "print(type(np_encoded_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 450, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np_encoded_images.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, see above the shape of the representation of the original images has been lowered to (1, 1) as specified in the model structure. The number 450, on the other hand, corresponds to the channels of the image; this value started at 3 and layer by layer it incremented until reaching 450."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to flatten the data in order to apply kernel density on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "model_encoder_output_shape = (450,1,1)\n",
    "print(model_encoder_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vector_shape = model_encoder_output_shape[0]*model_encoder_output_shape[1]*model_encoder_output_shape[2]\n",
    "encoded_images_vector = [np.reshape(img, (out_vector_shape)) for img in np_encoded_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_images_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_images_vector[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(encoded_images_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function fits a kernel density estimation to the data that is provided, that is, to the \"encoded_images_vector\" variable. It does so using a Guassian kernel of bandwidth 0.2.\n",
    "\n",
    "The badnwidth parameter affects on how the selected kernel will fit each sample of the given data. For example for the case in which the kernel is a Gaussian distribution, the bandwidth parameter would affect in how thin or wide is the Gaussian distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in the variable \"kde\" we have some numbers that are the result of fitting Gaussian functions to the given data points in the variable \"encoded_images_vecotr\". We will use the \"kde\" variable later for scoring with it, some given data points; the scoring will be given depending on how similar are the given data points to the ones that it had estimated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below, it is shown the kde values corresponding to each encoded sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 306.23048203 306.23048203 306.23048203 306.23048203 306.23048203\n",
      " 306.23048203 306.23048203 306.2304823  306.2304823  306.23048203\n",
      " 306.23048203 306.23048203 306.23048203 306.23048203 306.23048203\n",
      " 306.23048203 306.23048214 306.23048214 306.23048203 306.23048203\n",
      " 306.23048203 306.23048203 306.23048203 306.23048203 306.23048203\n",
      " 306.23048203 306.23048203 306.2304823  306.2304823  306.23048203\n",
      " 306.23048203 306.23048203 306.23048203 306.23048203 306.23048203\n",
      " 306.23048203 306.23048214 306.23048214 306.23048203 306.23048203\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733486 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733486 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.56227943 305.53733947 305.56228394\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53740527 305.53740527 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733497 305.53733485 305.53733497\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485 305.53733485\n",
      " 305.53733485 305.53733485 305.53733485 305.53733485]\n"
     ]
    }
   ],
   "source": [
    "density_vals = kde.score_samples(encoded_images_vector)\n",
    "print(density_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the above density values are pretty much the same among them. This has to do with the new model that was trained. The previous model from the \"Pt_latentSpace_DS1\" program, makes these value to be more different among them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, the mean and standard deviation of these values are computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg of the density values is:  305.69250763044613\n",
      "The stdev_density of the density values is:  0.2886038372455375\n"
     ]
    }
   ],
   "source": [
    "average_density = np.mean(density_vals)\n",
    "stdev_density = np.std(density_vals)\n",
    "print(\"The avg of the density values is: \", average_density)\n",
    "print(\"The stdev_density of the density values is: \", stdev_density)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, the density calculation, was computed, in the video reference (https://www.youtube.com/watch?v=q_tpFGHiRgg&t=1140s&ab_channel=DigitalSreeni), in this manner.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg of the density values is:  305.69250763044613\n",
      "The stdev_density of the density values is:  0.2886038372455375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Calculate density and reconstruction error to find their means values for\n",
    "density_lst = []\n",
    "\n",
    "X = dataset[0]\n",
    "image_in_tensor = X[0]\n",
    "\n",
    "model_encoder_output_shape = (450,1,1)          # This is the shape of the last layer of the encoder model\n",
    "out_vector_shape = model_encoder_output_shape[0]*model_encoder_output_shape[1]*model_encoder_output_shape[2]\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    X = dataset[i]\n",
    "    image_in_tensor = X[0]\n",
    "    image_in_tensor = image_in_tensor.cuda()            # Because GPU is being used\n",
    "    with torch.no_grad():\n",
    "        Y = model_encoder(image_in_tensor)  # should be same as X\n",
    "    # np_converted_encoded_img = Y.detach().numpy()     # If GPU is not used\n",
    "    np_converted_encoded_img = Y.cpu().detach().numpy() # If GPU is used\n",
    "    flattened = np.reshape(np_converted_encoded_img, (out_vector_shape))\n",
    "    density = kde.score_samples([flattened])[0]\n",
    "    density_lst.append(density)\n",
    "average_density = np.mean(np.array(density_lst))  \n",
    "stdev_density = np.std(np.array(density_lst)) \n",
    "print(\"The avg of the density values is: \", average_density)\n",
    "print(\"The stdev_density of the density values is: \", stdev_density)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code above is not relevant to execute, since it only shows an alternative way of computing the density mean and std values. See that the results from this code block and the one above of it, are the same. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it will be shown the density mean and std deviation of the set of anomalies samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_anomalies = '../../../Images/BottleStoodUp_atNight/Anomalies2.0'      #This is for the home laptop\n",
    "# data_anomalies = '../../../Images/BottleStoodUp_atNight/Anomalies2.0'      #This is for the work laptop\n",
    "transform_characteristics = transforms.Compose([transforms.ToTensor(),\n",
    "                                                transforms.Resize(255),\n",
    "                                                transforms.CenterCrop(224)])\n",
    "dataset_anomalies = datasets.ImageFolder(data_anomalies, transform=transform_characteristics)\n",
    "dataloader_anomalies = torch.utils.data.DataLoader(dataset_anomalies, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Get encoded output of input images = Latent space\n",
    "encoded_anomalies_images = []\n",
    "\n",
    "for i in range(len(dataset_anomalies)):\n",
    "    X = dataset_anomalies[i]\n",
    "    image_in_tensor = X[0]\n",
    "    image_in_tensor = image_in_tensor.cuda()            # Because GPU is being used\n",
    "    with torch.no_grad():\n",
    "        Y = model_encoder(image_in_tensor)  # should be same as X\n",
    "    encoded_anomalies_images.append(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_encoded_anomaly_images = []\n",
    "for i in range (len(encoded_anomalies_images)):\n",
    "    # np_conversion = encoded_anomalies_images[i].detach().numpy()      # If GPU is not used\n",
    "    np_conversion = encoded_anomalies_images[i].cpu().detach().numpy()    # If GPU is used\n",
    "    np_encoded_anomaly_images.append(np_conversion)\n",
    "np_encoded_anomaly_images = np.array(np_encoded_anomaly_images)\n",
    "print(type(np_encoded_anomaly_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_anomaly_images_vector = [np.reshape(img_encoded, (out_vector_shape)) for img_encoded in np_encoded_anomaly_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_anomalies = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(encoded_anomaly_images_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308.93296118 308.93296118 308.93296118 308.93296118 308.93296118\n",
      " 308.93296118]\n"
     ]
    }
   ],
   "source": [
    "density_vals_anomalies = kde_anomalies.score_samples(encoded_anomaly_images_vector)\n",
    "print(density_vals_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg of the density values is:  308.9329611840144\n",
      "The stdev_density of the density values is:  0.0\n"
     ]
    }
   ],
   "source": [
    "average_density_anomalies = np.mean(density_vals_anomalies)\n",
    "stdev_density_anomalies = np.std(density_vals_anomalies)\n",
    "print(\"The avg of the density values is: \", average_density_anomalies)\n",
    "print(\"The stdev_density of the density values is: \", stdev_density_anomalies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the non-anomaly images, the difference among the density values is very low; so low that for this case, the anomaly images, there is no difference among these values. See that the standard deviation is zero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having computed the mean of the kde of the anomaly and non-anomaly images, the following fucntions to decide whether a kde value corresponds or not to an anomaly images can be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranges_mapper(value, leftMin, leftMax, rightMin, rightMax):\n",
    "    # Figure out how 'wide' each range is\n",
    "    leftSpan = leftMax - leftMin\n",
    "    rightSpan = rightMax - rightMin\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    valueScaled = float(value - leftMin) / float(leftSpan)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return rightMin + (valueScaled * rightSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_kde2prob_list(input_list):\n",
    "    threshold = 305.6925          # The mean of the kde corresponding to the non-anomaly images\n",
    "    std_dev = 0.2886            # The std deviation of the kde corresponding to the non-anomaly images\n",
    "    prob_score_list = []\n",
    "    prob_score = 0              # This was changed for making threshold+std_dev be mapped to be 50% chance. Before it was directly mapped threshold value to 50% chance\n",
    "    for i in range (len(input_list)):\n",
    "        aux_score = input_list[i] - threshold\n",
    "        if aux_score>=0:\n",
    "            additional = ranges_mapper(aux_score, 0, std_dev, 0, 50)\n",
    "            prob_score_tot = prob_score+additional\n",
    "        else:\n",
    "            additional = ranges_mapper(abs(aux_score), 0, std_dev, 0, 50)\n",
    "            prob_score_tot = prob_score-additional\n",
    "        if prob_score_tot > 100:\n",
    "            prob_score_tot = 100\n",
    "        if prob_score_tot < 0:\n",
    "            prob_score_tot = 0\n",
    "        prob_score_list.append(prob_score_tot)\n",
    "    return prob_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_kde2prob(value):\n",
    "    threshold = 305.6925          # The mean of the kde corresponding to the non-anomaly images\n",
    "    std_dev = 0.2886            # The std deviation of the kde corresponding to the non-anomaly images\n",
    "    prob_score = 0              # This was changed for making threshold+std_dev be mapped to be 50% chance. Before it was directly mapped threshold value to 50% chance\n",
    "    aux_score = value - threshold\n",
    "        \n",
    "    if aux_score>=0:\n",
    "        additional = ranges_mapper(aux_score, 0, std_dev, 0, 50)\n",
    "        prob_score_tot = prob_score+additional\n",
    "    else:\n",
    "        additional = ranges_mapper(abs(aux_score), 0, std_dev, 0, 50)\n",
    "        prob_score_tot = prob_score-additional\n",
    "    if prob_score_tot > 100:\n",
    "        prob_score_tot = 100\n",
    "    if prob_score_tot < 0:\n",
    "        prob_score_tot = 0    \n",
    "    return prob_score_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.24255024255378\n"
     ]
    }
   ],
   "source": [
    "print(map_kde2prob(305.6925 + 0.29 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePred(kde_value):\n",
    "    pred = 0\n",
    "    prob_anomaly = map_kde2prob(kde_value)/100\n",
    "    if prob_anomaly > 0.5:\n",
    "        pred = 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prob of the kde value of being anomaly image is:  51.2993762993706\n",
      "Given the probability, it is actually predicted as: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"The prob of the kde value of being anomaly image is: \", map_kde2prob(305.7+0.2886))\n",
    "print(\"Given the probability, it is actually predicted as:\", computePred(305.7+0.2886))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the kde thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../../../Images/BottleStoodUp_atNight/Evaluation'      #This is for the home laptop\n",
    "transform_characteristics = transforms.Compose([transforms.ToTensor(),\n",
    "                                                transforms.Resize(255),\n",
    "                                                transforms.CenterCrop(224)])\n",
    "\n",
    "dataset_test = datasets.ImageFolder(test_dir, transform=transform_characteristics)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
    "classes = ('non-anomaly','anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\.conda\\envs\\tfm_3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Get encoded output of input images = Latent space\n",
    "encoded_test_imgs = []\n",
    "\n",
    "\n",
    "for i in range(len(dataset_test)):\n",
    "    X = dataset_test[i]\n",
    "    image_in_tensor = X[0]\n",
    "    image_in_tensor = image_in_tensor.cuda()     \n",
    "    with torch.no_grad():\n",
    "        Y = model_encoder(image_in_tensor)  # should be same as X\n",
    "    # np_conversion = Y.detach().numpy()\n",
    "    np_conversion = Y.cpu().detach().numpy()\n",
    "    encoded_test_imgs.append(np_conversion)\n",
    "np_encoded_test_images = np.array(encoded_test_imgs)\n",
    "print(type(np_encoded_test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "encoded_test_images_vector = [np.reshape(img, (out_vector_shape)) for img in np_encoded_test_images]\n",
    "print(len(encoded_test_images_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -350.66413316   -693.23419748  -2022.37516531  -2183.68671352\n",
      "  -2798.28766935  -3265.51542309    196.33231176  -2769.17219781\n",
      "  -1146.84173522  -2419.90016941    117.26213975    146.6709388\n",
      "    270.04007735    -80.36922329   -564.51120736     74.38002572\n",
      " -20701.61324201 -16411.97025552  -2097.54033818   -267.31605633\n",
      "   -236.57407978   -543.94012139   -663.36097389   -562.03047548\n",
      "   -613.33389858   -950.48218362   -920.10936183  -1474.8882248\n",
      "  -1752.38172298  -1124.49142743]\n"
     ]
    }
   ],
   "source": [
    "density_vals_test = kde.score_samples(encoded_test_images_vector)\n",
    "print(density_vals_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shown values are REALLY strange. It was not expected to have negative values in the density numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_test = map_kde2prob_list(density_vals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# Grabbing only the first image of the anomalies dataset\n",
    "X = dataset_test[0]\n",
    "image_in_tensor = X[0]\n",
    " \n",
    "n_features = len(image_in_tensor[0])  # Get the size of one image of the anomaly images dataset. This is supposed to be 224\n",
    "for i in range(len(dataset_test)):\n",
    "    X = dataset_test[i]\n",
    "    image_in_tensor = X[0]\n",
    "    image_in_tensor = image_in_tensor.cuda() \n",
    "    ground_truth = X[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Y = model_encoder(image_in_tensor)  # should be same as X\n",
    "    np_converted_encoded_img = Y.cpu().detach().numpy()\n",
    "    flattened = np.reshape(np_converted_encoded_img, (out_vector_shape))\n",
    "    density = kde.score_samples([flattened])[0]\n",
    "    prediction = computePred(density)\n",
    "    y_pred.append(prediction) # Save Prediction\n",
    "    y_true.append(ground_truth) # Save Truth\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, it can be seen that all the images are predicted to be non-anomaly images. This is a terrible performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
