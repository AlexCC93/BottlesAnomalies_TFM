{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# uci_digits_auto_anomaly.py\n",
    "\n",
    "# autoencoder reconstruction error anomaly detection\n",
    "# uses an encoder-decoder architecture\n",
    "# PyTorch 1.8.0-CPU Anaconda3-2020.02  Python 3.7.6\n",
    "# Windows 10 \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as T\n",
    "\n",
    "device = T.device(\"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "\n",
    "class UCI_Digits_Dataset(T.utils.data.Dataset):\n",
    "  # 8,12,0,16, . . 15,7\n",
    "  # 64 pixel values [0-16], digit [0-9]\n",
    "\n",
    "  def __init__(self, src_file, n_rows=None):\n",
    "    all_xy = np.loadtxt(src_file, max_rows=n_rows,\n",
    "      usecols=range(0,65), delimiter=\",\", comments=\"#\",\n",
    "      dtype=np.float32)\n",
    "    self.xy_data = T.tensor(all_xy, dtype=T.float32).to(device) \n",
    "    self.xy_data[:, 0:64] /= 16.0   # normalize pixels\n",
    "    self.xy_data[:, 64] /= 9.0      # normalize digit/label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.xy_data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    xy = self.xy_data[idx]\n",
    "    return xy\n",
    "\n",
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "\n",
    "class Autoencoder(T.nn.Module):  # 65-32-8-32-65\n",
    "  def __init__(self):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.fc1 = T.nn.Linear(65, 32)\n",
    "    self.fc2 = T.nn.Linear(32, 8)\n",
    "    self.fc3 = T.nn.Linear(8, 32)\n",
    "    self.fc4 = T.nn.Linear(32, 65)\n",
    "\n",
    "  def encode(self, x):  # 65-32-8\n",
    "    z = T.tanh(self.fc1(x))\n",
    "    z = T.tanh(self.fc2(z))  # latent in [-1,+1]\n",
    "    return z  \n",
    "\n",
    "  def decode(self, x):  # 8-32-65\n",
    "    z = T.tanh(self.fc3(x))\n",
    "    z = T.sigmoid(self.fc4(z))  # [0.0, 1.0]\n",
    "    return z\n",
    "    \n",
    "  def forward(self, x):\n",
    "    z = self.encode(x) \n",
    "    z = self.decode(z) \n",
    "    return z  # in [0.0, 1.0]\n",
    "\n",
    "# -----------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "\n",
    "def display_digit(ds, idx, save=False):\n",
    "  # ds is a PyTorch Dataset\n",
    "  line = ds[idx]  # tensor\n",
    "  pixels = np.array(line[0:64])  # numpy row of pixels\n",
    "  label = np.int_(line[64] * 9.0)  # denormalize; like '5'\n",
    "  print(\"\\ndigit = \", str(label), \"\\n\")\n",
    "\n",
    "  pixels = pixels.reshape((8,8))\n",
    "  for i in range(8):\n",
    "    for j in range(8):\n",
    "      pxl = pixels[i,j]  # or [i][j] syntax\n",
    "      pxl = np.int_(pxl * 16.0)  # denormalize\n",
    "      print(\"%.2X\" % pxl, end=\"\")\n",
    "      print(\" \", end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "  plt.imshow(pixels, cmap=plt.get_cmap('gray_r'))\n",
    "  if save == True:\n",
    "    plt.savefig(\".\\\\idx_\" + str(idx) + \"_digit_\" + \\\n",
    "    str(label) + \".jpg\", bbox_inches='tight')\n",
    "  plt.show() \n",
    "  plt.close() \n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_digits(ds, idxs, save=False):\n",
    "  # idxs is a list of indices\n",
    "  for idx in idxs:\n",
    "    display_digit(ds, idx, save)\n",
    "\n",
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(ae, ds, bs, me, le, lr):\n",
    "  # autoencoder, dataset, batch_size, max_epochs,\n",
    "  # log_every, learn_rate\n",
    "  # assumes ae.train() has been set\n",
    "  data_ldr = T.utils.data.DataLoader(ds, batch_size=bs,\n",
    "    shuffle=True)\n",
    "  loss_func = T.nn.MSELoss()\n",
    "  opt = T.optim.SGD(ae.parameters(), lr=lr)\n",
    "  print(\"\\nStarting training\")\n",
    "  for epoch in range(0, me):\n",
    "    epoch_loss = 0.0\n",
    "    for (batch_idx, batch) in enumerate(data_ldr):\n",
    "      X = batch  # inputs\n",
    "      Y = batch  # targets (same as inputs)\n",
    "\n",
    "      opt.zero_grad()                # prepare gradients\n",
    "      oupt = ae(X)                   # compute output/target\n",
    "      loss_val = loss_func(oupt, Y)  # a tensor\n",
    "      epoch_loss += loss_val.item()  # accumulate for display\n",
    "      loss_val.backward()            # compute gradients\n",
    "      opt.step()                     # update weights\n",
    "\n",
    "    if epoch % le == 0:\n",
    "      print(\"epoch = %4d   loss = %0.4f\" % (epoch, epoch_loss))\n",
    "  print(\"Done \")\n",
    "\n",
    "# -----------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_err_list(model, ds):\n",
    "  # assumes model.eval()\n",
    "  result_lst = []\n",
    "  n_features = len(ds[0])  # 65\n",
    "  for i in range(len(ds)):\n",
    "    X = ds[i]\n",
    "    with T.no_grad():\n",
    "      Y = model(X)  # should be same as X\n",
    "    err = T.sum((X-Y)*(X-Y)).item()  # SSE all features\n",
    "    err = err / n_features           # sort of norm'ed SSE \n",
    "    result_lst.append( (i,err) )     # idx of data item, err\n",
    "  return result_lst \n",
    "\n",
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin UCI Digits autoencoder anomaly demo \n",
      "\n",
      "Loading data as normalized tensors \n"
     ]
    }
   ],
   "source": [
    "# 0. get started\n",
    "print(\"\\nBegin UCI Digits autoencoder anomaly demo \")\n",
    "T.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# 1. create Dataset object\n",
    "print(\"\\nLoading data as normalized tensors \")\n",
    "fn = \".\\\\Data\\\\optdigits_train_3823.txt\"\n",
    "data_ds = UCI_Digits_Dataset(fn)  # all rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "3823\n"
     ]
    }
   ],
   "source": [
    "print(type(data_ds.__getitem__(1125)))\n",
    "print(len(data_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ae, ds, bs, me, le, lr):\n",
    "  # autoencoder, dataset, batch_size, max_epochs,\n",
    "  # log_every, learn_rate\n",
    "  # assumes ae.train() has been set\n",
    "  data_ldr = T.utils.data.DataLoader(ds, batch_size=bs,\n",
    "    shuffle=True)\n",
    "  loss_func = T.nn.MSELoss()\n",
    "  opt = T.optim.SGD(ae.parameters(), lr=lr)\n",
    "  print(\"\\nStarting training\")\n",
    "  for epoch in range(0, me):\n",
    "    epoch_loss = 0.0\n",
    "    for (batch_idx, batch) in enumerate(data_ldr):\n",
    "      X = batch  # inputs\n",
    "      Y = batch  # targets (same as inputs)\n",
    "\n",
    "      opt.zero_grad()                # prepare gradients\n",
    "      oupt = ae(X)                   # compute output/target\n",
    "      loss_val = loss_func(oupt, Y)  # a tensor\n",
    "      epoch_loss += loss_val.item()  # accumulate for display\n",
    "      loss_val.backward()            # compute gradients\n",
    "      opt.step()                     # update weights\n",
    "\n",
    "    if epoch % le == 0:\n",
    "      print(\"epoch = %4d   loss = %0.4f\" % (epoch, epoch_loss))\n",
    "  print(\"Done \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating a 65-32-8-32-65 autoencoder \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (fc1): Linear(in_features=65, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (fc3): Linear(in_features=8, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2. create autoencoder net\n",
    "print(\"\\nCreating a 65-32-8-32-65 autoencoder \")\n",
    "autoenc = Autoencoder().to(device)\n",
    "autoenc.train()   # set mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bat_size =  10 \n",
      "max epochs = 100\n",
      "loss = MSELoss\n",
      "optimizer = SGD\n",
      "lrn_rate = 0.005 \n"
     ]
    }
   ],
   "source": [
    "# 3. train autoencoder model\n",
    "bat_size = 10\n",
    "max_epochs = 100\n",
    "log_interval = 10\n",
    "lrn_rate = 0.005\n",
    "\n",
    "print(\"\\nbat_size = %3d \" % bat_size)\n",
    "print(\"max epochs = \" + str(max_epochs))\n",
    "print(\"loss = MSELoss\")\n",
    "print(\"optimizer = SGD\")\n",
    "print(\"lrn_rate = %0.3f \" % lrn_rate)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(autoenc, data_ds, bat_size, max_epochs, \\\n",
    "log_interval, lrn_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../../BottlesAnomalies_TFM/models/pytorchModels/UCI_digitsModel1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.save(autoenc.state_dict(), filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (fc1): Linear(in_features=65, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (fc3): Linear(in_features=8, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loading the model \n",
    "autoenc.load_state_dict(T.load(filepath))\n",
    "autoenc.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing reconstruction errors \n"
     ]
    }
   ],
   "source": [
    "# 4. compute and store reconstruction errors\n",
    "print(\"\\nComputing reconstruction errors \")\n",
    "autoenc.eval()  # set mode\n",
    "err_list = make_err_list(autoenc, data_ds)\n",
    "err_list.sort(key=lambda x: x[1], \\\n",
    "reverse=True)  # high error to low\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest reconstruction item / error: \n",
      " [ 486]  0.1352\n",
      "\n",
      "digit =  7 \n",
      "\n",
      "00 00 00 0A 10 10 10 09 \n",
      "00 00 00 02 05 0A 10 0C \n",
      "00 00 00 00 00 06 10 02 \n",
      "00 00 00 00 00 0E 0A 00 \n",
      "00 01 08 0E 10 10 05 00 \n",
      "00 05 0A 08 10 0A 01 00 \n",
      "00 00 00 05 0E 01 00 00 \n",
      "00 00 00 0D 09 00 00 00 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End autoencoder anomaly detection demo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. show most anomalous item\n",
    "print(\"Largest reconstruction item / error: \")\n",
    "(idx,err) = err_list[0]\n",
    "print(\" [%4d]  %0.4f\" % (idx, err)) \n",
    "display_digit(data_ds, idx)\n",
    "\n",
    "print(\"\\nEnd autoencoder anomaly detection demo \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
