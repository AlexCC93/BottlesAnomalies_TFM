{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "# from keras import layers\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "SIZE = 228"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 17:04:54.600405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2023-06-05 17:04:54.623917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:04:54.624235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.23GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2023-06-05 17:04:54.624430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-05 17:04:54.625685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-05 17:04:54.627038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-05 17:04:54.627268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-05 17:04:54.628813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-05 17:04:54.629565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-05 17:04:54.632517: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-05 17:04:54.632626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:04:54.632984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:04:54.633266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2023-06-05 17:04:54.633849: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-06-05 17:04:54.654547: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2599990000 Hz\n",
      "2023-06-05 17:04:54.655149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5b78000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-05 17:04:54.655164: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-06-05 17:04:54.740613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:04:54.741018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24db280 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-05 17:04:54.741057: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 with Max-Q Design, Compute Capability 7.5\n",
      "2023-06-05 17:04:54.741300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:04:54.741780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.23GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2023-06-05 17:04:54.741855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-05 17:04:54.741880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-05 17:04:54.741902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-05 17:04:54.741920: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-05 17:04:54.741938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-05 17:04:54.741979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-05 17:04:54.742026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-05 17:04:54.742149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:04:54.742686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:04:54.743007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2023-06-05 17:04:54.743044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-05 17:04:54.743488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-06-05 17:04:54.743498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2023-06-05 17:04:54.743503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2023-06-05 17:04:54.743596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:04:54.743930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:04:54.744236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6478 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input shape is:  (15, 228, 228, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 17:04:55.278356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-05 17:04:56.045509: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-05 17:04:56.049112: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    933\u001b[0m             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[1;32m    934\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: Expecting int64_t value for attr strides, got numpy.int32",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(input_shape)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe input shape is: \u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 4\u001b[0m y \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49minput_shape[\u001b[39m1\u001b[39;49m:])(x) \u001b[39m# Conv2D(filters, kernel size, ...)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe output shape, after applying Conv2D, is: \u001b[39m\u001b[39m\"\u001b[39m, y\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:968\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m cast_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m    966\u001b[0m \u001b[39mwith\u001b[39;00m base_layer_utils\u001b[39m.\u001b[39mautocast_context_manager(\n\u001b[1;32m    967\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype):\n\u001b[0;32m--> 968\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(cast_inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    969\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py:207\u001b[0m, in \u001b[0;36mConv.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcausal\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mConv1D\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    205\u001b[0m   inputs \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mpad(inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_causal_padding())\n\u001b[0;32m--> 207\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convolution_op(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel)\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m    210\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_format \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mchannels_first\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:1106\u001b[0m, in \u001b[0;36mConvolution.__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[39mreturn\u001b[39;00m convolution_internal(\n\u001b[1;32m   1097\u001b[0m       inp,\n\u001b[1;32m   1098\u001b[0m       \u001b[39mfilter\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1103\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m   1104\u001b[0m       call_from_convolution\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_op(inp, \u001b[39mfilter\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:638\u001b[0m, in \u001b[0;36m_WithSpaceToBatch.__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, inp, \u001b[39mfilter\u001b[39m):  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(inp, \u001b[39mfilter\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:231\u001b[0m, in \u001b[0;36m_NonAtrousConvolution.__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, inp, \u001b[39mfilter\u001b[39m):  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_op(\n\u001b[1;32m    232\u001b[0m       \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49minp,\n\u001b[1;32m    233\u001b[0m       \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m,\n\u001b[1;32m    234\u001b[0m       strides\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrides,\n\u001b[1;32m    235\u001b[0m       padding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[1;32m    236\u001b[0m       data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[1;32m    237\u001b[0m       name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:2006\u001b[0m, in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2004\u001b[0m strides \u001b[39m=\u001b[39m _get_sequence(strides, \u001b[39m2\u001b[39m, channel_index, \u001b[39m\"\u001b[39m\u001b[39mstrides\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2005\u001b[0m dilations \u001b[39m=\u001b[39m _get_sequence(dilations, \u001b[39m2\u001b[39m, channel_index, \u001b[39m\"\u001b[39m\u001b[39mdilations\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2006\u001b[0m \u001b[39mreturn\u001b[39;00m gen_nn_ops\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m,  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;49;00m\n\u001b[1;32m   2007\u001b[0m                          \u001b[39mfilter\u001b[39;49m,\n\u001b[1;32m   2008\u001b[0m                          strides,\n\u001b[1;32m   2009\u001b[0m                          padding,\n\u001b[1;32m   2010\u001b[0m                          use_cudnn_on_gpu\u001b[39m=\u001b[39;49muse_cudnn_on_gpu,\n\u001b[1;32m   2011\u001b[0m                          explicit_paddings\u001b[39m=\u001b[39;49mexplicit_paddings,\n\u001b[1;32m   2012\u001b[0m                          data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[1;32m   2013\u001b[0m                          dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[1;32m   2014\u001b[0m                          name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py:930\u001b[0m, in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m    929\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     \u001b[39mreturn\u001b[39;00m conv2d_eager_fallback(\n\u001b[1;32m    931\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mfilter\u001b[39;49m, strides\u001b[39m=\u001b[39;49mstrides, use_cudnn_on_gpu\u001b[39m=\u001b[39;49muse_cudnn_on_gpu,\n\u001b[1;32m    932\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding, explicit_paddings\u001b[39m=\u001b[39;49mexplicit_paddings,\n\u001b[1;32m    933\u001b[0m         data_format\u001b[39m=\u001b[39;49mdata_format, dilations\u001b[39m=\u001b[39;49mdilations, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[1;32m    934\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[1;32m    935\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py:1021\u001b[0m, in \u001b[0;36mconv2d_eager_fallback\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[1;32m   1017\u001b[0m _inputs_flat \u001b[39m=\u001b[39m [\u001b[39minput\u001b[39m, \u001b[39mfilter\u001b[39m]\n\u001b[1;32m   1018\u001b[0m _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, _attr_T, \u001b[39m\"\u001b[39m\u001b[39mstrides\u001b[39m\u001b[39m\"\u001b[39m, strides, \u001b[39m\"\u001b[39m\u001b[39muse_cudnn_on_gpu\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1019\u001b[0m use_cudnn_on_gpu, \u001b[39m\"\u001b[39m\u001b[39mpadding\u001b[39m\u001b[39m\"\u001b[39m, padding, \u001b[39m\"\u001b[39m\u001b[39mexplicit_paddings\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1020\u001b[0m explicit_paddings, \u001b[39m\"\u001b[39m\u001b[39mdata_format\u001b[39m\u001b[39m\"\u001b[39m, data_format, \u001b[39m\"\u001b[39m\u001b[39mdilations\u001b[39m\u001b[39m\"\u001b[39m, dilations)\n\u001b[0;32m-> 1021\u001b[0m _result \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49mexecute(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mConv2D\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m, inputs\u001b[39m=\u001b[39;49m_inputs_flat, attrs\u001b[39m=\u001b[39;49m_attrs,\n\u001b[1;32m   1022\u001b[0m                            ctx\u001b[39m=\u001b[39;49mctx, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1023\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n\u001b[1;32m   1024\u001b[0m   _execute\u001b[39m.\u001b[39mrecord_gradient(\n\u001b[1;32m   1025\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mConv2D\u001b[39m\u001b[39m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "input_shape = (batch_size, SIZE, SIZE, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "print(\"The input shape is: \", x.shape)\n",
    "y = tf.keras.layers.Conv2D(2, 3, activation='relu', input_shape=input_shape[1:])(x) # Conv2D(filters, kernel size, ...)\n",
    "print(\"The output shape, after applying Conv2D, is: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 228, 3)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape[1:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the layers in program \"BottlesTensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after Conv2D, the shape is:  (None, 228, 228, 16)\n"
     ]
    }
   ],
   "source": [
    "input_img = keras.Input(shape=(SIZE, SIZE, 3))\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img) #Conv2D(filters, kernel_size, ...)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "autoencoder = keras.Model(input_img, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input shape is:  (15, 228, 228, 3)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "The output shape, after feeding to the autoencoder, is:  (15, 228, 228, 16)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (batch_size, SIZE, SIZE, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "print(\"The input shape is: \", x.shape)\n",
    "decoded_imgs = autoencoder.predict(x)\n",
    "print(\"The output shape, after feeding to the autoencoder, is: \", decoded_imgs.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, checking all the layers of the \"BottlesTensorflow\" program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER PART\n",
      "input img shape is:  (15, 228, 228, 3)\n",
      "after Conv2D, the shape is:  (None, 228, 228, 16)\n",
      "after MaxPooling2D, the shape is:  (None, 114, 114, 16)\n",
      "after Conv2D, the shape is:  (None, 114, 114, 8)\n",
      "after MaxPooling2D, the shape is:  (None, 57, 57, 8)\n",
      "after Conv2D, the shape is:  (None, 57, 57, 8)\n",
      "after MaxPooling2D, the shape is:  (None, 29, 29, 8)\n",
      "DECODER PART\n",
      "after Conv2D, the shape is:  (None, 29, 29, 8)\n",
      "after UpSampling2D, the shape is:  (None, 58, 58, 8)\n",
      "after Conv2D, the shape is:  (None, 58, 58, 8)\n",
      "after UpSampling2D, the shape is:  (None, 116, 116, 8)\n",
      "after Conv2D, the shape is:  (None, 114, 114, 16)\n",
      "after UpSampling2D, the shape is:  (None, 228, 228, 16)\n",
      "after Conv2D, the shape is:  (None, 228, 228, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"ENCODER PART\")\n",
    "print(\"input img shape is: \", input_shape)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(\"after MaxPooling2D, the shape is: \", x.shape)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(\"after MaxPooling2D, the shape is: \", x.shape)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(\"after MaxPooling2D, the shape is: \", encoded.shape)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "print(\"DECODER PART\")\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "print(\"after UpSampling2D, the shape is: \", x.shape)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "print(\"after UpSampling2D, the shape is: \", x.shape)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "print(\"after UpSampling2D, the shape is: \", x.shape)\n",
    "# decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "print(\"after Conv2D, the shape is: \", decoded.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the layers in program \"BottlesTensorflow13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "# from keras import layers\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER PART\n",
      "input img shape is:  Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32)\n",
      "after Conv2D, the shape is:  (None, 224, 224, 128)\n",
      "after MaxPooling2D, the shape is:  (None, 112, 112, 128)\n",
      "after Conv2D, the shape is:  (None, 112, 112, 64)\n",
      "after MaxPooling2D, the shape is:  (None, 56, 56, 64)\n",
      "after Conv2D, the shape is:  (None, 56, 56, 32)\n",
      "after MaxPool2D, the shape is:  (None, 28, 28, 32)\n",
      "after Conv2D, the shape is:  (None, 28, 28, 16)\n",
      "after MaxPool2D, the shape is:  (None, 14, 14, 16)\n",
      "after Conv2D, the shape is:  (None, 14, 14, 4)\n",
      "after MaxPool2D, the shape is:  (None, 7, 7, 4)\n",
      "after Conv2D, the shape is:  (None, 7, 7, 1)\n",
      "shape_before_flattening is:  (None, 7, 7, 1)\n",
      "after Flatten, the shape is:  (None, 49)\n",
      "after Dense, the shape is:  (None, 64)\n",
      "after Dense, the shape is:  (None, 32)\n",
      "shape of Z is:  (None, 32)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 64)      73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 4)         580       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 4)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 1)           37        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                3200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 106,361\n",
      "Trainable params: 106,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 32  # Number of latent dimension parameters\n",
    "\n",
    "print(\"ENCODER PART\")\n",
    "\n",
    "input_img = Input(shape=(SIZE, SIZE, 3))\n",
    "print(\"input img shape is: \", input_img)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same') (input_img)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(\"after MaxPooling2D, the shape is: \", x.shape)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(\"after MaxPooling2D, the shape is: \", x.shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "x = MaxPool2D( (2, 2), padding='same')(x)\n",
    "print(\"after MaxPool2D, the shape is: \", x.shape)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "x = MaxPool2D( (2, 2), padding='same')(x)\n",
    "print(\"after MaxPool2D, the shape is: \", x.shape)\n",
    "x = Conv2D(4, (3, 3), activation='relu', padding='same')(x)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "x = MaxPool2D( (2, 2), padding='same')(x)\n",
    "print(\"after MaxPool2D, the shape is: \", x.shape)\n",
    "x = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
    "print(\"after Conv2D, the shape is: \", x.shape)\n",
    "shape_before_flattening = K.int_shape(x)\n",
    "print(\"shape_before_flattening is: \", shape_before_flattening)\n",
    "x = Flatten()(x)\n",
    "print(\"after Flatten, the shape is: \", x.shape)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "print(\"after Dense, the shape is: \", x.shape)\n",
    "\n",
    "Z = Dense(latent_dim)(x)\n",
    "print(\"after Dense, the shape is: \", Z.shape)\n",
    "\n",
    "print(\"shape of Z is: \", K.int_shape(Z))\n",
    "\n",
    "encoder = Model(input_img,Z)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
