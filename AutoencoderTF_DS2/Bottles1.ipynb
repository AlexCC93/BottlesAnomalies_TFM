{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "# from keras import layers\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 16:20:35.605538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2023-06-05 16:20:35.683022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 16:20:35.683380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.23GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2023-06-05 16:20:35.684634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-05 16:20:35.711441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-05 16:20:35.735353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-05 16:20:35.740008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-05 16:20:35.772014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-05 16:20:35.776483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-05 16:20:35.833935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-05 16:20:35.834142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 16:20:35.834891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 16:20:35.835475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) == 0:\n",
    "    print(\"Not enough GPU hardware devices available\")\n",
    "else:\n",
    "    config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(\"Num GPUs Available: \", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)       # Will print the log information of every execution of tensorflow, mainly about "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size of our input images\n",
    "SIZE = 224"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the training and testing datasets "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator.flow_from_directory: Takes the path to a directory and generates batches of augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Data augmentation generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # zoom_range=0.2,\n",
    "    brightness_range=[0.88,1.0],\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # rotation_range=20)\n",
    "    # zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Original images generator\n",
    "original_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"../../Images/BottleStoodUp_atNight/Positive/\",     # For home laptop\n",
    "    # \"../../../BottleStoodUp_atNight/Positive/\",           # For work laptop\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    class_mode='input'          # Class used for working with Autoencoders\n",
    "    \n",
    "    )\n",
    "\n",
    "# Generate original images from the original data directory\n",
    "original_generator = original_datagen.flow_from_directory(\n",
    "    \"../../Images/BottleStoodUp_atNight/Positive/\",\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    class_mode='input')\n",
    "\n",
    "# Combine the generators using the `keras.preprocessing.image.Iterator` class\n",
    "combined_generator = zip(train_generator, original_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = original_datagen.flow_from_directory(\n",
    "    \"../../Images/BottleStoodUp_atNight/Positive_val/\",     # For home laptop\n",
    "    # \"../../../BottleStoodUp_atNight/Positive_val/\",           # For work lpatop   \n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    class_mode='input'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_generator = original_datagen.flow_from_directory(\n",
    "    \"../../Images/BottleStoodUp_atNight/Anomalies2.0/\",         # For home laptop\n",
    "    # \"../../../BottleStoodUp_atNight/Anomalies2.0/\",           # For work lpatpo\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    class_mode='input'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_generator = original_datagen.flow_from_directory(\n",
    "    \"../../Images/BottleStoodUp_atNight/Evaluation/\",       # For home laptop\n",
    "    # \"../../../BottleStoodUp_atNight/Evaluation/\",             # For work laptop  \n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    class_mode='binary'\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing one sample of the training set images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing only one image of one batch of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(augmented_images_batch, original_images_batch) = next(combined_generator)\n",
    "print(\"FOR THE AUGMENTED IMAGES\")\n",
    "print(type(augmented_images_batch))\n",
    "print(len(augmented_images_batch))\n",
    "print(tf.reduce_min(augmented_images_batch), tf.reduce_max(augmented_images_batch))\n",
    "print(\"FOR THE ORIGINAL IMAGES\")\n",
    "print(type(original_images_batch))\n",
    "print(len(original_images_batch))\n",
    "print(tf.reduce_min(original_images_batch), tf.reduce_max(original_images_batch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One sample of the augmented images\")\n",
    "print(len(augmented_images_batch))\n",
    "input_batch_augmented = augmented_images_batch[0]\n",
    "print(input_batch_augmented.shape)\n",
    "single_img = input_batch_augmented[0]\n",
    "plt.imshow(single_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One sample of the original images\")\n",
    "print(len(original_images_batch))\n",
    "input_batch_original = original_images_batch[0]\n",
    "print(input_batch_original.shape)\n",
    "single_img_orgn = input_batch_original[0]\n",
    "plt.imshow(single_img_orgn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring the Autoencoder netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32  # Number of latent dimension parameters\n",
    "\n",
    "input_img = Input(shape=(SIZE, SIZE, 3))\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same') (input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPool2D( (2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPool2D( (2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(4, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPool2D( (2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "shape_before_flattening = K.int_shape(x)\n",
    "print(shape_before_flattening)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "Z = Dense(latent_dim)(x)\n",
    "print(K.int_shape(Z))\n",
    "\n",
    "encoder = Model(input_img,Z)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder takes the latent distribution sample as input\n",
    "decoder_input = Input(K.int_shape(Z)[1:])\n",
    "x = Dense(14*14*4, activation='relu', name=\"intermediate_decoder\", input_shape=(latent_dim,))(decoder_input)\n",
    "# Expand to 784 total pixels\n",
    "x = Dense(784, activation='sigmoid', name=\"original_decoder\")(x)\n",
    "x = Reshape((14,14,4),input_shape=(784,))(x)\n",
    "\n",
    "x = Conv2DTranspose(3, (3, 3), padding='same')(x)\n",
    "x = UpSampling2D( (2, 2))(x)\n",
    "\n",
    "x = Conv2DTranspose(3, (3, 3), padding='same')(x)\n",
    "x = UpSampling2D( (2, 2))(x)\n",
    "\n",
    "x = Conv2DTranspose(3, (3, 3), padding='same')(x)\n",
    "x = UpSampling2D( (2, 2))(x)\n",
    "\n",
    "x = Conv2DTranspose(3, (3, 3), padding='same')(x)\n",
    "x = UpSampling2D( (2, 2))(x)\n",
    "\n",
    "# decoder model statement\n",
    "decoder = Model(decoder_input, x)\n",
    "\n",
    "# apply the decoder to the sample from the latent distribution\n",
    "z_decoded = decoder(Z)\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model statement\n",
    "ae = Model(input_img,z_decoded)\n",
    "ae.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "ae.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the weights of a specific layer of the encoder model, before training are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_number = 1\n",
    "print(\"quantity of layers in the model: \", len(encoder.layers))\n",
    "print(\"The weigths in the\", encoder.layers[layer_number].name, \"is: \", encoder.layers[layer_number].weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the weights of a specific layer of the decoder model,before training are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_number = 1\n",
    "# print(\"quantity of layers in the model: \", len(decoder.layers))\n",
    "# print(\"The weigths in the\", decoder.layers[layer_number].name, \"is: \", decoder.layers[layer_number].weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the weights of a specific layer of the autoencoder model,before training are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_number = 1\n",
    "# print(\"quantity of layers in the model: \", len(ae.layers))\n",
    "# print(\"The weigths in the\", ae.layers[layer_number].name, \"is: \", ae.layers[layer_number].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# run the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=5, mode='auto')\n",
    "history = ae.fit(combined_generator, epochs=2000, validation_data=validation_generator, callbacks=[early_stopping],verbose=1, steps_per_epoch=(len(original_generator)*20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the training and validation loss values from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 'NewAutoencoderModel14'\n",
    "print(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.save(f\"../../BottlesAnomalies_TFM/models/{model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ae))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model that was previously saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../models/NewAutoencoderModel14')\n",
    "print(type(model))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the weights after the model loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the weights of a specific layer of the encoder model, AFTER training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_number = 1\n",
    "print(\"quantity of layers in the model: \", len(encoder.layers))\n",
    "print(\"The weigths in the\", encoder.layers[layer_number].name, \"is: \", encoder.layers[layer_number].weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the weights of a specific layer of the Autoencoder model, AFTER training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_number = 1\n",
    "print(\"quantity of layers in the model: \", len(model.layers))\n",
    "print(\"The weigths in the\", model.layers[layer_number].name, \"is: \", model.layers[layer_number].weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed the weights of the \"Autoencoder\" model have been updated but the ones from the \"Encoder\" have not. This is expected, since the model that was trained was actually the \"Autoencoder\" mdoel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform an Autoencoder reconstruction in one image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all batches generated by the datagen and pick a batch for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just to test the model. \n",
    "data_batch = []  #Capture all training batches as a numpy array\n",
    "img_num = 0\n",
    "# while img_num <= train_generator.batch_index:   #gets each generated batch of size batch_size\n",
    "while img_num < len(original_generator):        #I think this should be the correct while clause\n",
    "    data = original_generator.next()\n",
    "    data_batch.append(data[0])\n",
    "    img_num = img_num + 1\n",
    "    \n",
    "print(\"number of batches are: \", img_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_batch))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on the first batch of images. Do also notice that the prediction is being carried out over the images we used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_batch[0].shape)\n",
    "predicted = model.predict(data_batch[0])  \n",
    "print(predicted.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is 15 length because it corresponds to the 15 predicted images of a batch. Recall that the predictions are reconstructions of the input images, since we are working with the autoencoder network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img = data_batch[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(single_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check, view few images and corresponding reconstructions\n",
    "image_number = random.randint(0, predicted.shape[0]-1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.title(\"input image\")\n",
    "plt.imshow(data_batch[0][image_number])\n",
    "plt.subplot(122)\n",
    "plt.title(\"reconstructed image\")\n",
    "plt.imshow(predicted[image_number])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying the reconstruction error using \"evaluate_generator()\" function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us examine the reconstruction error of our validation data (good/normal images) and the anomaly images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_error = model.evaluate_generator(validation_generator)\n",
    "print(\"Recon. error for the validation (normal) data is: \", validation_error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reconstruction error above should be very low, since the validation generator is full of normal images (good images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas the reconstruction error here below, for the \"anomaly_generator\" should be higher, since this dataset is comprised of full anomaly images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_error = model.evaluate_generator(anomaly_generator)\n",
    "print(\"Recon. error for the anomaly data is: \", anomaly_error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that this error is slightly higher than the error in the validation dataset. This is good, but the difference is not that significant and this could result in wrong anomaly detections. Let's see some detections."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIDENOTE: Additionally, we can check the train generator error according to the \"evaluate_generator()\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error = model.evaluate_generator(original_generator)\n",
    "print(\"Recon. error for the training (non-anomaly) data is: \", training_error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that the above value does not correspond with the below mean reconstruction error of the training set that will be computed. It should at least be close, I think. This is something to check."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also see tha the error from the anomaly images is smaller than the error of the training set, which consists of non-anomaly images. THis is not expected and means that this particular model is shit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the reconstruction error without using the \"evaluate_generator()\" function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes the reconstrution error per each batch of images. It does, for each of the batches:\n",
    "- Initialize a vector for storing the reconstruction errors.\n",
    "- A for loop that traverses all the images contained in a batch.\n",
    "    - Take the one image of the batch.\n",
    "    - Add a new size dimension to the image.\n",
    "    - Make a prediction of the selected image with the model that was built.\n",
    "    - Evaluate the performance of the prediction, i.e. compute the prediction error.\n",
    "    - Append the reconstruction error into a list.\n",
    "- Compute the mean and std deviation of the error.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_recon_error(batch_images):   \n",
    "    recon_error_list=[]\n",
    "    for im in range(0, batch_images.shape[0]):\n",
    "        img  = batch_images[im]\n",
    "        img = img[np.newaxis, :,:,:]\n",
    "        reconstruction = model.predict([[img]])\n",
    "        # reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]    # The batch_size parameter for the moment can be supressed. Results were seen to be the same\n",
    "        # reconstruction_error = model.evaluate([reconstruction],[[img]])[0]                    # It included the [0] subscription but with this new model, the rec error is directly a float value, so no more need for subscription\n",
    "        reconstruction_error = model.evaluate([reconstruction],[[img]])\n",
    "        recon_error_list.append(reconstruction_error)   \n",
    "    return recon_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_error = []\n",
    "for i in range(len(original_generator)):        #I think this should be the correct while clause\n",
    "    data = original_generator.next()\n",
    "    total_rec_error.append(calc_recon_error(data[0]))\n",
    "    \n",
    "print(\"The list of rec. error contains \", len(total_rec_error), \"batches of rec. errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_error_list = [item for sublist in total_rec_error for item in sublist]\n",
    "print(len(total_rec_error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_average_recon_error = np.mean(np.array(total_rec_error_list))  \n",
    "na_stdev_recon_error = np.std(np.array(total_rec_error_list)) \n",
    "min_prob = np.min(total_rec_error_list)\n",
    "max_prob = np.max(total_rec_error_list)\n",
    "print(\"THIS IS FOR THE TRAINING (NON-ANOMALY) IMAGES\\n\")\n",
    "print(\"The average of the errors list is: \", na_average_recon_error)\n",
    "print(\"The standard deviation of the errors list is: \", na_stdev_recon_error)\n",
    "print(\"The min value of the errors list is: \", min_prob)\n",
    "print(\"The max value of the errors list is: \", max_prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average and std dev. of recon. error for positive (anomalies) samples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_batch = anomaly_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_error_anomalies = []\n",
    "for i in range(len(anomaly_generator)):        #I think this should be the correct while clause\n",
    "    data = anomaly_generator.next()\n",
    "    total_rec_error_anomalies.append(calc_recon_error(data[0]))\n",
    "    \n",
    "print(\"The list of rec. error for anomalies contains \", len(total_rec_error_anomalies), \"batches of rec. errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_error_anomalies = [item for sublist in total_rec_error_anomalies for item in sublist]\n",
    "print(len(total_rec_error_anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_average_recon_error = np.mean(np.array(total_rec_error_anomalies))  \n",
    "a_stdev_recon_error = np.std(np.array(total_rec_error_anomalies)) \n",
    "min_prob = np.min(total_rec_error_anomalies)\n",
    "max_prob = np.max(total_rec_error_anomalies)\n",
    "print(\"THIS IS FOR THE ANOMALY IMAGES\\n\")\n",
    "print(\"The average of the errors list is: \", a_average_recon_error)\n",
    "print(\"The standard deviation of the errors list is: \", a_stdev_recon_error)\n",
    "print(\"The min value of the errors list is: \", min_prob)\n",
    "print(\"The max value of the errors list is: \", max_prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average and std dev. of recon. error for the validation (non-anomalies) samples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_error_validation = []\n",
    "for i in range(len(validation_generator)):        #I think this should be the correct while clause\n",
    "    data = validation_generator.next()\n",
    "    total_rec_error_validation.append(calc_recon_error(data[0]))\n",
    "    \n",
    "print(\"The list of rec. error for anomalies contains \", len(total_rec_error_validation), \"batches of rec. errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_error_validation = [item for sublist in total_rec_error_validation for item in sublist]\n",
    "print(len(total_rec_error_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_average_recon_error = np.mean(np.array(total_rec_error_validation))  \n",
    "val_stdev_recon_error = np.std(np.array(total_rec_error_validation)) \n",
    "min_prob = np.min(total_rec_error_validation)\n",
    "max_prob = np.max(total_rec_error_validation)\n",
    "print(\"THIS IS FOR THE VALIDATION IMAGES\\n\")\n",
    "print(\"The average of the errors list is: \", val_average_recon_error)\n",
    "print(\"The standard deviation of the errors list is: \", val_stdev_recon_error)\n",
    "print(\"The min value of the errors list is: \", min_prob)\n",
    "print(\"The max value of the errors list is: \", max_prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can see the plot of the reconstruction error values, of the non-anomaly list (blue) and the anomaly list (red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "val = 0. # this is the value where you want the data to appear on the y-axis.\n",
    "plt.plot(total_rec_error_list, np.zeros_like(total_rec_error_list) + val, 'x')\n",
    "plt.plot(total_rec_error_anomalies, np.zeros_like(total_rec_error_anomalies) + val, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "\n",
    "bins = numpy.linspace(0.5, 0.7, 10)\n",
    "\n",
    "pyplot.hist(total_rec_error_list, bins, alpha=0.5, label='errors non-anomalies')\n",
    "pyplot.hist(total_rec_error_anomalies, bins, alpha=0.5, label='errors anomalies')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the latent space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update the weights of the encoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the layer weights from the base model to the target model\n",
    "for i, target_layer in enumerate(encoder.layers):\n",
    "    base_layer = model.layers[i]\n",
    "    target_layer.set_weights(base_layer.get_weights())\n",
    "\n",
    "# Verify if the weights are successfully copied\n",
    "for base_layer, target_layer in zip(model.layers[:len(encoder.layers)], encoder.layers):\n",
    "    base_weights = base_layer.get_weights()\n",
    "    target_weights = target_layer.get_weights()\n",
    "    for base_weight, target_weight in zip(base_weights, target_weights):\n",
    "        if (base_weight == target_weight).all():\n",
    "            print(\"Layer weights are successfully copied.\")\n",
    "        else:\n",
    "            print(\"Error: Layer weights are not copied correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Calculate KDE using sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "#Get encoded output of input images = Latent space\n",
    "encoded_images = encoder.predict_generator(original_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_images.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that it is 179 length because it corresponds to all the images that belong to the training dataset. The second length corresponds to the output shape of the model as specified in its structure at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(encoded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output_shape = encoder.output_shape \n",
    "print(encoder_output_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fit KDE to the image latent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(encoded_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function fits a kernel density estimation to the data that is provided, that is, the \"encoded_images\" variable. It does so using a Guassian kernel of bandwidth 0.2.\n",
    "\n",
    "The badnwidth parameter affects on how the selected kernel will fit each sample of the given data. For example for the case in which the kernel is a Gaussian distribution, the bandwidth parameter would affect in how thin or wide is the Gaussian distribution.\n",
    "\n",
    "At this point in the variable \"kde\" we have some numbers that are the result of fitting Gaussian functions to the given data points in the variable \"encoded_images\". We will use the \"kde\" variable later for scoring with it, some given data points; the scoring will be given depending on how similar are the given data points to the ones that it had estimated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below, it is shown the kde values corresponding to each encoded sample. THese are supposed to be very close to each other in value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_vals = kde.score_samples(encoded_images)\n",
    "print(density_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, the mean and standard deviation of these values are computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_density = np.mean(density_vals)\n",
    "stdev_density = np.std(density_vals)\n",
    "print(\"The avg of the density values is: \", average_density)\n",
    "print(\"The stdev_density of the density values is: \", stdev_density)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the above data create a function that outputs a probability of a KDE value to be considered an anomaly or non-anomaly image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranges_mapper(value, leftMin, leftMax, rightMin, rightMax):\n",
    "    # Figure out how 'wide' each range is\n",
    "    leftSpan = leftMax - leftMin\n",
    "    rightSpan = rightMax - rightMin\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    valueScaled = float(value - leftMin) / float(leftSpan)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return rightMin + (valueScaled * rightSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_kde2prob_list(input_list):\n",
    "    threshold = average_density          # The mean of the kde corresponding to the non-anomaly images\n",
    "    std_dev = stdev_density            # The std deviation of the kde corresponding to the non-anomaly images\n",
    "    prob_score_list = []\n",
    "    prob_score = 0              # This was changed for making threshold+std_dev be mapped to be 50% chance. Before it was directly mapped threshold value to 50% chance\n",
    "    for i in range (len(input_list)):\n",
    "        aux_score = input_list[i] - threshold\n",
    "        if aux_score>=0:\n",
    "            additional = ranges_mapper(aux_score, 0, std_dev, 0, 50)\n",
    "            prob_score_tot = prob_score+additional\n",
    "        else:\n",
    "            additional = ranges_mapper(abs(aux_score), 0, std_dev, 0, 50)\n",
    "            prob_score_tot = prob_score-additional\n",
    "        if prob_score_tot > 100:\n",
    "            prob_score_tot = 100\n",
    "        if prob_score_tot < 0:\n",
    "            prob_score_tot = 0\n",
    "        prob_score_list.append(prob_score_tot)\n",
    "    return prob_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_kde2prob(value):\n",
    "    threshold = average_density         # The mean of the kde corresponding to the non-anomaly images\n",
    "    std_dev = stdev_density          # The std deviation of the kde corresponding to the non-anomaly images\n",
    "    prob_score = 0              # This was changed for making threshold+std_dev be mapped to be 50% chance. Before it was directly mapped threshold value to 50% chance\n",
    "    aux_score = value - threshold\n",
    "    print(\"value is: \", value)\n",
    "    print(\"aux_score is: \", aux_score)\n",
    "        \n",
    "    if aux_score>=0:\n",
    "        additional = ranges_mapper(aux_score, 0, std_dev, 0, 50)\n",
    "        print(\"additional is: \", additional)\n",
    "        prob_score_tot = prob_score+additional\n",
    "        print(\"prob_score_tot is: \", prob_score_tot)\n",
    "        \n",
    "    else:\n",
    "        additional = ranges_mapper(abs(aux_score), 0, std_dev, 0, 50)\n",
    "        prob_score_tot = prob_score-additional\n",
    "    if prob_score_tot > 100:\n",
    "        prob_score_tot = 100\n",
    "    if prob_score_tot < 0:\n",
    "        prob_score_tot = 0    \n",
    "    return prob_score_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePred(kde_value):\n",
    "    pred = 0\n",
    "    prob_anomaly = map_kde2prob(kde_value)/100\n",
    "    if prob_anomaly > 0.5:\n",
    "        pred = 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(map_kde2prob_list([average_density + stdev_density+0.00000000000000168]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get encoded output of input images = Latent space\n",
    "encoded_images_test_set = encoder.predict_generator(test_set_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_images_test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_vals_test = kde.score_samples(encoded_images_test_set)\n",
    "print(density_vals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_density + stdev_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_test = map_kde2prob_list(density_vals_test)\n",
    "print(prob_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the final predictions based on the KDE average values that was computed before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "for i in range(len(test_set_generator)):        #I think this should be the correct while clause\n",
    "    _, labels = test_set_generator.next()\n",
    "    ground_truth.append(labels)\n",
    "    \n",
    "print(\"The list of rec. error for anomalies contains \", len(ground_truth), \"batches of rec. errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [item for sublist in ground_truth for item in sublist]\n",
    "ground_truth = [int(x) for x in ground_truth]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "for i in range(len(prob_test)):\n",
    "    \n",
    "    if(prob_test[i]>50):\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    pred_list.append(pred)\n",
    "print(ground_truth)\n",
    "print(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
